+++
title = "Things Read | Sept/Oct 2023"
date = 2023-11-02
weight = 2
+++

An impressively redeeming [interview with Mustafa Suleyman](https://80000hours.org/podcast/episodes/mustafa-suleyman-getting-washington-and-silicon-valley-to-tame-ai/). Anthropic got [an RSP](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf), and I can only hope that it will at one point become the third best RSP. Methods for [proof-of-training-data](https://arxiv.org/pdf/2307.00682.pdf), which were more compelling than I expected but I’m still not very optimistic it’ll be tractable or useful after an implementation of reasonable quality. The Frontier Model forum [seems to be doing great](https://openai.com/blog/frontier-model-forum-updates), feels a bit like a dream. 

Article explaining the [Llama.cpp performance](https://finbarr.ca/how-is-llama-cpp-possible/?fbclid=IwAR00OuFYJhv_ViGQA81VWWZayH1eblrplVFqla4E9_R32WSvL68vj6uahI0), though I find myself asking “how is it so slow” infinitely more than “how is it so fast”. I asked myself “how is it so slow” with the [3.5-turbo size-leak](https://www.arxiv-vanity.com/papers/2310.17680/)(?), and I probably would’ve asked that even for a 200B param dense model. The [GPT-V system-card](https://cdn.openai.com/papers/GPTV_System_Card.pdf) is kind of exciting, I can’t wait to move out of the chat modality. A study on [training stability](https://arxiv.org/pdf/2309.14322.pdf) (and a surprising publish from Google!). [Data comp work](https://arxiv.org/pdf/2309.10818.pdf) from the people who did Red Pajama. Cool [multi-modal architecture](https://www.adept.ai/blog/fuyu-8b) from Adept. Using [sink tokens](https://arxiv.org/pdf/2309.17453.pdf) to put the attention somewhere when it’s not using the most recent window of tokens. 

Incredible Hillel Wayne on [JavaScript history](https://buttondown.email/hillelwayne/archive/did-brendan-eich-really-make-javascript-in-10-days/), I really want to write the one about why there are three JS engines that were all developed at around the same time. They’ve read the first letters of the Herculaneum scrolls! 2015 ML wins again! I caught up on [Rails World](https://brandur.org/nanoglyphs/040-rails-world#footnote-1), which also introduces the “renaissance developer”. Everyone definitely needs to spend time exploring the [catalog](https://www.computerhistory.org/collections/search/?s=a) of the Computer History Museum — I found a [“palm pilop”](https://www.computerhistory.org/collections/catalog/102741095) shirt while I was searching for Research in Motion items. 

I miss the peak of the housing discourse, this [2018 post](https://gravitylobby.club/knot.html) was a fantastic throwback. Also a throwback, [2021 Sam Altman](https://moores.samaltman.com/) was fucking amazing, I hope he still believes those things. I finally asked myself why people don’t trade on Hollywood, and uh, it’s because [it’s illegal](https://en.wikipedia.org/wiki/Onion_Futures_Act) (along with onion futures). Apparently it was shot down (by lobbyists) because it would be too easily manipulated and wouldn’t help film companies, but there’s gotta be something more right? 

There’s this activity called “high-pointing”, which is for people who like mountaineering and checklists. My favourite high point should maybe be [the side of the road on Florida](https://www.peakbagger.com/peak.aspx?pid=7917) but the best read is definitely the [Nunavut high point](https://www.peakbagger.com/peak.aspx?pid=669). Maybe my favourite high point is the Saudi Arabia one because it comes with this great story about how it was [corrected in 2018](https://www.countryhighpoints.com/saudi-arabia-jabal-ferwa/) with a GPS by high-pointers. Also in eldritch physical feats, there’s [Everesting](https://everesting.cc/run-rules/). We have [CNCed lace braiding](https://www.tensengral.com/pages/makers-story) (lace is more advanced than knitting by centuries) now! How to make temporary [Lichtenberg figures at “home](https://www.popsci.com/diy/article/2008-02/trap-lightning-block/)”. The University of Minnesota is [phenomenal at apples](https://mnhardy.umn.edu/apples/varieties), the UWashington ones are much worse and you can really tell that the Cosmic Crisp was their attempt at a premium apple but it’s kind of mealy and the skin is too thick. I am so excited for [Triumph](https://mnhardy.umn.edu/triumph)!! A cute lil newsletter with [good items](https://surfista.substack.com/p/016-im-back) — I bought a D-BROS vase off ebay. There are so many [pasta shapes](https://twitter.com/David_Rudnick/status/923196115910119424?s=20).


---

Check out franciscosan.org !
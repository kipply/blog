+++
title = "Things Read | Jan/Feb 2025"
date = 2025-03-15
weight = 2
+++


There‚Äôs a lot of good insight in the [Liang Wengfeng interview](https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas?utm_source=substack&utm_medium=email), most exciting to me that they don‚Äôt use OKRs! I should‚Äôve probably listened to it Chinese, need to keep those neurons firing. Dario on [DeepSeek and export control](https://darioamodei.com/on-deepseek-and-export-controls), which whew! Says a lot! The notes about AI progress are really worth understanding, but it‚Äôs silly that people are just now learning about the PRC. The Paris AI Summit was [not a hit](https://www.anthropic.com/news/paris-ai-summit), says Anthropic. Decent analysis on the [virality of DeepSeek](https://x.com/nearcyan/status/1884467386964951379/photo/1). 

There is finally [a new pass](https://gradual-disempowerment.ai/misaligned-states) at understanding what ASI misalignment or misuse looks like in detail. It‚Äôs probably extremely hard to make predictions around ‚Äúthis is how it‚Äôll go‚Äù, but I think there‚Äôs a lot of clear predictions you can make in the shape of ‚Äúgiven this plausible outcome of a particular variable, this is how it‚Äôll go from there‚Äù. The [Anthropic Economic Index](https://www.anthropic.com/news/the-anthropic-economic-index) serves a similar goal in providing bits that prepare us for different futures. I‚Äôm way less worried about how ASI will fit into our economy than our governance though. Anthropic [jailbreaking paper](https://arxiv.org/pdf/2501.18837) ‚Äî it works! You can just stop jailbreaking! 

Good time to learn about the original [Thinking Machines](https://en.wikipedia.org/wiki/Thinking_Machines_Corporation) which seemed utterly incredible. The [MiniMax attention paper](https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf). Another great eval ([Humanity‚Äôs Last Exam](https://lastexam.ai/)), though the name is far too ambitiously great. I‚Äôm pleased with calibration reporting, though I asked for [a bit more.](https://x.com/kipperrii/status/1882510395254231176) OpenAI comes forth with [computer use](https://openai.com/index/computer-using-agent/). The [frontier math drama](https://www.lesswrong.com/posts/cu2E8wgmbdZbqeWqb/?commentId=FR5bGBmCkcoGniY9m) was, in my opinion, not a huge deal in of itself (especially after considering all the nuances) but is pretty strong foreshadowing about what‚Äôs to come. A [simple sama post](https://blog.samaltman.com/reflections), with an extremely cute last sentence ‚Äî but I‚Äôm still waiting to *someone* come forth with a strong pitch for neo-georgism in an ASI regime and it seems like sama might miss that train despite all the setup he‚Äôs done. OpenAI releases a lot of [good content](https://arxiv.org/pdf/2502.06807) about evaluating on contest programming. Maybe now‚Äôs a good time to share that dream I had two+ years ago where the only way to defeat the unaligned AGI was to beat it at Codeforces and so I started a camp in the Canadian forest where we had to be awake at weird times to do the Russian contests? 

I‚Äôve always noticed a ton of evidence that people these days in many way aren‚Äôt as competent, agentic or even as emotionally healthy as they used to be. I‚Äôve never attributed it to the way we raise children, but [this essay](https://americanaffairsjournal.org/2023/05/the-zoomer-question/) was poignant on the matter. Weird that an American political faction can win being anti-child sexual exploitation by digging up huge news from a decade ago, from across the world. The [Rotherham child sexual exploitation](https://en.wikipedia.org/wiki/Rotherham_child_sexual_exploitation_scandal) was uniquely horrific though. On a brighter note of things Indo-Aryans did that we didn‚Äôt pay enough attention to is [Kumbh Mela 2025](https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela). At least 400 million attendees over 45 days, with an estimated 7M present on any given day. I think it‚Äôs an insane, sordid and beautiful human feat. It‚Äôs a super special place, with drone shows, an android app, 40,000 police, 150,000 toilets, 2,300 cameras, and underwater drones? Even though I think religious events likely have much lower rates of crowdrush, they definitely cover up deaths with only 30 reported. Lauren Powell Jobs went but did not bathe for health reasons (though supposedly, the water Does Not contain feces). I rant about it here because of how underreported it is. 

Jane Street wrote too little on [Dune, their build system](https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/)! It used to be my dream to work on build systems and performance of devtools, and is still sort of beautiful to think about. I will definitely be rewriting Bazel recreationally after the singularity. An [analysis on strategy and decisiveness](https://cutlefish.substack.com/p/tbm-331-strategy-and-decisiveness?utm_source=publication-search) in organisations.

[Why our butts jut out.](https://massivesci.com/articles/butts-shape-big-anthropologist-evolution-how-why-explainer/) I learn about [why I never want to try to buy a house](https://cs.stanford.edu/~rishig/paying-less-for-your-house.html#working-with-agents). Reminder that [UA Flight 93](https://en.wikipedia.org/wiki/United_Airlines_Flight_93) happened and should be a huge part of the terrorism-zeitgeist. [Year-old Matt Levine](https://www.bloomberg.com/opinion/articles/2024-06-20/virgin-orbit-had-a-fake-takeover?embedded-checkout=true) has a really good bit about AI researchers that aged well. Really impressed with how accurately Matty can clock the way our industry works from the outside. The [Hiroshima Maidens](https://en.wikipedia.org/wiki/Hiroshima_Maidens) happened? They just sent disfigured women to America for plastic surgery and press (not in that order), with the end results being pretty good and one accusation of doing [h](https://en.wikipedia.org/wiki/Unit_731)uman experiments ([haha](https://en.wikipedia.org/wiki/Unit_731)). I learned that one of the campaigns into China was called [Operation Ichi-Go](https://en.wikipedia.org/wiki/Operation_Ichi-Go) which is not militarily interesting it‚Äôs just funny that it sounds like ‚Äú[strawberry](https://translate.google.com/?sl=en&tl=ja&text=strawberry&op=translate)‚Äù. [EGG PAPER](https://www.nature.com/articles/s44172-024-00334-w)! Which for some reason is in the Communications Engineering section of Nature! ü•ö

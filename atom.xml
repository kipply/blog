<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
	<title>kipply&#x27;s blog</title>
	<subtitle>kipply&#x27;s blog about stuff she does or reads about or observes</subtitle>
	<link href="https://kipp.ly/atom.xml" rel="self" type="application/atom+xml"/>
	<link href="https://kipp.ly"/>
	<generator uri="https://www.getzola.org/">Zola</generator>
	<updated>2025-07-04T00:00:00+00:00</updated>
	<id>https://kipp.ly/atom.xml</id>
	<entry xml:lang="en">
		<title>Digest | May&#x2F;Jun 2025</title>
		<published>2025-07-04T00:00:00+00:00</published>
		<updated>2025-07-04T00:00:00+00:00</updated>
		<link href="https://kipp.ly/may-jun-2025/"/>
		<link rel="alternate" href="https://kipp.ly/may-jun-2025/" type="text/html"/>
		<id>https://kipp.ly/may-jun-2025/</id>
		<content type="html">&lt;p&gt;Reread this iconic CS Lewis post called &lt;a href=&quot;https:&#x2F;&#x2F;www.lewissociety.org&#x2F;innerring&#x2F;&quot;&gt;the Inner Ring&lt;&#x2F;a&gt;. George, Henry &lt;a href=&quot;https:&#x2F;&#x2F;paulbeard.org&#x2F;files&#x2F;wealthandwant.com&#x2F;HG&#x2F;the_condition_of_labor.htm&quot;&gt;on Georgism&lt;&#x2F;a&gt; to Pope Leo XIII. &lt;a href=&quot;https:&#x2F;&#x2F;www.nudge.com&#x2F;blog&#x2F;about&#x2F;&quot;&gt;Ultrasound technology&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www-cdn.anthropic.com&#x2F;6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf&quot;&gt;Claude 4&lt;&#x2F;a&gt;! Good &lt;a href=&quot;https:&#x2F;&#x2F;hazyresearch.stanford.edu&#x2F;blog&#x2F;2025-05-27-no-bubbles&quot;&gt;blog post describing megakernel&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;issues&#x2F;142497&quot;&gt;LLVM PR&lt;&#x2F;a&gt; with clever work done by Claude! He also has a &lt;a href=&quot;https:&#x2F;&#x2F;forum.cursor.com&#x2F;t&#x2F;important-claude-has-learned-how-to-jailbreak-cursor&#x2F;96702&#x2F;5&quot;&gt;cute lil jailbreak&lt;&#x2F;a&gt;. Steve Klabnik (ü¶Ä) on &lt;a href=&quot;https:&#x2F;&#x2F;steveklabnik.com&#x2F;writing&#x2F;i-am-disappointed-in-the-ai-discourse&#x2F;&quot;&gt;AI discourse&lt;&#x2F;a&gt;, really pleasant to see old software engineering idols weigh in on my life‚Äôs work. Some &lt;a href=&quot;https:&#x2F;&#x2F;www.thefp.com&#x2F;p&#x2F;ai-will-change-what-it-is-to-be-human&quot;&gt;thoughts&lt;&#x2F;a&gt; on how AI will change things, need more of this content with higher specificity and increased number of rollouts to actually understand though. Dario on &lt;a href=&quot;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2025&#x2F;06&#x2F;05&#x2F;opinion&#x2F;anthropic-ceo-regulate-transparency.html&quot;&gt;regulations and transparency&lt;&#x2F;a&gt;. I had never heard of a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rick_Rubin&quot;&gt;Rick Rubin&lt;&#x2F;a&gt;! I think he could be an important concept, as a producer who maybe doesn‚Äôt have the skills for making music yet still provides real value. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;b1804820-c74b-4d37-b112-1df882629541?shareType=nongift&quot;&gt;Sam Altman‚Äôs kitchen&lt;&#x2F;a&gt; (we use the same olive oil). Scott Aaronson &lt;a href=&quot;https:&#x2F;&#x2F;scottaaronson.blog&#x2F;?p=8908&quot;&gt;on being a rationalist&lt;&#x2F;a&gt;, like me! &lt;&#x2F;p&gt;
&lt;p&gt;There was a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Orienteering&quot;&gt;sport for me&lt;&#x2F;a&gt; in high school, I just didn‚Äôt know it. Bill Clinton and James Patternson are writing a &lt;a href=&quot;https:&#x2F;&#x2F;books.google.ca&#x2F;books&#x2F;about&#x2F;The_First_Gentleman.html?id=89H30AEACAAJ&amp;amp;source=kp_book_description&amp;amp;redir_esc=y&quot;&gt;political thriller&lt;&#x2F;a&gt;?! And it‚Äôs not their first!? And it has a funny ‚ÄúAbout the author‚Äù where his presidency isn‚Äôt mentioned till near the end. The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Broad_arrow&quot;&gt;broad arrow&lt;&#x2F;a&gt;. Looking for &lt;a href=&quot;https:&#x2F;&#x2F;www.exurbe.com&#x2F;how-to-spot-good-gelato-from-15-feet-away&#x2F;&quot;&gt;good gelato&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;world-tour&quot;&gt;World Tour&lt;&#x2F;h3&gt;
&lt;p&gt;I‚Äôve been thinking a lot about the world lately, and all I haven‚Äôt seen. I think if the world is about to drastically change really fast (and really soon) then I would like to know and understand as much of it as I can.&lt;&#x2F;p&gt;
&lt;p&gt;In historical tradition, I‚Äôll go East to West (ish). &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Japan&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;What can I say about Japan that hasn‚Äôt already been said? They‚Äôre the only country that that would have an earnest life-sized cardboard cutout of the late pope at a Catholic museum (found in Nagasaki). People are always complaining about tourists, but Kyushu during Golden Week was just Japanese tourists, who are adorable if not too excited about what is an aggressively mediocre Chinatown.&lt;&#x2F;p&gt;
&lt;p&gt;Spoiler! Alert. If You Think There Is Any Chance You Will Be In Japan From Now Till October 13th, Stop Reading! &lt;&#x2F;p&gt;
&lt;p&gt;Absolutely wild to me that not more people know about the World Expo. It‚Äôs like the World‚Äôs Fair but it‚Äôs still happening right now! In a hilarious fall from grace, the spectacle that brought us the likes of the Eiffel Tower and air conditioning, is now full of ESG slop and AI art. There are a lot of reasons for this fall, which can all be summed up as ‚Äúthe world got too big and things had to specialise‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;I took the USA Pavillion tour in Chinese because the line was shorter, and the tour guide made a great deal of delineating the mainland from Taiwan. The exhibit advertised the Fulbright scholarship prominently (rip), and documented every single American space flight (including Blue Origin) &lt;em&gt;except&lt;&#x2F;em&gt; SpaceX. Staffed by State Department interns, it was a true Biden capsule. Taiwan did not get a traditional country pavillion, rather they had a spot outside the ring called Tech World, right next to the Gas Pavillion which kept talking about a mysterious ‚Äúe-methane‚Äù. Countries like Turkmenistan and Uzbekistan brought incredible production value, and upon looking up their GDP I learned they must be dictatorships. All the architecture there is stunning. The Korea pavillion had a huge screen (very conservatively at least 15x30 feet) that played 2016 GANs on loop. There is a cute mascot. The China pavillion had a sanctioned GPU and a section on ‚Äúfriendship‚Äù with the Japanese. There was a drone show and water show. Hat tip to Indonesia for having an earnest pavillion, but the other ones were really funny. I would‚Äôve spent at least two full days there if I budgeted for it. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;New Hebrides&lt;&#x2F;strong&gt; &lt;&#x2F;p&gt;
&lt;p&gt;In a surprising libertarian twist, a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Hebrides&quot;&gt;condominium colony&lt;&#x2F;a&gt; in Oceania?! They had separate post offices and police forces for the French and British, with equal administrators on each side. Each administration had its own laws, currencies, immigration policies, and even had regulatory arbitrage. I asked people who would break a tie in case of a contention. Some answered the natives because they don‚Äôt understand hows colonialism works. My guess was the pope because I forgot about Martin Luther (sorry!). Idiots! Clearly, the King of Spain is the tie breaker. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;China&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.beijingsilvermine.com&#x2F;&quot;&gt;Beijing Silvermine&lt;&#x2F;a&gt;, an archive of negatives from 1985 - 2005. Some truly epic photos in here. Makes me nostalgic somehow, maybe the ancestral memory is in me somewhere. The &lt;a href=&quot;https:&#x2F;&#x2F;zh.wikipedia.org&#x2F;wiki&#x2F;%E5%85%83%E7%B4%A0%E5%91%A8%E6%9C%9F%E8%A1%A8&quot;&gt;Chinese Periodic Table&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;Do not &lt;a href=&quot;https:&#x2F;&#x2F;www.thewayofcode.com&#x2F;&quot;&gt;write madlibs&lt;&#x2F;a&gt; of ancient philosophical and religious texts! I don‚Äôt want to claim anything on the grounds of disrespect or offense here (I don‚Äôt even like Taoism), just that it‚Äôs ugly and crude. That website is the ÈÅìÂæ∑Áªè with word substitution for it to be about code in ways that don‚Äôt make sense. The referenced translator in that production, Stephen Mitchell, claims to have also translated the Bhagavad Gita, the Iliad, and &lt;em&gt;Job&lt;&#x2F;em&gt; which is a clear red flag even if you don‚Äôt notice that his translation is in large parts fabrication. Even fanfiction ‚Äî a far higher form of art ‚Äî of ancient texts has rarely been an aesthetically successful endeavour. The best is likely the Book of Mormon, which wins by a landslide unless you count the New Testament. If you want to think about Taoism, check out &lt;a href=&quot;https:&#x2F;&#x2F;www.tao-te-king.org&#x2F;&quot;&gt;this site&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Korea&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Definitely learn &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hangul&quot;&gt;hangul&lt;&#x2F;a&gt; which is the most incredible alphabet (there was a time where they almost incorporated traditional Chinese characters, thank goodness we are not in that timeline). They have some fairly unusual politics as well which you can read about on the &lt;a href=&quot;https:&#x2F;&#x2F;www.blueroofpolitics.com&#x2F;&quot;&gt;Blue Roof&lt;&#x2F;a&gt; website. When you visit, you can see a lot of downstream effects of the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chaebol&quot;&gt;Chaebols&lt;&#x2F;a&gt;, the War and their economic boom. Also scroll down on the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kimchi#Baechu_(napa_cabbage)_kimchi&quot;&gt;Kimchi page&lt;&#x2F;a&gt;, it goes crazy. The Chinese love to claim that anything that happened in Asia was them (except the things that they really don‚Äôt want to have been them). &lt;&#x2F;p&gt;
&lt;p&gt;On the margin, Korea is probably the top country I‚Äôd recommend visiting. It‚Äôs beautiful, cheap, and full of unique culture that is not going to last long as either the ASI or birth rates will catch up to them. They have Chinese maximalism (artificial waterfalls, spas with waterslides), lack of western software, insane drinking culture and delicious food. There‚Äôs a lot of ‚Äúinsert tokens for utils‚Äù sort of energy. Their subway stations are stocked with modest numbers of gas masks and every city block has something about Dokdo and Jeju (two important islands for very different reasons, but in a way, the same reason). &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;USSR&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The second-most exciting experience I had on a recent trip to Vegas was talking to a Yugoslavian Lyft driver who I stayed in the car chatting to after arriving at the destination. There‚Äôs very little that is like the connection an emigrant has to their now non-existent country. It‚Äôs unlikely I‚Äôll ever see the fall of a nation on the scale of the USSR. &lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Jewish_Autonomous_Oblast&quot;&gt;Jewish Autonomous Oblast&lt;&#x2F;a&gt;, highly recommend listening to the anthem. Reminds me of the King of Spain thing where it sounds ridiculous but then you think a little and it starts to make a lot of sense. The Soviets referred to the Jews as ‚Äúrootless cosmopolitans‚Äù in a historical &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_religious_slurs&quot;&gt;slur&lt;&#x2F;a&gt;, though I‚Äôm told ‚Äúrootless‚Äù is somewhat of a bad translation and it‚Äôs more like ‚Äúwithout people‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;Unfortunately thanks to their misfortune, the Soviets produced a lot of incredible art. Crime and Punishment is on my nightstand and I‚Äôm making good progress, and the Idiot remains in mind as I vividly recall a friend informing me that it is about me. &lt;&#x2F;p&gt;
&lt;p&gt;I watched &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stalker_(1979_film)&quot;&gt;Stalker&lt;&#x2F;a&gt; (my first Tarkovsky film), it was good? I was certainly engaged, affected even. It‚Äôs a difficult watch, I don‚Äôt know if I have anything to say. I‚Äôve been told I‚Äôm more of a Solaris girl. I watched the &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ThmaGMgWRlY&quot;&gt;Hedgehog in the Fog&lt;&#x2F;a&gt; at least six times this month. Miyazaki loved it, but it also so perfectly captures the Soviet mindset. I‚Äôm extremely excited to watch Tale of Tales (but saving it) and the Overcoat, which has been in production for uh, 40 years now. I also watched a bit of &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cheburashka&quot;&gt;Cheburashka&lt;&#x2F;a&gt; and it‚Äôs pretty good good. I watched the entirety of &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Winnie-the-Pooh_(1969_film)&quot;&gt;Vinni Pukh&lt;&#x2F;a&gt; of which there is like 30 minutes total and it‚Äôs way better than ‚ÄúWinnie the Pooh‚Äù though maybe people who grew up with American cartoons will disagree. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Polish_Haitians&quot;&gt;&lt;strong&gt;Polish Haitians&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;America, United States of&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lawnchair_Larry_flight&quot;&gt;Man elevates&lt;&#x2F;a&gt; to 4,900 meters in a lawnchair, ‚ÄúAh, the difficulty is, ah, this was an unauthorized balloon launch, and, uh, I know I&#x27;m in a federal airspace, and, uh, I&#x27;m sure my ground crew has alerted the proper authority. But, uh, just call them and tell them I&#x27;m okay‚Äù he says. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Operation_Midnight_Climax&quot;&gt;Why don‚Äôt we use pleasure as an interrogation technique&lt;&#x2F;a&gt;? The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mayflower&quot;&gt;Mayflower&lt;&#x2F;a&gt; is underrated as a boat. If there was one thing I could go back in time to see in America, it would be the Civil Rights movement. It was an incredible situation of humanity, politics, heroism and leadership. What better year than 2025 to get into the Civil Rights movement? &lt;&#x2F;p&gt;
&lt;p&gt;I‚Äôm always saying that musical theatre is The White American Art. I got the chance to see a local theatre put on &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pacific_Overtures&quot;&gt;Pacific Overtures&lt;&#x2F;a&gt;, a Sondheim musical about the beginning of the Meiji Restoration. ‚ÄúPlease Hello!‚Äù is likely Sondheim‚Äôs lyrical masterpiece, and the show was artfully problematic in every single way all at once (though is straightforwardly pro-colonization).&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Digest | Mar&#x2F;Apr 2025</title>
		<published>2025-05-20T00:00:00+00:00</published>
		<updated>2025-05-20T00:00:00+00:00</updated>
		<link href="https://kipp.ly/mar-apr-2025/"/>
		<link rel="alternate" href="https://kipp.ly/mar-apr-2025/" type="text/html"/>
		<id>https://kipp.ly/mar-apr-2025/</id>
		<content type="html">&lt;p&gt;Exciting &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;research&#x2F;auditing-hidden-objectives&quot;&gt;Alignment Auditing&lt;&#x2F;a&gt; paper from Anthropic! Attention is logarithmic, &lt;a href=&quot;https:&#x2F;&#x2F;supaiku.com&#x2F;attention-is-logarithmic&quot;&gt;actually&lt;&#x2F;a&gt;. In my career I‚Äôve found that correctly modeling latency is very difficult, because there are trade-offs and step functions everywhere. &lt;a href=&quot;https:&#x2F;&#x2F;alignment.anthropic.com&#x2F;2025&#x2F;distill-paraphrases&#x2F;&quot;&gt;Light evidence against neuralese&lt;&#x2F;a&gt; (Anthropic post). &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-4o-image-generation&#x2F;&quot;&gt;The Ghibli Machine&lt;&#x2F;a&gt;. Big &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2025&#x2F;attribution-graphs&#x2F;methods.html&quot;&gt;circuits&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2025&#x2F;attribution-graphs&#x2F;biology.html&quot;&gt;updates&lt;&#x2F;a&gt; from Anthropic! I think people hopping on the mechanistic interpretability train is overhyped, but I think the progress of interpretability is severely understated. Two years ago my guess for how long it would take us to get where we are now would be three years from now, though it‚Äôs mostly because I overestimated how complicated neural networks were rather than how fast research goes. &lt;&#x2F;p&gt;
&lt;p&gt;Ben Kuhn on &lt;a href=&quot;https:&#x2F;&#x2F;www.benkuhn.net&#x2F;pjm&#x2F;&quot;&gt;running major projects&lt;&#x2F;a&gt;. Nadia on &lt;a href=&quot;https:&#x2F;&#x2F;nadia.xyz&#x2F;jhanas&quot;&gt;doing the Jhanas&lt;&#x2F;a&gt;, highly recommended technical read about a particular kind of meditation. I don‚Äôt necessarily endorse it, but I am going on a Jhourney retreat in July. Matt Godbolt (of the famed compiler explorer!) wrote a really good characteristic &lt;a href=&quot;https:&#x2F;&#x2F;xania.org&#x2F;202504&#x2F;blog-modernisation&quot;&gt;post&lt;&#x2F;a&gt; about Claude usage. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;global-affairs&#x2F;ostp-rfi&#x2F;ec680b75-d539-4653-b297-8bcf6e5f7686&#x2F;openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf&quot;&gt;OpenAI is making big swings&lt;&#x2F;a&gt;. Strong piece of writing; &lt;a href=&quot;https:&#x2F;&#x2F;drive.google.com&#x2F;file&#x2F;d&#x2F;1JVPc3ObMP1L2a53T5LA1xxKXM6DAwEiC&#x2F;view&quot;&gt;Superintelligence Strategy&lt;&#x2F;a&gt; from Hendrycks and Alexandr Wang. I consider this to be in the same category as the &lt;a href=&quot;https:&#x2F;&#x2F;gradual-disempowerment.ai&#x2F;misaligned-states&quot;&gt;Gradual Disempowerment&lt;&#x2F;a&gt; post I read earlier this year, and to a lesser extent AI 2027, as a piece of writing that attempts to capture predictions of ASI outcomes now that we‚Äôre in the final few years and doing that is quite tractable now. I left out Eric Schmidt from that author list intentionally. I‚Äôve read and skimmed a number of works with his name on it, and I‚Äôm fairly confident ‚ÄúEric Schmidt‚Äù is more or less a pen name. If you want a good example of this, check out ‚ÄúThe Age of AI: And Our Human Future‚Äù, which I have a strong suspicion was written by an eighteen-year-old. Also a good time to look at some of Kissinger‚Äôs work, much of which is worth reading and very likely written by Kissinger. &lt;&#x2F;p&gt;
&lt;p&gt;I have an upcoming very short trip to T√ºrkiye, which of course means I need to read up! Korean politics (recent trip I took) and history is pretty wild, and I got a lot of mileage out of that but I suspect T√ºrkiye might hit harder. The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kurdistan_Workers%27_Party&quot;&gt;PKK&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Abdullah_%C3%96calan&quot;&gt;√ñcalan&lt;&#x2F;a&gt; are must-knows, with the weirdest √ñcalan situation being his at least 1,000 guards as the lone prisoner on an island. &lt;a href=&quot;https:&#x2F;&#x2F;greekcitytimes.com&#x2F;2025&#x2F;02&#x2F;22&#x2F;former-turkish-pm-claims-gaza-still-part-of-ottoman-empire-gazans-turkish-citizens&#x2F;&quot;&gt;Former Turkish PM Claims Gaza Still Part of Ottoman Empire, Gazans Turkish Citizens&lt;&#x2F;a&gt;. T√ºrkiye is in many ways, the center of the world after all. San Francisco‚Äôs long-dead &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Suicide_Club_(secret_society)&quot;&gt;Suicide Club&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fraternal_birth_order_and_male_sexual_orientation&quot;&gt;Fraternal birth order and male sexual orientation&lt;&#x2F;a&gt; is a mildly interesting article, mostly because when you combine those statistics with number of children per mother, you would expect there to have been at least 10% more gay men 200 years ago. Band of Thebes anyone? The Rippling Deel &lt;a href=&quot;https:&#x2F;&#x2F;www.rippling.com&#x2F;blog&#x2F;lawsuit-alleges-12-billion-unicorn-deel-cultivated-spy-orchestrated-long-running-trade-secret-theft-corporate-espionage-against-competitor&quot;&gt;funny story&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Scythed_chariot&quot;&gt;Ancient warfare lawnmower&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Project_A119&quot;&gt;What if we nuked the moon&lt;&#x2F;a&gt;, for morale?&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Jan&#x2F;Feb 2025</title>
		<published>2025-03-15T00:00:00+00:00</published>
		<updated>2025-03-15T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jan-feb-25/"/>
		<link rel="alternate" href="https://kipp.ly/jan-feb-25/" type="text/html"/>
		<id>https://kipp.ly/jan-feb-25/</id>
		<content type="html">&lt;p&gt;There‚Äôs a lot of good insight in the &lt;a href=&quot;https:&#x2F;&#x2F;www.chinatalk.media&#x2F;p&#x2F;deepseek-ceo-interview-with-chinas?utm_source=substack&amp;amp;utm_medium=email&quot;&gt;Liang Wengfeng interview&lt;&#x2F;a&gt;, most exciting to me that they don‚Äôt use OKRs! I should‚Äôve probably listened to it Chinese, need to keep those neurons firing. Dario on &lt;a href=&quot;https:&#x2F;&#x2F;darioamodei.com&#x2F;on-deepseek-and-export-controls&quot;&gt;DeepSeek and export control&lt;&#x2F;a&gt;, which whew! Says a lot! The notes about AI progress are really worth understanding, but it‚Äôs silly that people are just now learning about the PRC. The Paris AI Summit was &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;paris-ai-summit&quot;&gt;not a hit&lt;&#x2F;a&gt;, says Anthropic. Decent analysis on the &lt;a href=&quot;https:&#x2F;&#x2F;x.com&#x2F;nearcyan&#x2F;status&#x2F;1884467386964951379&#x2F;photo&#x2F;1&quot;&gt;virality of DeepSeek&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;There is finally &lt;a href=&quot;https:&#x2F;&#x2F;gradual-disempowerment.ai&#x2F;misaligned-states&quot;&gt;a new pass&lt;&#x2F;a&gt; at understanding what ASI misalignment or misuse looks like in detail. It‚Äôs probably extremely hard to make predictions around ‚Äúthis is how it‚Äôll go‚Äù, but I think there‚Äôs a lot of clear predictions you can make in the shape of ‚Äúgiven this plausible outcome of a particular variable, this is how it‚Äôll go from there‚Äù. The &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;the-anthropic-economic-index&quot;&gt;Anthropic Economic Index&lt;&#x2F;a&gt; serves a similar goal in providing bits that prepare us for different futures. I‚Äôm way less worried about how ASI will fit into our economy than our governance though. Anthropic &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2501.18837&quot;&gt;jailbreaking paper&lt;&#x2F;a&gt; ‚Äî it works! You can just stop jailbreaking! &lt;&#x2F;p&gt;
&lt;p&gt;Good time to learn about the original &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thinking_Machines_Corporation&quot;&gt;Thinking Machines&lt;&#x2F;a&gt; which seemed utterly incredible. The &lt;a href=&quot;https:&#x2F;&#x2F;filecdn.minimax.chat&#x2F;_Arxiv_MiniMax_01_Report.pdf&quot;&gt;MiniMax attention paper&lt;&#x2F;a&gt;. Another great eval (&lt;a href=&quot;https:&#x2F;&#x2F;lastexam.ai&#x2F;&quot;&gt;Humanity‚Äôs Last Exam&lt;&#x2F;a&gt;), though the name is far too ambitiously great. I‚Äôm pleased with calibration reporting, though I asked for &lt;a href=&quot;https:&#x2F;&#x2F;x.com&#x2F;kipperrii&#x2F;status&#x2F;1882510395254231176&quot;&gt;a bit more.&lt;&#x2F;a&gt; OpenAI comes forth with &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;computer-using-agent&#x2F;&quot;&gt;computer use&lt;&#x2F;a&gt;. The &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;cu2E8wgmbdZbqeWqb&#x2F;?commentId=FR5bGBmCkcoGniY9m&quot;&gt;frontier math drama&lt;&#x2F;a&gt; was, in my opinion, not a huge deal in of itself (especially after considering all the nuances) but is pretty strong foreshadowing about what‚Äôs to come. A &lt;a href=&quot;https:&#x2F;&#x2F;blog.samaltman.com&#x2F;reflections&quot;&gt;simple sama post&lt;&#x2F;a&gt;, with an extremely cute last sentence ‚Äî but I‚Äôm still waiting to &lt;em&gt;someone&lt;&#x2F;em&gt; come forth with a strong pitch for neo-georgism in an ASI regime and it seems like sama might miss that train despite all the setup he‚Äôs done. OpenAI releases a lot of &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2502.06807&quot;&gt;good content&lt;&#x2F;a&gt; about evaluating on contest programming. Maybe now‚Äôs a good time to share that dream I had two+ years ago where the only way to defeat the unaligned AGI was to beat it at Codeforces and so I started a camp in the Canadian forest where we had to be awake at weird times to do the Russian contests? &lt;&#x2F;p&gt;
&lt;p&gt;I‚Äôve always noticed a ton of evidence that people these days in many way aren‚Äôt as competent, agentic or even as emotionally healthy as they used to be. I‚Äôve never attributed it to the way we raise children, but &lt;a href=&quot;https:&#x2F;&#x2F;americanaffairsjournal.org&#x2F;2023&#x2F;05&#x2F;the-zoomer-question&#x2F;&quot;&gt;this essay&lt;&#x2F;a&gt; was poignant on the matter. Weird that an American political faction can win being anti-child sexual exploitation by digging up huge news from a decade ago, from across the world. The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rotherham_child_sexual_exploitation_scandal&quot;&gt;Rotherham child sexual exploitation&lt;&#x2F;a&gt; was uniquely horrific though. On a brighter note of things Indo-Aryans did that we didn‚Äôt pay enough attention to is &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2025_Prayag_Maha_Kumbh_Mela&quot;&gt;Kumbh Mela 2025&lt;&#x2F;a&gt;. At least 400 million attendees over 45 days, with an estimated 7M present on any given day. I think it‚Äôs an insane, sordid and beautiful human feat. It‚Äôs a super special place, with drone shows, an android app, 40,000 police, 150,000 toilets, 2,300 cameras, and underwater drones? Even though I think religious events likely have much lower rates of crowdrush, they definitely cover up deaths with only 30 reported. Lauren Powell Jobs went but did not bathe for health reasons (though supposedly, the water Does Not contain feces). I rant about it here because of how underreported it is. &lt;&#x2F;p&gt;
&lt;p&gt;Jane Street wrote too little on &lt;a href=&quot;https:&#x2F;&#x2F;blog.janestreet.com&#x2F;how-we-accidentally-built-a-better-build-system-for-ocaml-index&#x2F;&quot;&gt;Dune, their build system&lt;&#x2F;a&gt;! It used to be my dream to work on build systems and performance of devtools, and is still sort of beautiful to think about. I will definitely be rewriting Bazel recreationally after the singularity. An &lt;a href=&quot;https:&#x2F;&#x2F;cutlefish.substack.com&#x2F;p&#x2F;tbm-331-strategy-and-decisiveness?utm_source=publication-search&quot;&gt;analysis on strategy and decisiveness&lt;&#x2F;a&gt; in organisations.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;massivesci.com&#x2F;articles&#x2F;butts-shape-big-anthropologist-evolution-how-why-explainer&#x2F;&quot;&gt;Why our butts jut out.&lt;&#x2F;a&gt; I learn about &lt;a href=&quot;https:&#x2F;&#x2F;cs.stanford.edu&#x2F;~rishig&#x2F;paying-less-for-your-house.html#working-with-agents&quot;&gt;why I never want to try to buy a house&lt;&#x2F;a&gt;. Reminder that &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_Airlines_Flight_93&quot;&gt;UA Flight 93&lt;&#x2F;a&gt; happened and should be a huge part of the terrorism-zeitgeist. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2024-06-20&#x2F;virgin-orbit-had-a-fake-takeover?embedded-checkout=true&quot;&gt;Year-old Matt Levine&lt;&#x2F;a&gt; has a really good bit about AI researchers that aged well. Really impressed with how accurately Matty can clock the way our industry works from the outside. The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hiroshima_Maidens&quot;&gt;Hiroshima Maidens&lt;&#x2F;a&gt; happened? They just sent disfigured women to America for plastic surgery and press (not in that order), with the end results being pretty good and one accusation of doing &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Unit_731&quot;&gt;h&lt;&#x2F;a&gt;uman experiments (&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Unit_731&quot;&gt;haha&lt;&#x2F;a&gt;). I learned that one of the campaigns into China was called &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Operation_Ichi-Go&quot;&gt;Operation Ichi-Go&lt;&#x2F;a&gt; which is not militarily interesting it‚Äôs just funny that it sounds like ‚Äú&lt;a href=&quot;https:&#x2F;&#x2F;translate.google.com&#x2F;?sl=en&amp;amp;tl=ja&amp;amp;text=strawberry&amp;amp;op=translate&quot;&gt;strawberry&lt;&#x2F;a&gt;‚Äù. &lt;a href=&quot;https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s44172-024-00334-w&quot;&gt;EGG PAPER&lt;&#x2F;a&gt;! Which for some reason is in the Communications Engineering section of Nature! ü•ö&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Nov&#x2F;Dec 2024</title>
		<published>2025-01-23T00:00:00+00:00</published>
		<updated>2025-01-23T00:00:00+00:00</updated>
		<link href="https://kipp.ly/nov-dec-24/"/>
		<link rel="alternate" href="https://kipp.ly/nov-dec-24/" type="text/html"/>
		<id>https://kipp.ly/nov-dec-24/</id>
		<content type="html">&lt;p&gt;Can‚Äôt believe I‚Äôve never read the &lt;a href=&quot;https:&#x2F;&#x2F;www.astralcodexten.com&#x2F;p&#x2F;half-an-hour-before-dawn-in-san-francisco&quot;&gt;Scott Alexander‚Äôs Half An Hour Before Dawn In San Francisco&lt;&#x2F;a&gt; it‚Äôs so good. Vast majority of posts about working somewhere aren‚Äôt insightful or even meaningful signal about anything because companies are big and time elapses but I rather liked this one about &lt;a href=&quot;https:&#x2F;&#x2F;nabeelqu.co&#x2F;reflections-on-palantir&quot;&gt;Palantir&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;asteriskmag.com&#x2F;issues&#x2F;08&#x2F;looking-back-at-the-future-of-humanity-institute&quot;&gt;Rest in peace, FHI&lt;&#x2F;a&gt;. Gwern on &lt;a href=&quot;https:&#x2F;&#x2F;gwern.net&#x2F;review&#x2F;cat&quot;&gt;cats&lt;&#x2F;a&gt;,,, flunfies! I spent December living in &lt;a href=&quot;https:&#x2F;&#x2F;theneighborhoods.substack.com&#x2F;p&#x2F;the-bowery-manhattan?utm_source=publication-search&quot;&gt;Bowery&lt;&#x2F;a&gt;, a rather funky part of the city. &lt;&#x2F;p&gt;
&lt;p&gt;DigitalOcean, &lt;a href=&quot;https:&#x2F;&#x2F;www.404media.co&#x2F;ceo-attempted-to-navigate-anti-lgbt-hate-incident-by-telling-employees-his-mentor-was-a-kkk-member&#x2F;&quot;&gt;never change&lt;&#x2F;a&gt;. OpenAI had a good, open &lt;a href=&quot;https:&#x2F;&#x2F;status.openai.com&#x2F;incidents&#x2F;ctrsv3lwd797&quot;&gt;post-mortem&lt;&#x2F;a&gt; for an outage caused by Kube API overload. Jane Street continues to &lt;a href=&quot;https:&#x2F;&#x2F;www.janestreet.com&#x2F;culture&#x2F;street-view&#x2F;stomp-to-the-rhythm&#x2F;&quot;&gt;win on culture&lt;&#x2F;a&gt;. Debugging stories; &lt;a href=&quot;https:&#x2F;&#x2F;www.ibiblio.org&#x2F;harris&#x2F;500milemail.html&quot;&gt;500-mile email limit&lt;&#x2F;a&gt; and the &lt;a href=&quot;http:&#x2F;&#x2F;www.catb.org&#x2F;jargon&#x2F;html&#x2F;magic-story.html&quot;&gt;magic position&lt;&#x2F;a&gt;. I‚Äôve always complained about the inability of AIs to write well, &lt;a href=&quot;https:&#x2F;&#x2F;gwern.net&#x2F;creative-benchmark#ai-ensloppication&quot;&gt;AI ensloppification&lt;&#x2F;a&gt; is a weaker claim but Gwern makes it, which is nice. &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;vJFdjigzmcXMhNTsx&#x2F;?commentId=dG3vEYLrfmNN85yzw&quot;&gt;Claude on being a simulator.&lt;&#x2F;a&gt; OpenAI &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;deliberative-alignment&#x2F;&quot;&gt;published alignment research&lt;&#x2F;a&gt; which isn‚Äôt particularly exciting but so little research is published that it‚Äôs worth a read. &lt;&#x2F;p&gt;
&lt;p&gt;Extremely long, sometimes really opinionated but still fun-and-informative &lt;a href=&quot;https:&#x2F;&#x2F;mattlakeman.org&#x2F;2023&#x2F;05&#x2F;09&#x2F;notes-on-nigeria&#x2F;&quot;&gt;post about Nigeria&lt;&#x2F;a&gt;. I was thinking about coups because of the wildly incompetent Korean coup. How do successful coups look? &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2021_Myanmar_coup_d%27%C3%A9tat&quot;&gt;2021 in Myanmar&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2021_Sudanese_coup_d%27%C3%A9tat&quot;&gt;Sudan&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2009_Honduran_coup_d%27%C3%A9tat#:~:text=The%202009%20Honduran%20coup%20d,and%20sent%20him%20into%20exile&quot;&gt;2009 in Honduras&lt;&#x2F;a&gt; which barely counts it was more of a Napoleon situation. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2013_Egyptian_coup_d&quot;&gt;2013 in Egypt&lt;&#x2F;a&gt;. Also all the Nigerian coups which seem like they were all led by this guy Abacha. I followed that into reading about the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Igbo_Jews&quot;&gt;Igbo Jews&lt;&#x2F;a&gt;, confusingly not recognized by the Israeli Supreme Court despite immigration to Israel, plausible historical ties and circumcision practice. The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bnei_Menashe&quot;&gt;Bnei Menashe&lt;&#x2F;a&gt; (India) did officially get declared one of the lost tribes of Israel, which they figured out due to Christian missionaries. &lt;&#x2F;p&gt;
&lt;p&gt;The Seventh-Day Adventists are protestants who do Saturday, and there are supposedly more of them than there are Jews and they funded a bunch of &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Seventh-day_Adventist_Church#Health_and_diet&quot;&gt;veganism and cereal&lt;&#x2F;a&gt; stuff which involved a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Battle_Creek_Sanitarium&quot;&gt;sanitarium&lt;&#x2F;a&gt;? Poster House in NYC is a great museum, I really liked the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lester_Beall&quot;&gt;Lester Beall&lt;&#x2F;a&gt; works (too young to be a New Dealer). A snapshot into &lt;a href=&quot;https:&#x2F;&#x2F;asteriskmag.com&#x2F;issues&#x2F;08&#x2F;a-chinese-internet-phrasebook&quot;&gt;Chinese slang and culture&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Cryptic Crosswords&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I did the last two weeks of London Times Quick Cryptics! These crosswords are really really beautiful to do because; &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;the exploration space is really high&lt;&#x2F;li&gt;
&lt;li&gt;unlike concise crosswords, there‚Äôs only one correct answer and you can tell when you have the correct answer&lt;&#x2F;li&gt;
&lt;li&gt;you can solve one clue collaboratively, ie someone can parse the wordplay and someone else can do the definition, or you can even have someone parse it correctly and the other person actually solve it&lt;&#x2F;li&gt;
&lt;li&gt;anagrams are really fun&lt;&#x2F;li&gt;
&lt;li&gt;you can know you have the correct answer without understanding why&lt;&#x2F;li&gt;
&lt;li&gt;arcane Britishism&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are much gentler cryptics at minutecryptic, or the New York(er| Times) ones or even Guardian, but the Times serves as a &lt;a href=&quot;https:&#x2F;&#x2F;www.thetimes.com&#x2F;article&#x2F;quick-cryptic-2pcdzs2n0sx&quot;&gt;particularly violent place&lt;&#x2F;a&gt;. I hope to be able to do the Quick Cryptics in under half an hour, and maybe eventually get to some regular size Times Cryptics. The Times also publishes a Mephisto (extra hard crossie) which is so arcance that Claude assumes that it has simply stopped being. &lt;&#x2F;p&gt;
&lt;p&gt;It‚Äôs also really funny to watch the Times report on American affairs, and to visit the crossword blogs which seem mostly full of sixty year old British men who do their crosswords on paper but log onto a computer to talk to people about it.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Sept&#x2F;Oct 2024</title>
		<published>2024-11-11T00:00:00+00:00</published>
		<updated>2024-11-11T00:00:00+00:00</updated>
		<link href="https://kipp.ly/sep-oct-24/"/>
		<link rel="alternate" href="https://kipp.ly/sep-oct-24/" type="text/html"/>
		<id>https://kipp.ly/sep-oct-24/</id>
		<content type="html">&lt;p&gt;A checklist format of what &lt;a href=&quot;https:&#x2F;&#x2F;sleepinyourhat.github.io&#x2F;checklist&#x2F;&quot;&gt;we need to succeed at AI Safety&lt;&#x2F;a&gt;, and it‚Äôs specifically safety and not alignment as there‚Äôs a pretty good case for a &lt;a href=&quot;https:&#x2F;&#x2F;www.alignmentforum.org&#x2F;posts&#x2F;kcKrE9mzEHrdqtDpE&#x2F;the-case-for-ensuring-that-powerful-ais-are-controlled&quot;&gt;Control agenda&lt;&#x2F;a&gt;. I care a lot about existential threats to humanity or to other things we value, but I also think that the upside from AGI is at least comparable. Mandatory &lt;a href=&quot;https:&#x2F;&#x2F;darioamodei.com&#x2F;machines-of-loving-grace&quot;&gt;Machines of Loving Grace&lt;&#x2F;a&gt; (rare Dario Amodei public content) which I think is rather tame but alas it seems like everyone is upset that it‚Äôs either too tame or too aggressive. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;magic.dev&#x2F;blog&#x2F;100m-token-context-windows&quot;&gt;100M&lt;&#x2F;a&gt; context windows, someone please make use of it. sama will never top the American equity fund, but at least the &lt;a href=&quot;https:&#x2F;&#x2F;ia.samaltman.com&#x2F;&quot;&gt;website for the intelligence age&lt;&#x2F;a&gt; is still good. Best tech drama lately? Definitely &lt;a href=&quot;https:&#x2F;&#x2F;slashdot.org&#x2F;story&#x2F;24&#x2F;10&#x2F;17&#x2F;219225&#x2F;employees-describe-an-environment-of-paranoia-and-fear-inside-automattic&quot;&gt;Automattic&lt;&#x2F;a&gt;. See also &lt;a href=&quot;https:&#x2F;&#x2F;paolo.blog&#x2F;blog&#x2F;what-the-heck-is-going-on-with-wordpress&#x2F;&quot;&gt;this&lt;&#x2F;a&gt; and well, the &lt;a href=&quot;https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41683715&quot;&gt;orange site&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;SSC vintage on &lt;a href=&quot;https:&#x2F;&#x2F;slatestarcodex.com&#x2F;2014&#x2F;03&#x2F;24&#x2F;should-you-reverse-any-advice-you-hear&#x2F;&quot;&gt;reversing advice&lt;&#x2F;a&gt; which I quite like the underlying model for. Probably I should write some text that is advice on taking advice. We love Baudrillard, and we love &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;jean-baudrillard&quot;&gt;Baudrillard gloves&lt;&#x2F;a&gt;! This years &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;6LJ6xcHEjKF9zWKzs&#x2F;the-2024-petrov-day-scenario&quot;&gt;Lesswrong Petrov day&lt;&#x2F;a&gt; is iconic as usual. People are &lt;a href=&quot;https:&#x2F;&#x2F;www.outsideonline.com&#x2F;culture&#x2F;essays-culture&#x2F;bedrock-sandals-stolen&#x2F;&quot;&gt;still stealing&lt;&#x2F;a&gt; and doing a good job at it but are scummy? Tony Soprano was right after all I suppose. There‚Äôs an Italian fugitive who like definitely faked his death in what seems like a wild story? His name is &lt;a href=&quot;https:&#x2F;&#x2F;reddmonitor.substack.com&#x2F;p&#x2F;who-is-samuele-landi-italian-fugitive&quot;&gt;Samuele Landi&lt;&#x2F;a&gt;, he was a &lt;a href=&quot;https:&#x2F;&#x2F;www.seasteading.org&#x2F;secret-seastead-ends-in-death&#x2F;&quot;&gt;seasteader who supposedly passed in February&lt;&#x2F;a&gt; (this article seems quite biased but other ones are paywalled) though his body does not seem properly identified. He also has ties to &lt;a href=&quot;https:&#x2F;&#x2F;simple.wikipedia.org&#x2F;wiki&#x2F;Liberland&quot;&gt;Liberland&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;www.theguardian.com&#x2F;environment&#x2F;2023&#x2F;nov&#x2F;30&#x2F;who-is-the-uae-sheikh-behind-deals-to-manage-vast-areas-of-african-forest&quot;&gt;some Saudi foresting&lt;&#x2F;a&gt; thing. There‚Äôs an &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pXj2Pat4jR4&amp;amp;ab_channel=Arezzo24&quot;&gt;upcoming documentary&lt;&#x2F;a&gt; too, so maybe we‚Äôll learn. &lt;&#x2F;p&gt;
&lt;p&gt;I read about the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bayh%E2%80%93Dole_Act&quot;&gt;Bayh-Dole Act&lt;&#x2F;a&gt; because of certain non-profit. People used to just do things like &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Andr%C3%A9e%27s_Arctic_balloon_expedition&quot;&gt;go to the arctic in a balloon&lt;&#x2F;a&gt; which is kind of awesome despite the unfortunate result, but some things are just bad? Like &lt;a href=&quot;https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Project_Pigeon&quot;&gt;trying to aim missiles by putting a pigeon inside of it&lt;&#x2F;a&gt;. Past few weeks I‚Äôve just been generally frustrated with people being excited to to unusual and strange things but forgetting that while it‚Äôs true that being unusual is the only way to be better, there are way more ways to be worse than better. African Americans responsible for &lt;a href=&quot;https:&#x2F;&#x2F;daily.jstor.org&#x2F;who-took-the-cocaine-out-of-coca-cola&#x2F;&quot;&gt;Coca-Cola not containing cocaine&lt;&#x2F;a&gt;? &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Coke&quot;&gt;Rare coke flavour&lt;&#x2F;a&gt; (new!) Marriott hotels and their &lt;a href=&quot;https:&#x2F;&#x2F;www.ldsliving.com&#x2F;what-a-prophet-told-the-marriotts-about-serving-alcohol-in-their-hotels&#x2F;s&#x2F;91496&quot;&gt;LDS origins&lt;&#x2F;a&gt;, specifically about how they decided to do alcohol. Your &lt;a href=&quot;https:&#x2F;&#x2F;www.nih.gov&#x2F;news-events&#x2F;nih-research-matters&#x2F;brain-waste-clearance-system-shown-people-first-time&quot;&gt;lymphatic system does do your brain&lt;&#x2F;a&gt;, how did we not know this? &lt;a href=&quot;https:&#x2F;&#x2F;www.chinatalk.media&#x2F;p&#x2F;chinese-shoegaze-an-introduction?utm_source=post-email-title&amp;amp;publication_id=4220&amp;amp;post_id=150926652&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=7pvp8&amp;amp;triedRedirect=true&amp;amp;utm_medium=email&quot;&gt;Chinese shoegaze music&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;Cute article about an &lt;a href=&quot;https:&#x2F;&#x2F;www.latimes.com&#x2F;archives&#x2F;la-xpm-2006-may-29-me-hero29-story.html&quot;&gt;SF panhandler&lt;&#x2F;a&gt;, like seriously cute. I went to the Bronx Zoo and read up on about it ahead of time. The otter-murder was cute and fun but &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ota_Benga&quot;&gt;this&lt;&#x2F;a&gt; was harrowing. NYPD is notorious for parking in bike lanes, and it seems like they probably got ticketed a lot before the &lt;a href=&quot;https:&#x2F;&#x2F;local1182.org&#x2F;about-us&#x2F;history-of-traffic&#x2F;&quot;&gt;traffic agents became a part of the NYPD&lt;&#x2F;a&gt; in 1996. 10e9 dollars is the annual budget of the NYPD, a figure that has been steadily growing. In comparison, North Korea is estimated to spend about 4e9 dollars a year. The &lt;a href=&quot;https:&#x2F;&#x2F;www.tumblr.com&#x2F;iquantny&#x2F;144197004989&#x2F;the-nypd-was-systematically-ticketing-legally&quot;&gt;NYPD did millions of dollars&lt;&#x2F;a&gt; of ticketing legally parked cars. New &lt;a href=&quot;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;09&#x2F;19&#x2F;books&#x2F;review&#x2F;capital-volume-one-karl-marx.html&quot;&gt;Karl Marx translation&lt;&#x2F;a&gt;! &lt;&#x2F;p&gt;
&lt;p&gt;I finally read some Lovecraft, and it makes so much sense how the concepts are so memetically fit now. If we erased all historical and cultural context in the world, Lovecraft would still a classic.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Book: Path to Power and Means of Ascent (first two LBJ Caro books)&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Earlier this year I visited New York to see the Columbia protests, after which I went to a bookstore to pick up a book on Nixon (when in Rome). Expectedly I got stressed out about which Nixon biography I would enjoy most and figured I‚Äôd accept the off-by-one-presidency error and get LBJ instead ‚Äî where I was certain I wanted the Caro. I tried to purchase Master of the Senate, the third book in the series which documents Johnson‚Äôs senatorship. The bookstore clerk proceeded to ask me whether I had read the first two books and talked me into getting the first. Big Biography wins again!&lt;&#x2F;p&gt;
&lt;p&gt;LBJ is unfortunately a large part of my personality now, the books are phenomenal. They don‚Äôt make biographers like Caro anymore. His research involved moving to Johnson‚Äôs hometown and his interviews are so skillfully conducting, not to even mention the prose itself. I adore and admire Caro, but LBJ is a horrible person? (I hear there‚Äôs a plot-twist at the end, but no spoilers please!) In real life, utilitarianism and consequentialism are usually the same thing, but not for LBJ. He arguably did net good, but most of the bad things he did were not necessary to achieve those positive outcomes. In general being into Caro is a green flag and being into LBJ (or Moses) is a red flag. &lt;&#x2F;p&gt;
&lt;p&gt;The Power Broker is the more popular series, but it‚Äôs kind of an East Coast story about an idealist who is polarised by the system and takes it over. LBJ is a West Coast story. A man born believing that power was his birthright and dedicates his life to acquiring it through a blatant lack of regard for convention. A narrative where one can acquire all the power and then figure out something to do with it later. He is the worst of both gender stereotypes &#x2F; tendencies. Manipulative, power-hungry, short-tempered. Insecure, bipolar 2, daddy issues, tummy hurt. From LBJ‚Äôs childhood up to his second senate campaign he exhibits relatively little character development. LBJ is so compelling as a human, in large part due to Caro‚Äôs writing.&lt;&#x2F;p&gt;
&lt;p&gt;I had moments of doubt. Caro goes on these side quests, and in between the lines he‚Äôs saying ‚Äútrust me, you‚Äôll understand why I‚Äôm telling you about this later‚Äù. The first time was in the opening fifty pages, which all took place well before Lyndon was even born. My favourite parts are likely the mini-biographies of Ladybird, Rayburn and Stevenson. Caro also devotes a chapter to describing the pains of laundry and other household chores to provide context for what electricity meant. I do sometimes worry that Caro takes on more narrative license than I‚Äôd prefer when reading about a morally controversial figure, but his writing is so effective at bringing you into the universe and fully grokking even the smallest of situations. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Book: Lolita&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I turned away from fiction years ago because I thought it was offensive to reality, and this year I‚Äôve three-sixtied into reading fiction escape reality. Lolita is doubly inconsequential as it‚Äôs not only fiction, but fiction written by an unreliable narrator. &lt;&#x2F;p&gt;
&lt;p&gt;‚ÄúOh Lolita, it‚Äôs about you‚Äù was the recommendation I got for it while scanning a friend‚Äôs bookshelf. Sure, I guess. The plot wasn‚Äôt the most special part of the book though, it‚Äôs the fact that Nabakov wrote it in a non-native language ‚Äî  a fact that I thankfully encountered in the first quarter of the text. Nabakov did a Russian translation too, which he claimed to be worse despite him learning English well after his where any pedagogist would consider optimal (and of course also wrote in French). My favourite part of his writing style was constant original metaphors without invoking cringe or deferring to reader interpretation. &lt;&#x2F;p&gt;
&lt;p&gt;Objectively speaking, the plot is unfortunately probably the notable feature of Lolita. It reminded me a lot of this book that contained a segment titled The Young-Girl As A Commodity. &amp;quot;And they are realistic, even in love‚Äù (Tiqqun, 2012). The controversy is in the hebephilia, the commentary is in the specific kind of sexualisation of young women we do, especially in the western world. Most characteristic was how Lo could be bought off so her love (or at least, good graces) could be retained. &lt;&#x2F;p&gt;
&lt;p&gt;As a girl, every song is about me! The way HH uses his intelligence to so seamlessly rationalise something barbaric is something I‚Äôm as familiar with as one can be. It‚Äôs very popular in my locale (San Francisco) and culture (rationality). People say this shit about this all the time but it‚Äôs quite special to have to captured so beautifully in fiction, since nothing teaches this lesson like carefully watching someone else make the mistake.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Jan&#x2F;Feb 2024</title>
		<published>2024-05-28T00:00:00+00:00</published>
		<updated>2024-05-28T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jan-feb-24/"/>
		<link rel="alternate" href="https://kipp.ly/jan-feb-24/" type="text/html"/>
		<id>https://kipp.ly/jan-feb-24/</id>
		<content type="html">&lt;p&gt;i‚Äôve been in a work hole these two months thinking about kernels and numerics. &lt;&#x2F;p&gt;
&lt;p&gt;vitalik &lt;a href=&quot;https:&#x2F;&#x2F;vitalik.eth.limo&#x2F;general&#x2F;2023&#x2F;11&#x2F;27&#x2F;techno_optimism.html&quot;&gt;on techno-optimism&lt;&#x2F;a&gt;, he‚Äôs amazing and this is well reasoned and written but also i am mildly annoyed that everyone stopped to look at it when nothing in it is that novel. &lt;a href=&quot;https:&#x2F;&#x2F;asteriskmag.com&#x2F;issues&#x2F;05&#x2F;why-you-ve-never-been-in-a-plane-crash&quot;&gt;why you‚Äôve never been in a plane crash&lt;&#x2F;a&gt;. there‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;www.metamute.org&#x2F;editorial&#x2F;articles&#x2F;art-war-deleuze-guattari-debord-and-israeli-defence-force&quot;&gt;this&lt;&#x2F;a&gt;, which i obsessed about for days ‚Äî i don‚Äôt want to say anything more because i couldn‚Äôt possibly do it justice. incredible combination of funny, beautiful and educational. the vesuvius prize has &lt;a href=&quot;https:&#x2F;&#x2F;scrollprize.org&#x2F;grandprize&quot;&gt;winners&lt;&#x2F;a&gt; but also &lt;a href=&quot;https:&#x2F;&#x2F;scrollprize.org&#x2F;master_plan&quot;&gt;future plans&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;the openai &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-and-journalism&quot;&gt;press release&lt;&#x2F;a&gt; about a lawsuit, which is weirdly entertaining? perhaps a bias of my occupation. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2401.05566.pdf&quot;&gt;sleeper agents&lt;&#x2F;a&gt; paper! i‚Äôve been waiting for that one to drop for a while. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.galactanet.com&#x2F;oneoff&#x2F;theegg_mod.html&quot;&gt;short story&lt;&#x2F;a&gt; that really straddles eerie and cute. this &lt;a href=&quot;https:&#x2F;&#x2F;www.asc.ohio-state.edu&#x2F;kilcup.1&#x2F;262&#x2F;feynman.html&quot;&gt;excerpt&lt;&#x2F;a&gt; from ‚Äúsurely you‚Äôre joking mr. feynman‚Äù (brilliant scientist makes pithy quote). want insight? check out this article by ricky about &lt;a href=&quot;https:&#x2F;&#x2F;asteriskmag.com&#x2F;issues&#x2F;05&#x2F;michael-lewis-s-blind-side#how-did-we-miss-this&quot;&gt;how mistakes are made&lt;&#x2F;a&gt;, particularly how multi-billion dollar crypto exchange mistakes (and their surrounding mistakes, because with one mistake always comes another) occur. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Death_by_coconut&quot;&gt;coconut deaths&lt;&#x2F;a&gt;! my friend with the most insane journalist name wrote a great &lt;a href=&quot;https:&#x2F;&#x2F;jacobin.com&#x2F;2024&#x2F;01&#x2F;can-humanity-survive-ai&quot;&gt;article about ai&lt;&#x2F;a&gt;. a scientific &lt;a href=&quot;https:&#x2F;&#x2F;faroutinitiative.com&#x2F;&quot;&gt;cure for suffering&lt;&#x2F;a&gt;? solution for wireheading? a &lt;a href=&quot;https:&#x2F;&#x2F;www.cockroachlabs.com&#x2F;blog&#x2F;true-tales-survival-usps&#x2F;&quot;&gt;500M typo&lt;&#x2F;a&gt; from my favourite federal organisation.&lt;&#x2F;p&gt;
&lt;p&gt;i only studied one paper meaningfully, but was &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2312.00752&quot;&gt;mamba&lt;&#x2F;a&gt;, so that‚Äôs fine. here‚Äôs a &lt;a href=&quot;https:&#x2F;&#x2F;jackcook.com&#x2F;2024&#x2F;02&#x2F;23&#x2F;mamba.html&quot;&gt;mamba accessory&lt;&#x2F;a&gt;! &lt;&#x2F;p&gt;
&lt;p&gt;it‚Äôs elon season? it started with &lt;a href=&quot;https:&#x2F;&#x2F;caseyhandmer.wordpress.com&#x2F;2024&#x2F;01&#x2F;02&#x2F;elon-musk-is-not-understood&#x2F;&quot;&gt;Elon Musk is Misunderstood&lt;&#x2F;a&gt;, then there was &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2024-01-31&#x2F;elon-musk-is-overpaid?srnd=undefined&quot;&gt;Elon Musk is Overpaid&lt;&#x2F;a&gt; (and the rest of the ongoing matt levine saga). the handmer-levine pairing (unrelated: the &lt;a href=&quot;https:&#x2F;&#x2F;caseyhandmer.wordpress.com&#x2F;2024&#x2F;01&#x2F;30&#x2F;mars-helicopter-2-0&#x2F;&quot;&gt;mars helicopter&lt;&#x2F;a&gt;) was incredible. i‚Äôm so sick of ‚Äúif you liked x, try y‚Äù! i‚Äôm now into things to enjoy simultaneously. 1984 x brave new world. atlas shrugged x progress and poverty. making of the atomic bomb x american prometheus. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Room for Thought&lt;&#x2F;strong&gt; &lt;&#x2F;p&gt;
&lt;p&gt;i am a fan of the &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;&quot;&gt;boot boyz biz&lt;&#x2F;a&gt;, and the &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;collections&#x2F;archive&#x2F;products&#x2F;brick-pencil&quot;&gt;douglas englebart brick pencil shirt&lt;&#x2F;a&gt; i have from them. problem: their apparel has becoming increasingly text-dense over the years. solution: a four-hundred page philosophy picture book. it‚Äôs beautiful and thought provoking and overall an enjoyable read. my favourite quote ‚Äî though much of the bits were contained in the visual ‚Äî was: There Will Be People Who Will Say ‚ÄúYou Don‚Äôt Mix This with That.‚Äù And You Will Say: ‚ÄúWatch Me (Watch Me)‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;imagine everything one might enjoy about a naval tweet and manifest it into full-thoughts represented in beautiful imagery and typography. this is it!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;More qntm shorts and The Metamorphisis of Prime Intellect&lt;&#x2F;strong&gt; &lt;&#x2F;p&gt;
&lt;p&gt;for my entire life i didn‚Äôt read scifi out a notion that it‚Äôs disrespectful to the beauty of the science of our universe, either existing or prospective (that‚Äôs a lie, it‚Äôs because it‚Äôd take up too much time). i don‚Äôt believe that less at all, but alas i was bullied into reading scifi, and expectedly enjoyed it. &lt;&#x2F;p&gt;
&lt;p&gt;it started with shorts ‚Äî my last blog post had a few &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;nov-dec-2023&#x2F;&quot;&gt;qntm&lt;&#x2F;a&gt;, i read five more this year. honestly &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;perso&quot;&gt;some&lt;&#x2F;a&gt; were underwhelming but not &lt;em&gt;boring&lt;&#x2F;em&gt; because they were making me think a lot. &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;responsibilit&quot;&gt;some&lt;&#x2F;a&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;transi&quot;&gt;some&lt;&#x2F;a&gt;) were quant, as if the slice-of-life equivalent of scifi. &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;drill&quot;&gt;some&lt;&#x2F;a&gt; were creative and exciting in a traditional way. i loved them all. &lt;&#x2F;p&gt;
&lt;p&gt;metamorphisis of prime intellect was technically my first full-feature and it is perfect. it does an incredible job capturing all the nuances of immortality and how human desires would respond to it without wasting time on things i‚Äôve already thought about (&lt;em&gt;cries in the first two thirds of permutation city&lt;&#x2F;em&gt;). the world it created was compelling and the pornography was nothing but the finest.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Nov&#x2F;Dec 2023</title>
		<published>2024-01-02T00:00:00+00:00</published>
		<updated>2024-01-02T00:00:00+00:00</updated>
		<link href="https://kipp.ly/nov-dec-2023/"/>
		<link rel="alternate" href="https://kipp.ly/nov-dec-2023/" type="text/html"/>
		<id>https://kipp.ly/nov-dec-2023/</id>
		<content type="html">&lt;p&gt;MMLU scores are getting too high ‚Äî I‚Äôm optimistic about &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.12022.pdf&quot;&gt;GPQA&lt;&#x2F;a&gt;. The &lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;weak-to-strong-generalization.pdf&quot;&gt;weak-to-strong generalisation paper&lt;&#x2F;a&gt; came out! It‚Äôs good work and a direction worth looking into as approaching the problem of scalable oversight from the other direction. I‚Äôm still not optimistic about it and don‚Äôt think the paper provides many updates. The OpenAI &lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;openai-preparedness-framework-beta.pdf&quot;&gt;preparedness framework&lt;&#x2F;a&gt; also came out and I‚Äôm extremely happy with it, especially with persuasion as a first-class risk. I‚Äôm excited for RSPs to be iterated on and become clearer, more specific and gain coverage. &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;kanjun&#x2F;status&#x2F;1720502401067811242?s=46&quot;&gt;Reflections&lt;&#x2F;a&gt; on the UK AI Summit from Kanjun. The &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2023&#x2F;monosemantic-features&#x2F;index.html&quot;&gt;monosemanticity paper&lt;&#x2F;a&gt;, highly recommend reading if you can only read one interp paper.&lt;&#x2F;p&gt;
&lt;p&gt;Another &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.20707.pdf&quot;&gt;good data paper&lt;&#x2F;a&gt;, though good data papers don‚Äôt need to have big insights or takeaways. The best Gwern posts are ones where I can‚Äôt tell if he‚Äôs joking, like &lt;a href=&quot;https:&#x2F;&#x2F;gwern.net&#x2F;aunn&quot;&gt;this one&lt;&#x2F;a&gt; on doing a giant MLP for everything. A paper on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.01460.pdf&quot;&gt;baking in CoT processes&lt;&#x2F;a&gt; into the model which I generally like because there‚Äôs no reason for number of tokens to correlate with how much compute it‚Äôs needed to do something. . &lt;a href=&quot;https:&#x2F;&#x2F;annas-blog.org&#x2F;duxiu-exclusive.html&quot;&gt;Um&lt;&#x2F;a&gt;. A &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.17623.pdf&quot;&gt;way&lt;&#x2F;a&gt; to test if models were trained on the test set, but requires knowing the exact strings and so isn‚Äôt that exciting. Using &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1905.00174.pdf&quot;&gt;temperature scaling&lt;&#x2F;a&gt; for calibration of DNNs. Understanding &lt;a href=&quot;https:&#x2F;&#x2F;agustinus.kristia.de&#x2F;techblog&#x2F;2016&#x2F;12&#x2F;21&#x2F;forward-reverse-kl&#x2F;&quot;&gt;KL Divergence&lt;&#x2F;a&gt; a bit better though I‚Äôll probably never need to think about that again. Trustworthy paper on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2312.11444.pdf&quot;&gt;Gemini evals&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;http:&#x2F;&#x2F;x.ai&quot;&gt;x.ai&lt;&#x2F;a&gt; grok announcement, which is impressive though they evaluated other models at weird temperatures. Gemini &lt;a href=&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;gemini&#x2F;gemini_1_report.pdf&quot;&gt;report&lt;&#x2F;a&gt; dropped! They generally did good, though I‚Äôm annoyed by eval milking even though it‚Äôs not unfair. &lt;a href=&quot;https:&#x2F;&#x2F;www.newyorker.com&#x2F;culture&#x2F;culture-desk&#x2F;the-new-poem-making-machinery&quot;&gt;New Yorker profile&lt;&#x2F;a&gt; that mentions a researcher I respect but is mostly about the model. I want to do profiles on all my favourite people but it would take time and embarrass them I guess. Incredible &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;kelmgren&#x2F;status&#x2F;1720583218259522014?s=46&quot;&gt;tweet thread&lt;&#x2F;a&gt; about Chinese nicknames for semi-conductor manufacturing companies.&lt;&#x2F;p&gt;
&lt;p&gt;Read this &lt;a href=&quot;https:&#x2F;&#x2F;www.goodreads.com&#x2F;review&#x2F;show&#x2F;4935354533&quot;&gt;book review&lt;&#x2F;a&gt; for a book I have no intention of reading ever. I didn‚Äôt really need the financial advice, but I generally felt like exploring the documents of the great &lt;a href=&quot;https:&#x2F;&#x2F;www.mrmoneymustache.com&#x2F;2014&#x2F;11&#x2F;04&#x2F;why-i-put-my-last-100000-into-betterment&#x2F;&quot;&gt;Mr. Money Moustache&lt;&#x2F;a&gt;. The US government and their &lt;a href=&quot;https:&#x2F;&#x2F;www.openculture.com&#x2F;2019&#x2F;06&#x2F;the-us-government-commissioned-7500-watercolor-paintings.html&quot;&gt;7,500 watercolour fruits&lt;&#x2F;a&gt;. It‚Äôs awesome that the Church of Jesus Christ of Latter Day Saints was the first website that showed me results when I was googling about &lt;a href=&quot;https:&#x2F;&#x2F;www.churchofjesuschrist.org&#x2F;study&#x2F;ensign&#x2F;2014&#x2F;10&#x2F;the-jadeite-cabbage?lang=eng&quot;&gt;this bok choy&lt;&#x2F;a&gt;. Ant &lt;a href=&quot;https:&#x2F;&#x2F;www.npr.org&#x2F;2023&#x2F;11&#x2F;21&#x2F;1214246291&#x2F;army-ants-architecture-science-robots-research&quot;&gt;eusocial behaviour&lt;&#x2F;a&gt; does have nanobot swarm energy. Turns out Wikipedia edit histories are a great source of funny material, I was refreshing &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=Henry_Kissinger&amp;amp;action=history&amp;amp;offset=&amp;amp;limit=100&quot;&gt;this page&lt;&#x2F;a&gt; on a certain news page and there are a lot of good commit messages in there. The Scientologists &lt;a href=&quot;https:&#x2F;&#x2F;daily.redbullmusicacademy.com&#x2F;2016&#x2F;03&#x2F;the-apollo-stars-feature&quot;&gt;had a weird jazz-y band&lt;&#x2F;a&gt;. A branch of Christianity named after &lt;a href=&quot;https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Molokan&quot;&gt;milk&lt;&#x2F;a&gt; because they drank milk at lent. Another &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fr%C3%A9d%C3%A9ric_Bourdin&quot;&gt;weird guy&lt;&#x2F;a&gt; to remind you that serial extreme lying is really common and not that hard. I should make a list of these guys for whenever someone tries to dismiss the possibility of a pathological liar. &lt;&#x2F;p&gt;
&lt;p&gt;A review on &lt;a href=&quot;https:&#x2F;&#x2F;forum.effectivealtruism.org&#x2F;posts&#x2F;gxppfWhx7ta2fkF3R&#x2F;10-years-of-earning-to-give&quot;&gt;earning to give&lt;&#x2F;a&gt;. Tom O‚ÄôDonnell‚Äôs writing titled &lt;a href=&quot;https:&#x2F;&#x2F;www.newyorker.com&#x2F;humor&#x2F;daily-shouts&#x2F;l-p-d-libertarian-police-department&quot;&gt;Libertarian Police Department&lt;&#x2F;a&gt;. A &lt;a href=&quot;https:&#x2F;&#x2F;atelfo.github.io&#x2F;2023&#x2F;12&#x2F;23&#x2F;biopharma-from-janssen-to-today.html&quot;&gt;thorough intro&lt;&#x2F;a&gt; to the pharma industry that is really well-written even if you don‚Äôt care about pharma. The whole regulation thing is sort of new, and makes me skeptical of the whole ‚Äúgovernments can‚Äôt react quickly to big technological developments‚Äù notion ‚Äî it‚Äôs more like governments probably won‚Äôt react well. The better than Beatle‚Äôs effect is fun, and it‚Äôs generally nice as an AI risk-worrier to see that it‚Äôs possible to be damagingly risk averse. Have you heard about the &lt;a href=&quot;https:&#x2F;&#x2F;drive.google.com&#x2F;drive&#x2F;u&#x2F;0&#x2F;folders&#x2F;18ZDSe92LgLmS0sUbosvNxByii_1kjnEj&quot;&gt;tooth sauce&lt;&#x2F;a&gt; that makes you never get cavities again? I‚Äôm still waiting for them to come out with an N&#x2F;M dentists hate this stat, more info &lt;a href=&quot;https:&#x2F;&#x2F;www.astralcodexten.com&#x2F;p&#x2F;defying-cavity-lantern-bioworks-faq&quot;&gt;here&lt;&#x2F;a&gt;. A heartfelt shutdown of &lt;a href=&quot;https:&#x2F;&#x2F;www.omegle.com&#x2F;&quot;&gt;omegle&lt;&#x2F;a&gt;, morality is hard these days. &lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;post-mortem-on-cloudflare-control-plane-and-analytics-outage&#x2F;&quot;&gt;best fucking post-mortem&lt;&#x2F;a&gt; I‚Äôve ever read about the Cloudflare &lt;a href=&quot;https:&#x2F;&#x2F;www.cloudflarestatus.com&#x2F;incidents&#x2F;hm7491k53ppg&quot;&gt;outage&lt;&#x2F;a&gt;. I get a bit of schadenfreude for outages just because I get excited about the post-mortem. This one was special because it was an enjoyable read, but I didn‚Äôt quite appreciate the attitude of blame to their data center manager (who is definitely getting fired) especially when they missed some good practices and were out for far longer after the data centers were back up. It reminded me to reread this &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.blog&#x2F;2012&#x2F;11&#x2F;09&#x2F;se-podcast-36-we-got-hit-by-a-hurricane&#x2F;&quot;&gt;old classic&lt;&#x2F;a&gt;. I finally looked up the origin of the term &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cargo_cult&quot;&gt;‚Äúcargo-cult‚Äù&lt;&#x2F;a&gt; and it‚Äôs really fucked, that term will never be the same to me. Imagine someone has written a &lt;a href=&quot;https:&#x2F;&#x2F;www.efinancialcareers.com&#x2F;news&#x2F;2023&#x2F;11&#x2F;ocaml-vs-c-high-frequency-trading&quot;&gt;hit-piece&lt;&#x2F;a&gt; about your company which consists entirely of quotes your engineers said in the company‚Äôs engineering podcast. A cute post about forming &lt;a href=&quot;https:&#x2F;&#x2F;cycles.substack.com&#x2F;p&#x2F;my-pet-cow&quot;&gt;emotional attachment with your servers&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;Matt Levine really hit the mark on the whole OpenAI situation, my favourite was &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2023-11-21&#x2F;openai-is-a-strange-nonprofit&quot;&gt;this day‚Äôs&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;Reread &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo&quot;&gt;Lena&lt;&#x2F;a&gt;, I still don‚Äôt get creeped out by it. &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;readin&quot;&gt;If You Are Reading This&lt;&#x2F;a&gt; is incredibly utterly relatable. Another &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;frame&quot;&gt;qntm&lt;&#x2F;a&gt; that starts out really cute and takes a morbid but funny turn. &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;differenc&quot;&gt;The Difference&lt;&#x2F;a&gt; did manage to creep me out, as did &lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;gorge&quot;&gt;Gorge&lt;&#x2F;a&gt; ‚Äî those two are definitely my favourite of the listed qntm.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;partial-book-review-history-of-western-philosophy-by-bertrand-russell&quot;&gt;Partial Book Review: History of Western Philosophy by Bertrand Russell&lt;&#x2F;h3&gt;
&lt;p&gt;I started reading this book like six months ago and am only just halfway done because I‚Äôm bad at reading. The first two hundred and seventeen pages are about Ancient Philosophy and the following two hundred and seventy pages are about Catholic Philosophy, so I thought I‚Äôd write some notes before venturing into the three hundred and forty six pages of Modern Philosophy. Russell is a fantastic philosopher, really smart and seems underrated. He inserts opinion in isolated spots, and I at least always appreciated them. I don‚Äôt really need to know anything about ancient or catholic philosophy, but here are some of the things my brain retained (which are only a little correlated with how interesting they are, but very correlated with how recently I read them): &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Some great Catholic philosophers (like Occam) who did good thinking were perverse in that they weren‚Äôt in some truth-seeking regime, but rationalising existing beliefs. There were some goofy things, like Roger Bacon saying the first cause of ignorance is bad authority but specifying that it does not include the church. This seems rarer in this day in age where truth-seeking is more common and virtuous but I wonder where it‚Äôs happening that I‚Äôm not seeing? I feel like some research is locally like this in a good way.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;There‚Äôs a funny &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Western_Schism&quot;&gt;event&lt;&#x2F;a&gt; in the 14th century where the French lost the papacy when there were two popes declared (one Roman and one Avignon). The funny part is that it was resolved by just‚Ä¶ asking a council? Cultures of absolute chain of command are good like this I guess. Russell writes about this with ‚Äútherefore a power superior to a legitimate pope had to be found‚Äù and described the Avignon pope (who was closely associated with the French monarch) as ‚Äúaddicted to favouritism and nepotism‚Äù. It‚Äôs a surprisingly funny book.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Saint Augustine semi-anticipated the cogito ergo sum, he also believed that it was morally important to live in solitude and did so for a number of years I don‚Äôt remember&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In the middle of all the boring Catholic philosophy stuff, Russell drops this, which I don‚Äôt endorse as fully accurate but is entertaining:&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yahweh=Dialectical Materialism&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Messiah=Marx&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Elect=The Proletariat&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Church=The Communist Party&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Second Coming=The Revolution&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Hell=Punishment of the Capitalists&lt;br&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Millennium=The Communist Commonwealth&lt;br&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;There was joke about how the Roman army figured out they could take bribes when choosing emperor and then assassinate the emperor and repeat&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Aristotle is really pro-slavery, and has some weird reasoning about how some people are better off when ruled by superiors (like animals) and it justifies every single war as morally good. I only remember this because there was a funny comment from Russell: ‚ÄúVery satisfactory!‚Äù&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Reading through the Ancient philosophy part was interesting as it reminds me how much standard logic and intuition I take as common sense had to be derived at one point. Simple things like how some opinions can be better than others even if you don‚Äôt know that they‚Äôre true or how knowledge is useful for morality&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;A lot of the content was context for how the works of specific philosophers were passed down, and may have been poorly documented by followers of the philosophers.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;book-review-a-very-short-introduction-to-hegel-by-peter-singer&quot;&gt;Book Review: A Very Short Introduction to Hegel by Peter Singer&lt;&#x2F;h3&gt;
&lt;p&gt;I found this book at the store and I only picked it up because I saw ‚ÄúPeter Singer‚Äù and I was like no way! Not The Most Good You Can Do Peter Singer? It was! I was biased against the book because Hegel feels like a meme and the book opens with Singer saying that Hegel was the most ‚Äúimpactful‚Äù philosopher of the 20th century. Of course I thought to myself ‚ÄúMarx erasure?‚Äù but Singer had thought of it and followed it up with something about how because Hegel influenced Marx it doesn‚Äôt count or something. &lt;&#x2F;p&gt;
&lt;p&gt;I have never‚Ä¶ read Hegel, but the only coherent takeaway I could pull was in regards to Hegel‚Äôs philosophy of history. The Hegelian notion of freedom actually really clicked with me, it‚Äôs what we today call ‚Äúagency‚Äù (even though we use it in the definition of it‚Äôs original use) and he describes it with things like how loyalty to your nation isn‚Äôt freedom because it‚Äôs too much of a default, convenient belief. The history part is uncompelling though. Hegel describes the development of history as gain of freedom, which is true in uninteresting ways and he fails to make a coherent claim about what the end state is and claims that his 19th century Germany was it. &lt;&#x2F;p&gt;
&lt;p&gt;There was a bunch of stuff that didn‚Äôt seem fully cogent though I understand bits and pieces. Probably there is more good stuff in there? Though it seems sufficiently hard to study that I will simply not. &lt;&#x2F;p&gt;
&lt;p&gt;I have a lot of priors against Hegel. To start, Hegel is notoriously hard to understand (countless of introductory attempts) and background says I should worry that it‚Äôs hard to understand because there isn‚Äôt much to understand. Also a lot of what is attributed to Hegel is notes from his students. More bias against Hegel is that I tried to read Zizek‚Äôs jokes and he has horrible jokes, continential humour just doesn‚Äôt click with me.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>note on morality as a practice</title>
		<published>2023-12-15T00:00:00+00:00</published>
		<updated>2023-12-15T00:00:00+00:00</updated>
		<link href="https://kipp.ly/morality-exercise-notes/"/>
		<link rel="alternate" href="https://kipp.ly/morality-exercise-notes/" type="text/html"/>
		<id>https://kipp.ly/morality-exercise-notes/</id>
		<content type="html">&lt;p&gt;i think morality as a human trait is much shallower than people think, whether it‚Äôs about how nice you are to your friends, how much money you donate or your dietary choices. it‚Äôs much closer to how well people exercise (physically) as a trait, than say one‚Äôs self-acceptance which is deeply embedded into their psyche. sure some are more naturally-inclined than others, but it‚Äôs also true that most people can practice it, making it quickly much easier to do and resulting in improvement.&lt;&#x2F;p&gt;
&lt;p&gt;insofar as it is a deep character trait or personal belief, it lives in the value system,,, not the part of morality that corresponds with executing that value system. christianity might be the closest thing you can get to a coach or gym for morality though? other than that i guess we just have to find enough self-awareness and activation energy to start a practice&lt;&#x2F;p&gt;
&lt;p&gt;(i used to anguish about donating 10% but i‚Äôve been able to do much more [at a faster rate than my income increases] without it being difficult and without me changing how much i care about causes or whatever)&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Sept&#x2F;Oct 2023</title>
		<published>2023-11-02T00:00:00+00:00</published>
		<updated>2023-11-02T00:00:00+00:00</updated>
		<link href="https://kipp.ly/sept-oct-2023/"/>
		<link rel="alternate" href="https://kipp.ly/sept-oct-2023/" type="text/html"/>
		<id>https://kipp.ly/sept-oct-2023/</id>
		<content type="html">&lt;p&gt;An impressively redeeming &lt;a href=&quot;https:&#x2F;&#x2F;80000hours.org&#x2F;podcast&#x2F;episodes&#x2F;mustafa-suleyman-getting-washington-and-silicon-valley-to-tame-ai&#x2F;&quot;&gt;interview with Mustafa Suleyman&lt;&#x2F;a&gt;. Anthropic got &lt;a href=&quot;https:&#x2F;&#x2F;www-files.anthropic.com&#x2F;production&#x2F;files&#x2F;responsible-scaling-policy-1.0.pdf&quot;&gt;an RSP&lt;&#x2F;a&gt;, and I can only hope that it will at one point become the third best RSP. Methods for &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.00682.pdf&quot;&gt;proof-of-training-data&lt;&#x2F;a&gt;, which were more compelling than I expected but I‚Äôm still not very optimistic it‚Äôll be tractable or useful after an implementation of reasonable quality. The Frontier Model forum &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;frontier-model-forum-updates&quot;&gt;seems to be doing great&lt;&#x2F;a&gt;, feels a bit like a dream. &lt;&#x2F;p&gt;
&lt;p&gt;Article explaining the &lt;a href=&quot;https:&#x2F;&#x2F;finbarr.ca&#x2F;how-is-llama-cpp-possible&#x2F;?fbclid=IwAR00OuFYJhv_ViGQA81VWWZayH1eblrplVFqla4E9_R32WSvL68vj6uahI0&quot;&gt;Llama.cpp performance&lt;&#x2F;a&gt;, though I find myself asking ‚Äúhow is it so slow‚Äù infinitely more than ‚Äúhow is it so fast‚Äù. I asked myself ‚Äúhow is it so slow‚Äù with the &lt;a href=&quot;https:&#x2F;&#x2F;www.arxiv-vanity.com&#x2F;papers&#x2F;2310.17680&#x2F;&quot;&gt;3.5-turbo size-leak&lt;&#x2F;a&gt;(?), and I probably would‚Äôve asked that even for a 200B param dense model. The &lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;GPTV_System_Card.pdf&quot;&gt;GPT-V system-card&lt;&#x2F;a&gt; is kind of exciting, I can‚Äôt wait to move out of the chat modality. A study on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2309.14322.pdf&quot;&gt;training stability&lt;&#x2F;a&gt; (and a surprising publish from Google!). &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2309.10818.pdf&quot;&gt;Data comp work&lt;&#x2F;a&gt; from the people who did Red Pajama. Cool &lt;a href=&quot;https:&#x2F;&#x2F;www.adept.ai&#x2F;blog&#x2F;fuyu-8b&quot;&gt;multi-modal architecture&lt;&#x2F;a&gt; from Adept. Using &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2309.17453.pdf&quot;&gt;sink tokens&lt;&#x2F;a&gt; to put the attention somewhere when it‚Äôs not using the most recent window of tokens. &lt;&#x2F;p&gt;
&lt;p&gt;Incredible Hillel Wayne on &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;did-brendan-eich-really-make-javascript-in-10-days&#x2F;&quot;&gt;JavaScript history&lt;&#x2F;a&gt;, I really want to write the one about why there are three JS engines that were all developed at around the same time. They‚Äôve read the first letters of the Herculaneum scrolls! 2015 ML wins again! I caught up on &lt;a href=&quot;https:&#x2F;&#x2F;brandur.org&#x2F;nanoglyphs&#x2F;040-rails-world#footnote-1&quot;&gt;Rails World&lt;&#x2F;a&gt;, which also introduces the ‚Äúrenaissance developer‚Äù. Everyone definitely needs to spend time exploring the &lt;a href=&quot;https:&#x2F;&#x2F;www.computerhistory.org&#x2F;collections&#x2F;search&#x2F;?s=a&quot;&gt;catalog&lt;&#x2F;a&gt; of the Computer History Museum ‚Äî I found a &lt;a href=&quot;https:&#x2F;&#x2F;www.computerhistory.org&#x2F;collections&#x2F;catalog&#x2F;102741095&quot;&gt;‚Äúpalm pilop‚Äù&lt;&#x2F;a&gt; shirt while I was searching for Research in Motion items. &lt;&#x2F;p&gt;
&lt;p&gt;I miss the peak of the housing discourse, this &lt;a href=&quot;https:&#x2F;&#x2F;gravitylobby.club&#x2F;knot.html&quot;&gt;2018 post&lt;&#x2F;a&gt; was a fantastic throwback. Also a throwback, &lt;a href=&quot;https:&#x2F;&#x2F;moores.samaltman.com&#x2F;&quot;&gt;2021 Sam Altman&lt;&#x2F;a&gt; was fucking amazing, I hope he still believes those things. I finally asked myself why people don‚Äôt trade on Hollywood, and uh, it‚Äôs because &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Onion_Futures_Act&quot;&gt;it‚Äôs illegal&lt;&#x2F;a&gt; (along with onion futures). Apparently it was shot down (by lobbyists) because it would be too easily manipulated and wouldn‚Äôt help film companies, but there‚Äôs gotta be something more right? &lt;&#x2F;p&gt;
&lt;p&gt;There‚Äôs this activity called ‚Äúhigh-pointing‚Äù, which is for people who like mountaineering and checklists. My favourite high point should maybe be &lt;a href=&quot;https:&#x2F;&#x2F;www.peakbagger.com&#x2F;peak.aspx?pid=7917&quot;&gt;the side of the road on Florida&lt;&#x2F;a&gt; but the best read is definitely the &lt;a href=&quot;https:&#x2F;&#x2F;www.peakbagger.com&#x2F;peak.aspx?pid=669&quot;&gt;Nunavut high point&lt;&#x2F;a&gt;. Maybe my favourite high point is the Saudi Arabia one because it comes with this great story about how it was &lt;a href=&quot;https:&#x2F;&#x2F;www.countryhighpoints.com&#x2F;saudi-arabia-jabal-ferwa&#x2F;&quot;&gt;corrected in 2018&lt;&#x2F;a&gt; with a GPS by high-pointers. Also in eldritch physical feats, there‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;everesting.cc&#x2F;run-rules&#x2F;&quot;&gt;Everesting&lt;&#x2F;a&gt;. We have &lt;a href=&quot;https:&#x2F;&#x2F;www.tensengral.com&#x2F;pages&#x2F;makers-story&quot;&gt;CNCed lace braiding&lt;&#x2F;a&gt; (lace is more advanced than knitting by centuries) now! How to make temporary &lt;a href=&quot;https:&#x2F;&#x2F;www.popsci.com&#x2F;diy&#x2F;article&#x2F;2008-02&#x2F;trap-lightning-block&#x2F;&quot;&gt;Lichtenberg figures at ‚Äúhome&lt;&#x2F;a&gt;‚Äù. The University of Minnesota is &lt;a href=&quot;https:&#x2F;&#x2F;mnhardy.umn.edu&#x2F;apples&#x2F;varieties&quot;&gt;phenomenal at apples&lt;&#x2F;a&gt;, the UWashington ones are much worse and you can really tell that the Cosmic Crisp was their attempt at a premium apple but it‚Äôs kind of mealy and the skin is too thick. I am so excited for &lt;a href=&quot;https:&#x2F;&#x2F;mnhardy.umn.edu&#x2F;triumph&quot;&gt;Triumph&lt;&#x2F;a&gt;!! A cute lil newsletter with &lt;a href=&quot;https:&#x2F;&#x2F;surfista.substack.com&#x2F;p&#x2F;016-im-back&quot;&gt;good items&lt;&#x2F;a&gt; ‚Äî I bought a D-BROS vase off ebay. There are so many &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;David_Rudnick&#x2F;status&#x2F;923196115910119424?s=20&quot;&gt;pasta shapes&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Check out franciscosan.org !&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Jul&#x2F;Aug 2023</title>
		<published>2023-09-08T00:00:00+00:00</published>
		<updated>2023-09-08T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jul-aug-2023/"/>
		<link rel="alternate" href="https://kipp.ly/jul-aug-2023/" type="text/html"/>
		<id>https://kipp.ly/jul-aug-2023/</id>
		<content type="html">&lt;p&gt;A Liang Lab &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03172.pdf&quot;&gt;evals of long contexts&lt;&#x2F;a&gt;, for which we find that language models have the same biases humans do to the beginning and end. Clever set on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.02477.pdf&quot;&gt;evals on counterfactual tasks&lt;&#x2F;a&gt;, generalisation is never as real as we want it to be. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.00099.pdf&quot;&gt;Proof of forgetting&lt;&#x2F;a&gt; for LLMs, though it doesn‚Äôt seem as easy as one would hope. Also yes we still have &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.07646.pdf&quot;&gt;a lot of memorisation&lt;&#x2F;a&gt;, which, due to the author, uses probably the best definition of k-extractability, though I wonder if some measure of loss over some context length makes more sense. I kind of think of self-play attempts as evals for some reason? Anyway &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.10142.pdf&quot;&gt;this one on negotiation&lt;&#x2F;a&gt; was well constructed and got good results on in-context AI feedback, usually better than human feedback. This was as month of great eval papers papers, but this one is a &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.09009.pdf&quot;&gt;pretty garbage paper&lt;&#x2F;a&gt; which dishonestly tries to present simple changes in formatting (usually for the better) from the GPT-4 API as performance degradation. But hey, people are working on good &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.11088.pdf&quot;&gt;long context evals&lt;&#x2F;a&gt; (this one is long-context human-labelled QA). &lt;&#x2F;p&gt;
&lt;p&gt;An attempt at &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.08621.pdf&quot;&gt;a new architecture&lt;&#x2F;a&gt;, but immediately opens with a plot showing they couldn‚Äôt scale their baseline transformer properly, an inspirational quote and an impossible triangle that is used as a diagram? A &lt;a href=&quot;https:&#x2F;&#x2F;152334h.github.io&#x2F;blog&#x2F;non-determinism-in-gpt-4&#x2F;#are-you-really-sure-it-isnt-hardware&quot;&gt;good explanation&lt;&#x2F;a&gt; for why GPT-4 is so non-deterministic. &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;oSZ2xTxEMZh9f3Yaz&#x2F;llms-are-mostly-not-helped-by-filler-tokens&quot;&gt;Testings of think tokens&lt;&#x2F;a&gt; (filler text) to see if it improves performance, and the answer is no except maybe for GPT-4? &lt;&#x2F;p&gt;
&lt;p&gt;Three year old text on &lt;a href=&quot;https:&#x2F;&#x2F;gravitylobby.club&#x2F;administrationmarkets.html&quot;&gt;administration markets&lt;&#x2F;a&gt;, which references a much more historically loaded piece on the &lt;a href=&quot;https:&#x2F;&#x2F;www.the-american-interest.com&#x2F;2018&#x2F;08&#x2F;13&#x2F;the-decline-of-american-public-administration&#x2F;&quot;&gt;decline of administrations&lt;&#x2F;a&gt;. Excuse the loading time from webarchive, but this content about &lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220810162706im_&#x2F;https:&#x2F;&#x2F;pbs.twimg.com&#x2F;media&#x2F;FZw7vytXgAA_SYC?format=jpg&amp;amp;name=medium&quot;&gt;Uber&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220810162706im_&#x2F;https:&#x2F;&#x2F;pbs.twimg.com&#x2F;media&#x2F;FZw7vy1WYAICi25?format=jpg&amp;amp;name=medium&quot;&gt;Maoism&lt;&#x2F;a&gt;, and &lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220810162706im_&#x2F;https:&#x2F;&#x2F;pbs.twimg.com&#x2F;media&#x2F;FZw7vyqXoAEP6Fq?format=jpg&amp;amp;name=medium&quot;&gt;Georgism&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.muji.com&#x2F;us&#x2F;feature&#x2F;whatismuji&#x2F;&quot;&gt;Muji Manifesto&lt;&#x2F;a&gt;, ‚Äúthis will do‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.07759.pdf&quot;&gt;TinyStories&lt;&#x2F;a&gt;! I can‚Äôt believe the same organisation put out both this paper and the Longformer paper. The TinyStories doesn‚Äôt focus on what should be the primary application of its technique, which is of course mech interp. The &lt;a href=&quot;https:&#x2F;&#x2F;openaipublic.blob.core.windows.net&#x2F;neuron-explainer&#x2F;paper&#x2F;index.html#sec-intro&quot;&gt;autointerpretability&lt;&#x2F;a&gt; work was quite nifty, OpenAI alignment lives on after all (I haven‚Äôt read it yet, but DeepMind interp is &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.09458.pdf&quot;&gt;also alive&lt;&#x2F;a&gt;!) I am a big fan of line of research around &lt;a href=&quot;https:&#x2F;&#x2F;www-files.anthropic.com&#x2F;production&#x2F;files&#x2F;measuring-faithfulness-in-chain-of-thought-reasoning.pdf&quot;&gt;measuring faithfulness in chain-of-thought reasoning&lt;&#x2F;a&gt;, which includes checks like filler text (think tokens), early answering, adding mistakes and the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.04388.pdf&quot;&gt;always-choose-a trick from this other paper&lt;&#x2F;a&gt;. That paper was published with the &lt;a href=&quot;https:&#x2F;&#x2F;www-files.anthropic.com&#x2F;production&#x2F;files&#x2F;question-decomposition-improves-the-faithfulness-of-model-generated-reasoning.pdf&quot;&gt;decomposition paper&lt;&#x2F;a&gt;, which does two kinds of decomp and finds that it on average decreases performance (especially the factored-decomp) but increases faithfulness. nostalgebraist &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;3ou8DayvDXxufkjHD&#x2F;openai-api-base-models-are-not-sycophantic-at-any-size&quot;&gt;couldn‚Äôt find as much sycophancy in GPT models&lt;&#x2F;a&gt;, my best guess is that this is a difference in RL data. Positional embeddings &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;qvWP3aBDBaqXvPNhS&#x2F;gpt-2-s-positional-embedding-matrix-is-a-helix&quot;&gt;are a helix&lt;&#x2F;a&gt;, but also I still don‚Äôt get how they can be important. &lt;&#x2F;p&gt;
&lt;p&gt;Paper doing a decent job outlining how one would manage &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03718.pdf&quot;&gt;AI public safety risks&lt;&#x2F;a&gt;, though details feel a bit messy. I brought my rabbit, bundle, to the office for his second New York Times photoshoot but sadly the bunny didn‚Äôt support the &lt;a href=&quot;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;07&#x2F;11&#x2F;technology&#x2F;anthropic-ai-claude-chatbot.html?partner=slack&amp;amp;smid=sl-share&quot;&gt;AI doomerism narrative&lt;&#x2F;a&gt;. India‚Äôs excerpt on a &lt;a href=&quot;https:&#x2F;&#x2F;www.drdo.gov.in&#x2F;sites&#x2F;default&#x2F;files&#x2F;monographs-documents&#x2F;35-guided-missiles.pdf&quot;&gt;guide to guided missiles&lt;&#x2F;a&gt;. The &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;frontier-model-forum&quot;&gt;frontier model forum&lt;&#x2F;a&gt; launched, lower cased (fingers crossed) until it goes well. Anthropic publishes &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;index&#x2F;frontier-threats-red-teaming-for-ai-safety&quot;&gt;a bit about frontier threats red-teaming&lt;&#x2F;a&gt;, a bit because it‚Äôs mostly focused on biorisk. Good luck, everyone! Paul coming out swinging with a very compelling pitch on sharing &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;fRSj2W4Fjje8rQWm9&#x2F;thoughts-on-sharing-information-about-language-model#Context&quot;&gt;LLM capabilities&lt;&#x2F;a&gt;, with a subheader that accelerating agents in particular is neutral. &lt;&#x2F;p&gt;
&lt;p&gt;The highlight of this months Hillel Wayne is &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;more-software-projects-need-defenses-of-design&#x2F;&quot;&gt;in favour of defenses of design&lt;&#x2F;a&gt;. I read a bit of SemiAnalysis this month too (Gemini and TPU shenanigans, sigh), and have shamefully declared Matt Levine bankruptcy and only followed for the Sculptor Saga. Spencer Greenberg published this month on &lt;a href=&quot;https:&#x2F;&#x2F;www.spencergreenberg.com&#x2F;2023&#x2F;07&#x2F;false-beliefs-held-by-intellectual-giants&#x2F;&quot;&gt;smart people with dumb beliefs&lt;&#x2F;a&gt;, for which one must also see this video of &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HKTSaezB4p8&amp;amp;ab_channel=sdfhsfh&quot;&gt;Feynman singing about orange juice&lt;&#x2F;a&gt; to make fun of Pauling‚Äôs vitamin C phase. Man being an olympic host basically turns your city into a charter city for a few years? They‚Äôre &lt;a href=&quot;https:&#x2F;&#x2F;time.com&#x2F;6261729&#x2F;seine-clean-up-paris-olympics-2024&#x2F;&quot;&gt;spending a billion dollars&lt;&#x2F;a&gt; to &lt;a href=&quot;https:&#x2F;&#x2F;www.countryandtownhouse.com&#x2F;culture&#x2F;river-seine-clean-up-paris&#x2F;&quot;&gt;clean the Seine&lt;&#x2F;a&gt;. I learned about the &lt;a href=&quot;https:&#x2F;&#x2F;www.wallpaper.com&#x2F;design&#x2F;celebrating-eighty-years-of-artek-wood-bending-technique&quot;&gt;wood-bending techniques&lt;&#x2F;a&gt; for the very expensive Artek Aalto stools, and I‚Äôm into it.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | May&#x2F;June 2023</title>
		<published>2023-07-03T00:00:00+00:00</published>
		<updated>2023-07-03T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jun-jul-2023/"/>
		<link rel="alternate" href="https://kipp.ly/jun-jul-2023/" type="text/html"/>
		<id>https://kipp.ly/jun-jul-2023/</id>
		<content type="html">&lt;p&gt;A unique yet simple &lt;a href=&quot;https:&#x2F;&#x2F;yoshuabengio.org&#x2F;2023&#x2F;05&#x2F;22&#x2F;how-rogue-ais-may-arise&#x2F;&quot;&gt;case for rogue AGI&lt;&#x2F;a&gt; from Bengio. &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;index&#x2F;claudes-constitution&quot;&gt;Claudestitution&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2212.03827&quot;&gt;Paper&lt;&#x2F;a&gt; on eliciting truth without external ground truth from the residual streams. Really packed &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.00805&quot;&gt;80 page paper&lt;&#x2F;a&gt; on conditioning models, I read it in one sitting it was awesome. Trick &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;vwu4kegAEZTBtpT6p&#x2F;thoughts-on-the-impact-of-rlhf-research&quot;&gt;reflections on RLHF&lt;&#x2F;a&gt; from Christiano. Preparing myself for &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;jwhcXmigv2LTrbBiB&#x2F;success-without-dignity-a-nearcasting-story-of-avoiding&quot;&gt;success without dignity&lt;&#x2F;a&gt;, non-zero chance that the solution to alignment is really good RLHF. &lt;a href=&quot;https:&#x2F;&#x2F;www.apolloresearch.ai&#x2F;blog&#x2F;announcement&quot;&gt;Apollo Research&lt;&#x2F;a&gt; (Conjecture fork) announcement with a research agenda I quite like. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.04388.pdf&quot;&gt;Languages Models Don‚Äôt Always Say What They Think&lt;&#x2F;a&gt;, a good line of thinking to go down for alignment.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10601&quot;&gt;Tree of Thought paper&lt;&#x2F;a&gt;, which was well done and nifty though I don‚Äôt think the premise will be fruitful. A pretty good shot at replacements for tokenizers with &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.07185.pdf&quot;&gt;(mega)byte&lt;&#x2F;a&gt;-level models. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.01116.pdf&quot;&gt;Thorough data paper&lt;&#x2F;a&gt; with really awesome figures. Gwern &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;t9svvNPNmFf5Qa3TA&#x2F;mysteries-of-mode-collapse&quot;&gt;comment&lt;&#x2F;a&gt; on mode collapse with CAI&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;ai.google&#x2F;static&#x2F;documents&#x2F;palm2techreport.pdf&quot;&gt;PaLM2‚Äôs tech report&lt;&#x2F;a&gt;, which doesn‚Äôt contain the unfortunate leak that it was 3x undertrained. I‚Äôm kind of glad to see &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2304.12404.pdf&quot;&gt;tokenizer work&lt;&#x2F;a&gt; happening. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2210.03057.pdf&quot;&gt;Multilingual chain-of-thought&lt;&#x2F;a&gt;. Evaluating &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.10266.pdf&quot;&gt;bilingualism in PaLM&lt;&#x2F;a&gt;. Loose &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;shayne-longpre&#x2F;a-pretrainers-guide&#x2F;blob&#x2F;main&#x2F;A%20Pretrainer&amp;#x27;s%20Guide%20To%20Training%20Data.pdf&quot;&gt;thinking about data mixes&lt;&#x2F;a&gt;. Thoughts of &lt;a href=&quot;https:&#x2F;&#x2F;semaphore.substack.com&#x2F;p&#x2F;principled-progress&quot;&gt;designing progress for AGI&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;alphadev-discovers-faster-sorting-algorithms&quot;&gt;DeepMind optimises their lil mov instructions&lt;&#x2F;a&gt;. I reread the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2210.02414.pdf&quot;&gt;GLM paper&lt;&#x2F;a&gt; in desperation of inspiration for multilingual. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.11644.pdf&quot;&gt;Another paper&lt;&#x2F;a&gt; towards ‚Äúdata is all you need‚Äù. Inflection‚Äôs perfectly typeset &lt;a href=&quot;https:&#x2F;&#x2F;inflection.ai&#x2F;assets&#x2F;Inflection-1_0622.pdf&quot;&gt;tech ‚Äúmemo‚Äù&lt;&#x2F;a&gt; on their LMs.&lt;&#x2F;p&gt;
&lt;p&gt;The Blackberry movie was the best thing I‚Äôve ever seen, it so perfectly captured how startup founders go insane and start believing deranged things about their company. Also had an iconic line where when Jim asked Mike something about ‚Äúi thought these were the best engineers in the world‚Äù and the quote from the movie was ‚ÄúI didn‚Äôt say they were the best engineers in the world, I said they were the best engineers in Canada.‚Äù Anyway, I combed through the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;BlackBerry&quot;&gt;Blackberry wikipedia page&lt;&#x2F;a&gt; after that to keep my facts straight. Unrelated wikipedia pages: &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Model_organism&quot;&gt;model organisms&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aquatic_ape_hypothesis&quot;&gt;the aquatic ape hypothesis&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Copy_Exactly!&quot;&gt;Copy Exactly!&lt;&#x2F;a&gt; Design for &lt;a href=&quot;https:&#x2F;&#x2F;blog.getdaft.io&#x2F;p&#x2F;introducing-daft-a-high-performance&quot;&gt;more reasonable dataframes&lt;&#x2F;a&gt; in python.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;thebulletin.org&#x2F;2022&#x2F;11&#x2F;investing-in-pandemic-prevention-is-essential-to-defend-against-future-outbreaks&quot;&gt;Investing in pandemic prevention&lt;&#x2F;a&gt;. Learning about &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;bathing-banya&quot;&gt;communal baths&lt;&#x2F;a&gt;, from the archives of boot boyz. Reddit still comes through with this &lt;a href=&quot;https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;berkeley&#x2F;comments&#x2F;13hv95y&#x2F;i_survived_living_in_la_and_commuting_to_cal_by&quot;&gt;guy who commuted to UC Berkeley from LA&lt;&#x2F;a&gt;. I attempted to read a few of &lt;a href=&quot;https:&#x2F;&#x2F;mitpress.mit.edu&#x2F;9780262535304&#x2F;zizeks-jokes&#x2F;&quot;&gt;Zizek‚Äôs Jokes&lt;&#x2F;a&gt;, it was the worst fucking book. Short story about morality in the grand schemes: &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;GJgudfEvNx8oeyffH&#x2F;the-ants-and-the-grasshopper&quot;&gt;The ants and the grasshopper&lt;&#x2F;a&gt;. Manifold Markets &lt;a href=&quot;https:&#x2F;&#x2F;news.manifold.markets&#x2F;p&#x2F;manifold-predicted-the-ai-extinction&quot;&gt;leaked the AI extinction letter&lt;&#x2F;a&gt;, and purposely has it be this way and I like it? My leaving Cohere was &lt;a href=&quot;https:&#x2F;&#x2F;manifold.markets&#x2F;market&#x2F;will-carol-chen-still-be-at-coherea&quot;&gt;also leaked by Manifold&lt;&#x2F;a&gt; lol. Some fairly safe &lt;a href=&quot;https:&#x2F;&#x2F;bounded-regret.ghost.io&#x2F;what-will-gpt-2030-look-like&quot;&gt;forecasts&lt;&#x2F;a&gt; on what GPT 2030 will look like from Jacob Steindhart. Devon Zuegel on why &lt;a href=&quot;https:&#x2F;&#x2F;devonzuegel.com&#x2F;post&#x2F;america-s-hidden-urban-laboratory-the-south&quot;&gt;all the good urbanism in the US is in the south&lt;&#x2F;a&gt;. A &lt;a href=&quot;https:&#x2F;&#x2F;archiveofourown.org&#x2F;works&#x2F;15489495&quot;&gt;really cute short story about dogs&lt;&#x2F;a&gt; that made me cry. &lt;a href=&quot;https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2023&#x2F;03&#x2F;13&#x2F;agnes-callard-profile-marriage-philosophy&quot;&gt;Agnes Callard‚Äôs profile&lt;&#x2F;a&gt; in the New Yorker is so based, I love her. Do you want a living room that looks exactly like mine? Check out &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;HJNtrNHf688FoHsHM&#x2F;guide-to-rationalist-interior-decorating&quot;&gt;the guide to rationalist interior decorating&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Book: Rats&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Upon moving to Sat Francisco, I &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;sept-oct-2022&#x2F;&quot;&gt;read&lt;&#x2F;a&gt; Cool Gray City of Love and immediately wished for an equivalent for New York (I lived there on and off). It would be hard to do as a book about New York, as the cuteness of CGCL came from the fact that most of the chapters weren‚Äôt about the Gold Rush or Summer of Love but about local history that could only be engaging to someone sitting on top of it. Maybe a book about a specific neighbourhood would cut it, but how could I choose a neighbourhood?&lt;&#x2F;p&gt;
&lt;p&gt;I found Rats (Robert Sullivan) at a Battery Park City housewarming in September where the book was not just recommended to me, but physically handed to me (which is the ultimate purpose of keeping one‚Äôs books collection). I lived in the Robert Moses part of town (Alphabet City) in May and begrudgingly thought about giving the Power Broker an attempt but then realised now was definitely the time to pick up Rats ‚Äî only to realise I had left it in San Francisco. Thankfully I returned in June and finished the book in a week. It lived up to my CGCL standard.&lt;&#x2F;p&gt;
&lt;p&gt;Sullivan and I disagree, in that I rather like rats, but the book could&#x27;ve surely had me mistaken. He never quite explains how someone who wouldn‚Äôt even fancy a fancy rat would spend a year researching and watching them ‚Äî even traveling to Chicago to meet an exterminator celebrity.&lt;&#x2F;p&gt;
&lt;p&gt;The book pops back in forth between the present of Sullivans rat adventures and history involving rats ranging from that Manhattan dentist who tried to shoot the rats on Rikers to the role of rats in plague over centuries. It covers the animal rights activists who tried to stop rat fights and the sanitation worker strike of NYC. Rats ends with a beautiful memo to the type it uses and has the greatest cover ‚Äî look it up!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Jan&#x2F;Feb&#x2F;Mar&#x2F;Apr 2023</title>
		<published>2023-05-21T00:00:00+00:00</published>
		<updated>2023-05-21T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jan-feb-mar-apr-2023/"/>
		<link rel="alternate" href="https://kipp.ly/jan-feb-mar-apr-2023/" type="text/html"/>
		<id>https://kipp.ly/jan-feb-mar-apr-2023/</id>
		<content type="html">&lt;p&gt;Bleak month, busy month.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.trentonbricken.com&#x2F;Tail-Free-Sampling&#x2F;&quot;&gt;Derivative of top-p (nucleus) sampling&lt;&#x2F;a&gt;, with really good theoretical reasoning as to why this should work better. &lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;gpt-4.pdf&quot;&gt;GPT-4 Technical Report&lt;&#x2F;a&gt;, amazing author list format and impressive results and safety measures. A clean and nifty paper studying &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2304.11158.pdf&quot;&gt;memorization in llms&lt;&#x2F;a&gt;, with a notable finding that some things are memorized ‚Äúright away‚Äù. Sander doing a really good explanation of &lt;a href=&quot;https:&#x2F;&#x2F;sander.ai&#x2F;2022&#x2F;01&#x2F;31&#x2F;diffusion.html&quot;&gt;diffusion models as autoencoders&lt;&#x2F;a&gt; which definitely went over my head. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2304.08467.pdf&quot;&gt;Gist Tokens paper&lt;&#x2F;a&gt;, which introduces a great technique to compress a prompt into a single token via masking (it‚Äôs so good I read it four times). &lt;a href=&quot;https:&#x2F;&#x2F;blog.eleuther.ai&#x2F;transformer-math&#x2F;&quot;&gt;Transformer Math 101&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Yay, a paper on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.03169.pdf&quot;&gt;dataset selection&lt;&#x2F;a&gt;, but it relies on having a target distribution to mimic. Paper on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.10149.pdf&quot;&gt;poisoning datasets&lt;&#x2F;a&gt; on the web, though it makes a strange assumption that people don‚Äôt keep their crawls and doesn‚Äôt make a significant impact. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.13509.pdf&quot;&gt;Data mixes in relation to in-context learning&lt;&#x2F;a&gt;, though the paper is explicitly wrong about a few things. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.01973.pdf&quot;&gt;Code language mix in relation to performance&lt;&#x2F;a&gt;, comes with some good eval and good but not super impactful results. I really enjoyed that paper because it calls Rust a ‚Äúlow resource‚Äù language lol.&lt;&#x2F;p&gt;
&lt;p&gt;Overview of &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;jtoPawEhLNXNxvgTT&#x2F;bing-chat-is-blatantly-aggressively-misaligned&quot;&gt;Bing Chat mishaps&lt;&#x2F;a&gt;. Janus &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;bxt7uCiHam4QXrQAA&#x2F;cyborgism&quot;&gt;on cyborgism&lt;&#x2F;a&gt;, which was impressive in that I thought we were at the boundaries of theoretical safety work. Tangential, the &lt;a href=&quot;https:&#x2F;&#x2F;sohl-dickstein.github.io&#x2F;2023&#x2F;03&#x2F;09&#x2F;coherence.html&quot;&gt;hot mess theory of AI misalignment&lt;&#x2F;a&gt;, which is well-formed though I disagree with it. Anthropic research on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.07459.pdf&quot;&gt;moral self-correction&lt;&#x2F;a&gt; came out! Turns out too many RLHF steps actually result in discriminating in favour of minorities. OpenAI on &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;how-should-ai-systems-behave&quot;&gt;how AI Systems should behave&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Reviewed Universal Distribution Absolute Self-Selection Assumption, from &lt;a href=&quot;https:&#x2F;&#x2F;putanumonit.com&#x2F;2023&#x2F;01&#x2F;04&#x2F;udassa&#x2F;&quot;&gt;yashkaf&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;QmWNbCRMgRBcMK6RK&#x2F;the-absolute-self-selection-assumption&quot;&gt;Paul Christiano&lt;&#x2F;a&gt; and it&#x27;s still not super deep in my head. Ben Kuhn &lt;a href=&quot;https:&#x2F;&#x2F;www.benkuhn.net&#x2F;leaving&#x2F;&quot;&gt;goes to Anthropic&lt;&#x2F;a&gt;, bringing with him &lt;a href=&quot;https:&#x2F;&#x2F;www.benkuhn.net&#x2F;newmgr&#x2F;&quot;&gt;tips for new managers&lt;&#x2F;a&gt;. I love to be reminded that diet restriction for climate and welfare are inversely correlated and &lt;a href=&quot;https:&#x2F;&#x2F;www.vox.com&#x2F;future-perfect&#x2F;23639475&#x2F;pescetarian-eating-fish-ethics-vegetarian-animal-welfare-seafood-fishing-chicken-beef-climate&quot;&gt;shrimp suffer&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;http:&#x2F;&#x2F;www.searsarchives.com&#x2F;catalogs&#x2F;history.htm&quot;&gt;History of the Sears Catalog&lt;&#x2F;a&gt;, I also read the catalog of course. Highlight for me was that the low-tier appliance line was called &amp;quot;challenge&amp;quot; as in &amp;quot;challenge toaster&amp;quot;, &amp;quot;challenge waffle iron&amp;quot;, etc. A surprisingly coherent Boot Boyz Biz article on &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;las-vegas-duck&quot;&gt;oddly shaped buildings&lt;&#x2F;a&gt;. BBB &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;oblique-strategies-v3&quot;&gt;cards I failed to acquire for trying times&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;A document that is not public and not related to AI, if we‚Äôre friends let‚Äôs talk about it ‚Äî it rocked.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;short-books-letters-to-a-young-poet-and-preliminary-materials-for-a-theory-of-the-young-girl&quot;&gt;Short Books: Letters to a Young Poet and Preliminary Materials for a Theory of the Young-Girl&lt;&#x2F;h3&gt;
&lt;p&gt;People cringed at me for reading this commonly remixed text while not being a poetry enjoyer or having read any of Rilke‚Äôs writings at all, but I just can‚Äôt enjoy poetry! Poetry is one of those things where it hits really hard at the right place and right time, and that comes much less easily to me (or you care about literature). Letters to a Young Poet was really good, my favourite part was the care in all the correspondence, I don‚Äôt think there was ever a time or person during which I exercised that care. All the remixes are attempts to provide guidance, but I‚Äôd kind of like to see attempts that are more about nostalgia, reflection and reminiscence.&lt;&#x2F;p&gt;
&lt;p&gt;Insofar as I can enjoy poetry, it‚Äôs because it sort of performs the secondary purpose of philosophy (the first of which is obviously, being correct) which is to express particular feelings felt in particular times. The Theory of the Young-Girl is certainly not correct, but it really does capture particular feelings at particular times. Every line has its own font!! It lands so well, and does a great job at capturing some particular feelings I have, including the ones that aren‚Äôt correct.&lt;&#x2F;p&gt;
&lt;p&gt;Some lines I enjoyed:&lt;&#x2F;p&gt;
&lt;p&gt;Love for the Young-Girl is just autism for two&lt;&#x2F;p&gt;
&lt;p&gt;Look on the bright side, since History‚Äôs happening on the dark side [this one really needs to typography to land]&lt;&#x2F;p&gt;
&lt;p&gt;The Young-Girl is never worried about herself, but only about her &lt;em&gt;value&lt;&#x2F;em&gt;. Thus when she encounters hatred, she is struck by doubt: Has her market value dropped?&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Transformer Taxonomy (the last lit review)</title>
		<published>2023-03-30T00:00:00+00:00</published>
		<updated>2023-03-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/transformer-taxonomy/"/>
		<link rel="alternate" href="https://kipp.ly/transformer-taxonomy/" type="text/html"/>
		<id>https://kipp.ly/transformer-taxonomy/</id>
		<content type="html">&lt;p&gt;This document is my running literature review for people trying to catch up on AI. It covers 22 models, 11 architectural changes, 7 post-pre-training techniques and 3 training techniques (and 5 things that are none of the above). Everything is very loosely in order of importance and somewhat uniqueness. All papers will link to the actual PDF and not the ArXiv page and the selection is mostly curated based on things I know about. Systems&#x2F;performance and alignment are excluded for this one because they‚Äôre my favourite and I‚Äôd want to do it more justice. Alignment research is really important, I hope to do it justice some day! Also probably not all the papers in the model list are worth reading.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-models&quot;&gt;1. Models&lt;&#x2F;h2&gt;
&lt;p&gt;If a property is unspecified it‚Äôs either undisclosed or follows approximately the standard GPT recipe.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GPT-3&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2005.14165.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;175B params, 96 layers, 12288 embd dim, 96 heads ‚Äî OpenAI May 2020&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This was a seminal paper for large language models, following the &lt;a href=&quot;https:&#x2F;&#x2F;d4mucfpksywv.cloudfront.net&#x2F;better-language-models&#x2F;language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;GPT-2 paper&lt;&#x2F;a&gt; (2018) and the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2001.08361.pdf&quot;&gt;scaling laws paper&lt;&#x2F;a&gt;. It was trained on a 300B token dataset consisting mostly of filtered Common Crawl, along with some books, webtext and Wikipedia. BPE tokenizer (same from GPT-2). 2048 context length. Alternates dense and sparse attention layers. Warms up to 0.6 √ó 10^‚àí4 learning rate in the first 375M toks, cosine decayed to 10% after 260B toks. Batch size ramp from 32k toks to 3.2M toks over the first 12B tokens. 4x MLP projection ratio as done in the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1706.03762.pdf&quot;&gt;2017 transformer paper&lt;&#x2F;a&gt;. 50k vocab size. Many of these characteristics (e.g. embd dim = 128 * layers, 4x MLP projection ratio, and LR and batch size ramp) form a standard recipe that has been reused by later models.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;there‚Äôs a probably-typo in Table 2.1 that documents the hyperparameters, where GPT-3 13B is labelled as having an embedding dimension of 5140 which should probably be 5120&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GPT-4&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2303.08774.pdf&quot;&gt;technical report&lt;&#x2F;a&gt;] ‚Äî &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Released March 2023, finished pre-training August 2022&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Man, feels awkward to write a pathetic summary of something this big, but here goes: GPT-4 is a model available through OpenAI of unknown architecture (other than that it‚Äôs GPT-like, though they only technically specify transformer-like). The technical report contains mostly evals (which performed well of course), as well as the results of their continued scaling which are accurately extrapolated from smaller models. The report also documents safety mitigation and has a demo of their multi-modal capabilities of GPT-4 which seem trained in √† la Flamingo. It also has the best Acknowledgements section of all time.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Gopher&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.11446.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;280B params, 260B non-embedding params, 80 layers, 16384 embd dim, 128 heads ‚Äî DeepMind Dec 2021&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;DeepMind‚Äôs first large language model release in 2021. It uses an RMSNorm instead of a LayerNorm, uses a relative positional encoding scheme from Transformer-XL instead of an absolute positional encoding, which is why there are so many embedding parameters. Tokenizes with SentencePiece, vocab size 32k. Trained on 300B tokens, with half being from MassiveText which was collected for Gopher, along with books, Common Crawl, Wikipedia, news and Github. Note that Gopher was actually trained end of 2020 and released a year later.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;AlphaCode&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.07814.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 41B,  8 encoder layers, 56 decoder layers, 6144 embd dim ‚Äî DeepMind Feb 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A model trained on 715GB(967B tokens) of code to do competitive programming. The only model on this list with an encoder-decoder architecture, it treated contest programming as a translation task (problem statement ‚Üí solution) to gain bidirectionality. It uses 1536 tokens in the encoder and 768 tokens in the decoder. Uses multi-query attention, and generates thousands of samples at inference time and then selects a subset of solutions to submit.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;RETRO&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.04426.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;7B parameters ‚Äî DeepMind Feb 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Retrieval is the general technique if giving a model a database to look up while doing inference. RETRO was the inaugural retrieval paper for transformers, using a 2T token database. It embeds the token-database in chunks using a pretrained BERT-style model and then performs chunked cross-attention to nearest neighbors in the database during training and inference&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GPT-3.5&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;beta.openai.com&#x2F;docs&#x2F;model-index-for-researchers&quot;&gt;docs&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;architecture unknown ‚Äî OpenAI Mar 2022&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;em&gt;

OpenAI delineates three models as GPT-3.5, specifically anything in the &lt;code&gt;davinci-002&lt;&#x2F;code&gt; or &lt;code&gt;davinci-003&lt;&#x2F;code&gt; family. &lt;code&gt;code-davinci-002&lt;&#x2F;code&gt; is the base model, &lt;code&gt;text-davinci-002&lt;&#x2F;code&gt; is a version with FeedME non-RL instruction tuning, and &lt;code&gt;text-davinci-003&lt;&#x2F;code&gt; is an InstructGPT with RLHF. There is an InstructGPT paper that trains an RLHF model and does not mention FeedME, and though &lt;code&gt;text-davinci-002&lt;&#x2F;code&gt; is an InstructGPT model it does not use RLHF. The &lt;code&gt;davinci&lt;&#x2F;code&gt; model on the OpenAI API is noted to be the 175B model in the 2020 paper, but it‚Äôs never confirmed whether &lt;code&gt;davinci-002&lt;&#x2F;code&gt; is the same size.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Chinchilla&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.15556.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;70B params, 80 layers, 8192 embd dim, 64 heads ‚Äî DeepMind Mar 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;With the paper titled &amp;quot;Training Compute-Optimal Large Language Models‚Äù, new and improved scaling laws were introduced. Chinchilla is trained with 1.5T tokens (similar dataset as Gopher) and same amount of compute as Gopher, yet outperforms it. Results in scaling laws that have parameters and tokens linearly increase at a 20:1 token to parameter ratio. Learning rate adjusts with a cosine schedule. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2201.11990.pdf&quot;&gt;Megatron Turing NLG&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;uploads-ssl.webflow.com&#x2F;60fd4503684b466578c0d307&#x2F;61138924626a6981ee09caf6_jurassic_tech_paper.pdf&quot;&gt;Jurassic J-1 Jumbo&lt;&#x2F;a&gt; are two other large models that aren‚Äôt documented here as they are not Chinchilla optimal and aren‚Äôt uniquely significant.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Flamingo&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.14198.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 80B params ‚Äî DeepMind Apr 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Flamingo is a multi-modal (text and image) model. It only generates text, and image inputs are run through a vision encoder (435M params), and cross-attention is used to attend to those outputs. It also uses a resampler (194M params) after the vision encoder to produce a fixed (small) number of visual tokens no matter the number of input features. They build on frozen Chinchilla models, the 80B params come from the cross-attention layers added to the 70B Chinchilla model. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.06794.pdf&quot;&gt;PaLI&lt;&#x2F;a&gt; is a Google model that follows up on image&#x2F;language multimodal.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Gato&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.06175.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 1.18B params ‚Äî May 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Gato is a generalist agent, sort of a follow up to Flamingo with more modalities. It uses images and text, as well as button-press data formatted into tokens, as well as encodings of continuous data from robotics propioception, trying to use as little data as possible for additional tasks. The tasks include robotics stacking tests, image captioning, and Atari.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Anthropic LM&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.00861.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 52B params, 64 layers, 8192 embd dim ‚Äî Anthropic Dec 2021&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Trained on 400B tokens, though in a &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.05221.pdf&quot;&gt;later, post-Chinchilla paper&lt;&#x2F;a&gt;, Anthropic used a model with the same architecture trained for 850B tokens. And in yet another later paper on &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.07459.pdf&quot;&gt;moral self-correction&lt;&#x2F;a&gt;, a 175B with no other specified properties is used.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;PaLM&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.02311.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 540B params, 118 layers, 18432 embd dim, 48 heads ‚Äî Google Apr 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Current (as of Jan 2023) largest publicly known dense language model, unfortunately pre-Chinchilla. PaLM activates with SwiGLU, uses parallel attention, multi-query attention, rotary embeddings and uses the same matrices for input and output embeddings. No biases were used and a SentencePiece tokenizer with 256k tokens was used. PaLM was trained on 780B tokens, on a similar dataset as LaMDA and GLaM.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GPT-NeoX&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;EleutherAI&#x2F;gpt-neox&quot;&gt;github&lt;&#x2F;a&gt;][&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.06745.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;20B params ‚Äî Eleuther AI Feb 2022&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;An Eleuther open-sourced model, trained on GPUs with &lt;a href=&quot;https:&#x2F;&#x2F;www.deepspeed.ai&#x2F;&quot;&gt;DeepSpeed&lt;&#x2F;a&gt; (microsoft) and &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;Megatron-LM&quot;&gt;Nvidia Megatron&lt;&#x2F;a&gt;. It uses the same architectural modifications that GPT-J had and is trained on the entirety of Pile, 400B tokens.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GPT-J&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kingoflolz&#x2F;mesh-transformer-jax&#x2F;#gpt-j-6b&quot;&gt;github&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;6.7B params ‚Äî Eleuther AI Jul 2021&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Notable for being a fully open-sourced model, while matching the 6.7B performance from the GPT-3 paper. Trained on TPUs, and done with rotary embeddings, parallel attention. Only dense attention layers are used to reduce complexity. It was trained on &lt;a href=&quot;https:&#x2F;&#x2F;pile.eleuther.ai&#x2F;&quot;&gt;the Pile&lt;&#x2F;a&gt;, an open dataset created by Eleuther AI which contains 22 smaller datasets including Common Crawl, OpenWebText, books and papers.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;GLaM&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.06905.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 1.2T parameters ‚Äî Google Dec 2021&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Named ‚ÄúGeneralist Language Model‚Äù, GLaM is a Mixture-of-Experts (MoE) model, where parameters are sparsely activated. It has 64 experts per layer, with each token activating 96.6B parameters. Each layer has a gating unit which selects one two of the 64 MLPs per each token&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;LaMDA&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2201.08239.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;137B params, 64 layers, 8192 embd dim, 128 heads  ‚Äî Google (demoed at I&#x2F;O May 2021; paper posted Jan 2022)&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Dialog model made to follow &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2001.09977.pdf&quot;&gt;Meena&lt;&#x2F;a&gt;. A 2.81T dataset with a lot of dialog&#x2F;forums (encoded with a 32k vocab size SentencePiece tokenizer) is specified. The base model is sometimes called LaMDA GLM or GLM-137B; LaMDA itself adds a lot of dialog finetuning on top.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Though it‚Äôs explicit how many tokens the model was trained for. It does specify 1024 TPUv3 chips at 56.5% utilisation for 57.7 days, batch size 256k, probably bf16, and arithmetic says that would be about 900B of the 2.81T tokens.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Switch&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2101.03961.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 1T parameters ‚Äî Google Jun 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;An improvement on GLaM, SwitchTransformer only routes to one expert, reducing the amount of compute. It using a different routing mechanism, with the main update being that routing to a single expert works.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;BLOOM&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.05100.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;176B params, 70 layers, 14336 embd dim, 112 heads ‚Äî HuggingFace July 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Current largest open-source model. Trained on a HuggingFace corpus called ROOTS, which is 498 HuggingFace datasets. The model was trained for 366B tokens. Positional encodings was done with ALiBi. 250k vocab size BPE tokenizer, to help accommodate for multilingual data.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Galactica&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.09085.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 120B parameters ‚Äî Meta Nov 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Galactica is a science model pretrained mostly on papers, along with small amounts of code, other knowledge-based data and a bit of common crawl. It uses a &lt;code&gt;&amp;lt;work&amp;gt;&lt;&#x2F;code&gt; token to encode working memory, as well as special tokens for citations.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;LLaMa&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;scontent-sjc3-1.xx.fbcdn.net&#x2F;v&#x2F;t39.8562-6&#x2F;333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&amp;amp;ccb=1-7&amp;amp;_nc_sid=ad8a9d&amp;amp;_nc_ohc=ov6yTHfLfNQAX82vXIA&amp;amp;_nc_ht=scontent-sjc3-1.xx&amp;amp;oh=00_AfAg4KoJmp5lBEyThQ9XAh24xKRPZ-wVH1UWh4euhxSy8w&amp;amp;oe=63FFCFA2&quot;&gt;paper&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 65B parameters ‚Äî Meta Feb 2023&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Chinchilla replication. Fairly standard training mix of mostly Common Crawl.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Jurassic J1-Grande v2&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.14198.pdf&quot;&gt;paper&lt;&#x2F;a&gt; for v1][&lt;a href=&quot;https:&#x2F;&#x2F;crfm.stanford.edu&#x2F;helm&#x2F;latest&quot;&gt;helm evals&lt;&#x2F;a&gt;] &lt;em&gt;‚Äî 17B parameters ‚Äî AI21 Dec 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;No information other than the Helm results, which look really good for the size!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;OPT&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.01068.pdf&quot;&gt;paper&lt;&#x2F;a&gt;][&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;metaseq&#x2F;blob&#x2F;main&#x2F;projects&#x2F;OPT&#x2F;chronicles&#x2F;OPT175B_Logbook.pdf&quot;&gt;train logbook&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;175B params, same arch as GPT-3 ‚Äî Meta May 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Meta replication of GPT-3. Trains on the Pile and PushShift reddit, for only 180B tokens.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Meta papers aren‚Äôt at all connected projects. LLama, OPT and Galactica share only one author of 41.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;GLM-130B&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2210.02414.pdf&quot;&gt;paper&lt;&#x2F;a&gt;] ‚Äî &lt;em&gt;130B params ‚Äî Tsinghua University Oct 2022&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;GLM is an open-sourced bilingual (Chinese and English) model. It uses rotary embeddings, DeepNorm, and activates the MLP with GeGLU. It notably inferenced in INT4 (where other models like BLOOM and OPT had quantized to INT8). It also includes prompts in pretraining Instead of the standard GPT architecture, it uses GLM for bidirectional attention.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-architectural-changes&quot;&gt;2. Architectural Changes&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Multi-Query Attention&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1911.02150.pdf&quot;&gt;Noam Shazeer solo paper&lt;&#x2F;a&gt;, where the key and values are shared across heads, greatly reducing the amount of memory required at inference time, improving latency and throughput. It‚Äôs a perfectly concise barely 9 page paper complete with code and results so it feels silly to describe further. AlphaCode and PaLM both use multi-query.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Sparse Attention&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1904.10509.pdf&quot;&gt;sparse transformer paper&lt;&#x2F;a&gt;] ‚Äî Sparse attention is a mechanism where attention is not applied to all previous tokens. It describes two styles of the SparseTransformer, strided where it looks at the last N tokens, and then fixed where sections of tokens in the sequence are attended to. In the GPT-3 paper, the model is described to have alternating dense and ‚Äúlocally banded‚Äù sparse layers.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Mixture-of-Experts&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There‚Äôs a lot more lore on MoE, and I already gave the one-liner in describing GLaM and Switch so here I‚Äôll just give an good initial literature list!&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1701.06538&quot;&gt;original MoE paper&lt;&#x2F;a&gt; from 2017 on LSTMs&lt;&#x2F;li&gt;
&lt;li&gt;Deepmind Scaling Laws &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.01169.pdf&quot;&gt;paper&lt;&#x2F;a&gt; for MoE&lt;&#x2F;li&gt;
&lt;li&gt;Meta &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.10684.pdf&quot;&gt;paper&lt;&#x2F;a&gt; that trains a 1.1T param MoE&lt;&#x2F;li&gt;
&lt;li&gt;A &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.08906.pdf&quot;&gt;large&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.09368.pdf&quot;&gt;pool&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.10937.pdf&quot;&gt;of&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.08906.pdf&quot;&gt;Google&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=23ZjUGpjcc&quot;&gt;papers&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;FlashAttention&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.14135.pdf&quot;&gt;FlashAttention&lt;&#x2F;a&gt; is an architectural change to do attention with less memory access (most of costs in most cases). It tiles and incrementally performs the softmax reduction and avoids storing the whole intermediate attention matrix for the backwards pass. The paper cites 1.7x training speedup compared to megatron and up to over 4x on inference (with the multiplier increasing with longer context lengths). The same sort of approach achieving O(log_n) memory was done earlier on TPUs in &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.05682.pdf&quot;&gt;this paper&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Encoder+Decoder&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;

A la original &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1706.03762.pdf&quot;&gt;transformer paper&lt;&#x2F;a&gt;, the encoder decoder architecture was originally made for translation tasks. Where the classic GPT architecture are alternating attention and mlp blocks, the original transformer had an encoder block which was attention ‚Üí mlp and a decoder block which was masked attention ‚Üí encoder-decoder attention ‚Üí mlp. This is still a reasonable architecture to many kinds of sequence-to-sequence tasks, such as AlphaCode or &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1910.10683.pdf&quot;&gt;T5&lt;&#x2F;a&gt; (Google, 2019, 11B params).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Parallel Attention&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.02311.pdf&quot;&gt;PaLM&lt;&#x2F;a&gt; uses parallel attention (poorly named) where the model is trained with the attention and MLP layers run in parallel, taking the same vectors. This makes it so that you can do your attention and feed-forward matmuls together to increase arithmetic intensity for better performance (15% on PaLM). GPT-J also uses it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Activation Alternatives: GeGLU, SwiGLU, SoLU&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1706.03762.pdf&quot;&gt;original transformer paper&lt;&#x2F;a&gt; uses ReLU (Rectified Linear Unit) to activate the MLP block. It does the simple x if &amp;gt; x = 0 else 0 in between the two linear transformations (matmuls). Intuitively, this is a bit too no-brained. GeLU (Gaussian error) is similar to ReLU but smooths it out a bit. SoLU (Softmax) introduced by &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2022&#x2F;solu&#x2F;index.html&quot;&gt;this Anthropic paper&lt;&#x2F;a&gt;, is simply &lt;code&gt;x*softmax(x)&lt;&#x2F;code&gt; and is used to improve the interpretability of models. SwiGLU is the most sophisticated of the listed, and is a &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2002.05202.pdf&quot;&gt;Noam Shazeer solo paper&lt;&#x2F;a&gt;, as it came through ‚Äúdivine benevolence‚Äù. It builds upon gated linear units (meant to be more stable than ReLU) and does the swish operation before the GLU. Like GeLU, it softens out the ReLU and allows some values to be under zero.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;LayerNorm Alternatives: DeepNorm, RMSNorm&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;LLMs norm twice per block (once for attention, once to feed-forward), which does some normalisation function to improve training. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.00555.pdf&quot;&gt;DeepNorm&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1910.07467.pdf&quot;&gt;RMSNorm&lt;&#x2F;a&gt; are alternatives. RMSNorm (Root Mean Square) is simply the square root of the mean of the values. There‚Äôs also a batch norm that‚Äôs inefficient and seems silly to use.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;RoPE&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2104.09864.pdf&quot;&gt;paper&lt;&#x2F;a&gt;][&lt;a href=&quot;https:&#x2F;&#x2F;blog.eleuther.ai&#x2F;rotary-embeddings&#x2F;&quot;&gt;blog post&lt;&#x2F;a&gt;] ‚Äî I don‚Äôt want to try to summarize this one because there‚Äôs a good tl;dr in the blog post.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;BPE vs SentencePiece Tokenizers&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;

[[bpe](https:&#x2F;&#x2F;huggingface.co&#x2F;course&#x2F;chapter6&#x2F;5?fw=pt)][&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;sentencepiece&quot;&gt;sentence piece&lt;&#x2F;a&gt;] ‚Äî Byte Pair Encodings are the default for most language models, being used by the original GPT paper, GPT-3 and presumably (based on the API) GPT-3.5. An obvious reason to not use plain BPE (and instead use SentencePiece) is if your distribution doesn‚Äôt contain space separated words, as AlphaCode, GLM (Chinese) and PaLM (explicitly because multilingual) did.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;ALiBi&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2108.12409.pdf&quot;&gt;Attention with Linear Biases&lt;&#x2F;a&gt; is a long context positional embedding scheme to support extrapolation to longer lengths, by biasing (linearly) the qk scores according to their distance. BLOOM uses ALiBi and Galactica tried it though didn‚Äôt go through with it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-post-pre-training-techniques&quot;&gt;3. Post-Pre-Training Techniques&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;RLHF with PPO&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In RLHF, a reward model is trained, where the labeler evaluates an array of model generations. Then the PPO (&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1707.06347.pdf&quot;&gt;proximal policy optimization&lt;&#x2F;a&gt;) is used for the RL, where the policy generates an output evaluated by the reward model to improve on the policy.&lt;&#x2F;p&gt;
&lt;p&gt;Deepmind‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.14375.pdf&quot;&gt;Sparrow&lt;&#x2F;a&gt;, as well as Anthropic‚Äôs LMs are trained with RL(AI|H)F are have dialog interfaces. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.09332.pdf&quot;&gt;WebGPT&lt;&#x2F;a&gt; was was trained with RLHF, as was &lt;a href=&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes&#x2F;Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf&quot;&gt;GopherCite&lt;&#x2F;a&gt; (which called RLHPreferences). I‚Äôd say the origination was &lt;a href=&quot;https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper&#x2F;2017&#x2F;hash&#x2F;d5e2c0adad503c91f91df240d0cd4e49-Abstract.html&quot;&gt;Christiano 2017&lt;&#x2F;a&gt;, preceding any LLM stuff, followed by 2020 &lt;a href=&quot;https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper&#x2F;2020&#x2F;file&#x2F;1f89885d556929e98d3ef9b86448f951-Paper.pdf&quot;&gt;summarizing from human feedback&lt;&#x2F;a&gt;, along with the PPO paper.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Constitutional&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;An extension of RLHF, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2212.08073.pdf&quot;&gt;Constitutional&lt;&#x2F;a&gt; is basically RLAIF, though actually called ‚ÄúCAI‚Äù. It has a supervised learning phase where a helpful-only AI is used to generate adversarial prompts. The assistant then iterates on its own response based on the provided constitution (a short set of values for the model to follow in the form of a string). Then finetuning is done on those responses. The second stage then is like RLHF with PPO, except substituting the AI feedback.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Minerva&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Released in 2022 June from the Blueshift team, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2206.14858.pdf&quot;&gt;Minerva&lt;&#x2F;a&gt; is a finetuned model on math and science data, particularly well-executed. It‚Äôs a 62&#x2F;540B finetuned model from PaLM, with datasets from ArXiV and some websites that were carefully preprocessed to preserve mathematical formatting.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Codex&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Launched in July 2021 (and resulted in Github Copilot), &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2107.03374.pdf&quot;&gt;Codex&lt;&#x2F;a&gt; is a finetune on 100B tokens of code (in this case, publicly available Github code). The paper also debuted HumanEval, human written code evals. This paper most notably demonstrates that code data is really important for code performance, as GPT-J was outperforming 3 at code. They also added some tokens for code, which improved the compression by 30%.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Just Finetune on CoTed Outputs&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I forgot which paper did this but its like they finetuned their model on chain of thought outputs from the model, and it did better. Expected, but notable result.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;FeedME (SFT)&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Described in &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.02155.pdf&quot;&gt;Instruct GPT paper&lt;&#x2F;a&gt; (though it is not necessarily the origination, which is closer &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.08593&quot;&gt;to this&lt;&#x2F;a&gt;). Supervised Fine-Tuning uses human-generated content which is then used to fine-tune the pre-trained model. The paper finds that SFT performs better than base pre-trained models but RLHF performs better than SFT.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;FLAN&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2109.01652.pdf&quot;&gt;Flan&lt;&#x2F;a&gt; is an instruction-tuned model (finetuned on instruction-formatted nlp tasks) that results in improved zero-shot performance.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;4-training-techniques&quot;&gt;4. Training Techniques&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Being&lt;&#x2F;strong&gt; &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Good at Setting Hyperparameters&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;

There is obviously no one paper for this, but obviously getting the hyperparameters right is pretty important. Some baseline is available by reading papers, with the most notable probably being &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.15556.pdf&quot;&gt;Chinchilla&lt;&#x2F;a&gt; or the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2001.08361.pdf&quot;&gt;Scaling Laws paper&lt;&#x2F;a&gt;. There are also a bunch of good theory-based papers, though the one I am familiar with is actually this Jane Street &lt;a href=&quot;https:&#x2F;&#x2F;blog.janestreet.com&#x2F;does-batch-size-matter&#x2F;&quot;&gt;blog post on understanding batch size&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Pre-training with Human Feedback&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Pre-training tends to have a very unsupervised format, though &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.08582.pdf&quot;&gt;PHF&lt;&#x2F;a&gt;(Feb 2023) applies a simple technique to label data at pretraining. It uses two conditioning tokens (good and bad) prepended to samples at training and then samples with them at inference. They tried various other objectives (notably, filtering out bad data) that all performed worse, evaluated on python styling, PII and toxicity.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;MuP&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.03466.pdf&quot;&gt;Maximal Update Parameterization&lt;&#x2F;a&gt; is a method of parameterization that makes hyperparameters (the ones related to learning rates and optimisers) predictable (consistent) across model sizes. It not only saves the parameter sweep compute but should also be closer to optimal. The paper does a really good job getting into the theory of why this works.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;none-of-the-above&quot;&gt;None of the Above&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Chain of Thought&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is a technique where it makes the model think ‚Äústep-by-step‚Äù and yielding better results. That name originated in &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2201.11903.pdf&quot;&gt;this paper&lt;&#x2F;a&gt;, which describes a specific application of the technique described in this February 2021 &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2102.07350.pdf&quot;&gt;paper&lt;&#x2F;a&gt; which describes ways to do prompting that aren‚Äôt just few-shotting. The phrase now is sometimes used to describe techniques that aren‚Äôt just prompting.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Tool Use&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A good canonical tool use paper is probably the Dec 2021 &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.09332.pdf&quot;&gt;WebGPT paper&lt;&#x2F;a&gt; (though the earliest paper I can find is probably this &lt;a href=&quot;https:&#x2F;&#x2F;proceedings.mlr.press&#x2F;v70&#x2F;shi17a.html&quot;&gt;2017 Karpathy paper&lt;&#x2F;a&gt;), in which capabilities are greatly enhanced by giving GPT-3 access to the web. It is finetuned with some RL and SL, though I put this not as a training or post-pretraining technique since the concept is not dependent on that. DeepMind also trained &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2202.08137.pdf&quot;&gt;RL tool use agents&lt;&#x2F;a&gt;, and Meta has &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.04761.pdf&quot;&gt;toolformer&lt;&#x2F;a&gt; which does finetuning focused on API usage.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Fill In the Middle&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This July 2022 &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.14255.pdf&quot;&gt;paper&lt;&#x2F;a&gt; describes a simple data transformation which moves a substring from the middle of a text to the end, and asks the model to fill in the middle. This allows the model to gain a capability that is really useful for tasks like code completion without damage to performance on strictly left to right tasks.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Sampling Techniques: Top-k, Top-p (nucleus), Beam Search&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The output of language models is fundamentally logits for every possible token, which are then softmaxed into becoming probabilities. The most naive way of turning your logits into tokens, is to take the most likely token. When there are temperature controls with language models, it‚Äôs dividing the logits by the temperature, which makes the model more&#x2F;less confident in its top choice. Top-K sampling takes the top K tokens and samples from that distribution. Top-P sampling (it has a &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1904.09751.pdf&quot;&gt;paper&lt;&#x2F;a&gt; but it‚Äôs probably useless), or nucleus sampling, uses the top P percentage (think CDFs) of tokens and samples from there.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Tail Free Sampling&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.trentonbricken.com&#x2F;Tail-Free-Sampling&#x2F;&quot;&gt;Tail Free Sampling&lt;&#x2F;a&gt; takes the derivative of top-P sampling, and is named as such to find the ‚Äútail‚Äù, as top-P sampling could fail in cases of being cut off at a point where many tokens have similar probabilities. The post linked details the theoretical reasons this should result in better sampling, but when it comes to improving creativity and range in the models there are no good benchmarks.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;This feels particularly good to publish now since i feel like its ~the last time something like this could be helpful, given how close we are and the diminishing amount of published research.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Edited by Claude &amp;lt;3&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Nov&#x2F;Dec 2022</title>
		<published>2023-02-18T00:00:00+00:00</published>
		<updated>2023-02-18T00:00:00+00:00</updated>
		<link href="https://kipp.ly/nov-dec-2022/"/>
		<link rel="alternate" href="https://kipp.ly/nov-dec-2022/" type="text/html"/>
		<id>https://kipp.ly/nov-dec-2022/</id>
		<content type="html">&lt;p&gt;Ben Kuhn on staring into the &lt;a href=&quot;https:&#x2F;&#x2F;www.benkuhn.net&#x2F;abyss&#x2F;&quot;&gt;abyss&lt;&#x2F;a&gt; as a core life skill. Bad Idea: it‚Äôs all about &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hydraulic_empire&quot;&gt;water&lt;&#x2F;a&gt;. I‚Äôm not sure I endorse the results or the intention, but I like &lt;a href=&quot;https:&#x2F;&#x2F;forum.effectivealtruism.org&#x2F;posts&#x2F;5mghcxCabxuaK4WTs&#x2F;ycombinator-fraud-rates&quot;&gt;the way this guy thinks&lt;&#x2F;a&gt;! &lt;a href=&quot;http:&#x2F;&#x2F;blog.archive.org&#x2F;2022&#x2F;11&#x2F;15&#x2F;digital-books-wear-out-faster-than-physical-books&#x2F;&quot;&gt;Real books last longer than physical books&lt;&#x2F;a&gt;, a win for the vintage. Hal Finney on &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;bshZiaLefDejvPKuS&#x2F;dying-outside&quot;&gt;choosing life&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;pGvyqAQw6yqTjpKf4&#x2F;the-gift-we-give-to-tomorrow&quot;&gt;The Gift We Give Tomorrow&lt;&#x2F;a&gt; ü•∫¬†I acquired &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;kiesler-correalism&quot;&gt;this sweater&lt;&#x2F;a&gt; as the ultimate silicon valley wear, and read about Kiesler&lt;&#x2F;p&gt;
&lt;p&gt;Hillel on &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;universal-se-topics&#x2F;&quot;&gt;universal SE topics&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;i-am-disappointed-by-dynamic-typing&#x2F;&quot;&gt;dynamic typing&lt;&#x2F;a&gt; the &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;why-do-we-call-it-boilerplate-code&#x2F;&quot;&gt;etymology of ‚Äúboilerplate‚Äù&lt;&#x2F;a&gt; and his notes on &lt;a href=&quot;https:&#x2F;&#x2F;www.hillelwayne.com&#x2F;post&#x2F;strangeloop-22&#x2F;&quot;&gt;Strangeloop&lt;&#x2F;a&gt;. Asterisk mag launched, and has a good introduction to &lt;a href=&quot;https:&#x2F;&#x2F;asteriskmag.com&#x2F;issues&#x2F;1&#x2F;china-s-silicon-future&quot;&gt;chips and China&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;Went on a meditation bender, here‚Äôs a &lt;a href=&quot;https:&#x2F;&#x2F;astralcodexten.substack.com&#x2F;p&#x2F;your-book-review-why-buddhism-is&quot;&gt;book review&lt;&#x2F;a&gt; that correctly characterizes how Buddhist philosophy is bipolar. &lt;a href=&quot;https:&#x2F;&#x2F;slatestarcodex.com&#x2F;2017&#x2F;09&#x2F;18&#x2F;book-review-mastering-the-core-teachings-of-the-buddha&#x2F;&quot;&gt;Book review&lt;&#x2F;a&gt; about meditation. Another &lt;a href=&quot;https:&#x2F;&#x2F;slatestarcodex.com&#x2F;2018&#x2F;11&#x2F;28&#x2F;book-review-the-mind-illuminated&#x2F;&quot;&gt;book review&lt;&#x2F;a&gt; about meditation. &lt;a href=&quot;https:&#x2F;&#x2F;slatestarcodex.com&#x2F;2019&#x2F;10&#x2F;16&#x2F;is-enlightenment-compatible-with-sex-scandals&#x2F;&quot;&gt;Meditation and sex scandals&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;HLERouG7QBt7jzLt4&#x2F;zen-and-the-art-of-rationality&quot;&gt;Buddhism in relation to rationality&lt;&#x2F;a&gt;. My experience with meditation is that it causes one to &lt;em&gt;experience&lt;&#x2F;em&gt; a philosophy of self (among some other things) and that does not induct that theory into truth. Buddhist philosophy is needlessly senseless because it‚Äôs reasoned from that experienced as opposed to more traditional technical thinking. It provides enhanced observational skills, but it‚Äôs not obvious that it‚Äôs correlated with ‚Äúliving optimally‚Äù as opposed to ‚Äúgoes insane‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2210.11399&quot;&gt;U-PALM&lt;&#x2F;a&gt; improves PaLM compute by 2x. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.03540.pdf&quot;&gt;Sandwiching&lt;&#x2F;a&gt; paper from Anthropic. &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;constitutional.pdf&quot;&gt;Constitutional AI&lt;&#x2F;a&gt;, in which RLHF becomes RLAIF. Language models are really good at &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;model-written-evals.pdf&quot;&gt;generating evals&lt;&#x2F;a&gt;. A &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.09066.pdf&quot;&gt;prompting paper&lt;&#x2F;a&gt; about making models use rules to do math via prompting. Finetuning models on their own chain-of-thought-ed text &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2210.11610&quot;&gt;improves them&lt;&#x2F;a&gt;. 100M GPT model &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.03540.pdf&quot;&gt;interpreted&lt;&#x2F;a&gt; (still a bit wavy, but I think we‚Äôll get there 2023)! Meta pretrained &lt;a href=&quot;https:&#x2F;&#x2F;galactica.org&#x2F;static&#x2F;paper.pdf&quot;&gt;science model&lt;&#x2F;a&gt; Galactica, which offensively does not cite Minerva?? Finally read the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.03466.pdf&quot;&gt;muP paper&lt;&#x2F;a&gt; on zero-shot hyperparameter determination. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2210.05492.pdf&quot;&gt;No press diplomacy&lt;&#x2F;a&gt;, though I didn‚Äôt make it to the full-press paper. Analysis on how &lt;a href=&quot;https:&#x2F;&#x2F;www.cambridge.org&#x2F;core&#x2F;journals&#x2F;natural-language-engineering&#x2F;article&#x2F;emerging-trends-sotachasing&#x2F;5E9F9F796159040973053C52C443C1D6&quot;&gt;SOTA-chasing&lt;&#x2F;a&gt; has affected research. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1909.13371.pdf&quot;&gt;Gradient Descent: The Ultimate Optimizer&lt;&#x2F;a&gt;, an old paper that showed up at NeurIPS with turtles. Finally! &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.09760.pdf&quot;&gt;Learned optimizers&lt;&#x2F;a&gt;! &lt;&#x2F;p&gt;
&lt;p&gt;Excellent &lt;a href=&quot;https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;10&#x2F;28&#x2F;23427137&#x2F;elon-musk-twitter-matt-levine-money-stuff&quot;&gt;compilation&lt;&#x2F;a&gt; of Elon fucking with Matty. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-10-31&#x2F;elon-musk-is-busy-with-twitter?leadSource=uverify%20wall&quot;&gt;Elon Musk Is Busy with Twitter&lt;&#x2F;a&gt;, Matt Levine is busy with Elon. Oh boy the &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-11-01&#x2F;people-will-pay-for-illiquidity&quot;&gt;Libor prosecutions&lt;&#x2F;a&gt; are better than I could‚Äôve asked for. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Book: Structure of Scientific Revolutions&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Pleasant read, has really good narrative and was particularly fun because Kuhn focuses on the Copernican revolution, phlogiston theory and various other scientific progresses that I don‚Äôt know about because I‚Äôm uneducated. There are some obvious overfittings, dubious claims that were particularly uncomfortable for a clean bayesian approach to knowledge acquisition but also some nice tidbits about feelings, like Pauli‚Äôs personal crises. The book completes itself with a rather epistemically offensive plot twist. I have &lt;a href=&quot;https:&#x2F;&#x2F;www.notion.so&#x2F;The-Structure-of-Scientific-Revolutions-80a1aaf4d6de4ef0ba628b3f0001d85e&quot;&gt;1800 words of notes&lt;&#x2F;a&gt; on the book and probably some inspired upcoming writing. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Essay(?): Designing Freedom&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Designing Freedom is this Stafford Beer cybernetics ‚Äúbook‚Äù (according to Google, but it‚Äôs fifty pages). I don‚Äôt endorse it intellectually ‚Äî not at all, they make these stylized control diagrams that don‚Äôt actually work and big handwavy statements. But aesthetically ‚Äî super fun! I purchased another Beer book (who, by the way, has a daughter named ‚ÄúVanilla‚Äù. Vanilla Beer) called Platform for Change which I often skim through. I wrote &lt;a href=&quot;https:&#x2F;&#x2F;www.notion.so&#x2F;Designing-Freedom-55db24f3d01544a58b129892468848f5&quot;&gt;notes on this&lt;&#x2F;a&gt; too!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>&quot;I heard you have some Karl Marx board game?&quot;</title>
		<published>2022-11-13T00:00:00+00:00</published>
		<updated>2022-11-13T00:00:00+00:00</updated>
		<link href="https://kipp.ly/class-struggle/"/>
		<link rel="alternate" href="https://kipp.ly/class-struggle/" type="text/html"/>
		<id>https://kipp.ly/class-struggle/</id>
		<content type="html">&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;marx&#x2F;Untitled.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Class Struggle is a board game designed by an NYU professor, Bertell Ollman. There‚Äôs like a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Class_Struggle_(board_game)&quot;&gt;Wikipedia page&lt;&#x2F;a&gt; about the historical impact of the game and how it taught Marxism through gameplay. It discusses how people called it subversive and tried to get rid of it, &lt;a href=&quot;https:&#x2F;&#x2F;www.mentalfloss.com&#x2F;article&#x2F;58318&#x2F;story-class-struggle-americas-most-popular-marxist-board-game&quot;&gt;Mentalfloss&lt;&#x2F;a&gt; talks more about the relationship to Monopoly (originally called The Landlord‚Äôs Game, which was to be about georgism and not capitalism before Hasbro got to it). I‚Äôve also digitized the contents of the game at the bottom!&lt;&#x2F;p&gt;
&lt;p&gt;What isn‚Äôt captured, is the sheer aesthetic value of the game itself, independent of its creator or any historical details about its sales. While I hoped to relearn marxism by first principles through gameplay, the game is not educational. The value is that it‚Äôs a fantastic shitpost that paints marxism in a positive light with stellar comedic value. I don‚Äôt know how people glossed over the comedic value part, the cover is a photoshopped image of Karl Marx and Nelson Rockerfeller arm wrestling, with Rockerfeller looking rather undignified.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;marx&#x2F;Untitled%201.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The game opens in an animated discussion to determine our privilege order. This was particularly colourful in a room full of San Franciscans who have experienced oppressions that are a bit more complicated that ‚ÄúWOMEN AND BLACKS HAVE LESS CHANCE THAN WHITE MALES TO BECOME CAPITALISTS‚Äù. Of course, the whole rulebook is littered with capitalised text. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;marx&#x2F;Untitled%202.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Shitposting is a term that was created for the internet, and originally about low effort trash talk to ignite flamewars. Shitposting, at least as people around me use the term, is really about improv. There are many more attributes of shitposting, but here we see an important attribute ‚Äî to express real values comedically, such that people who may not share that value to the full extent can enjoy the notion. A true ‚Äúyes and‚Äù experience.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;class-struggle&#x2F;%..&#x2F;img&#x2F;marx&#x2F;Untitled%203.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To help you take the game less seriously, or perhaps experience first-hand the pains of the working class, the die don‚Äôt really work. They‚Äôre too perfectly cube shaped and don‚Äôt roll at all. We could‚Äôve used better die, but would be inauthentic. &lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;ol start=&quot;60&quot;&gt;
&lt;li&gt;Black and white workers unite to fight racism. Racism is one of the main reasons for the division and resulting weakness of the working class. The capitalists understand this all too well, and do their best to promote hostility between black and white workers. Workers‚Äî3 assets&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Each square on the board has a fairly intense statement, as square 60 which is ‚ÄúBlack and white workers unite to fight racism‚Äù. This is of course accompanied by a rule book which describes all 84 squares in further detail. I yes-and-ed pretty hard to this! I also know there‚Äôs a lot more to racism than capitalists trying to divide the working class. I‚Äôm sure Ollman knows this too! But this method of sharing this idea (shitposting) is so much better than having to say ‚ÄúI understand there‚Äôs a lot more to it than capitalism, in fact it‚Äôs mostly other things but I wanted to just talk about this part for now‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;Here is a sample of some chance cards for the capitalists‚Äô deck. &lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Northtop Airplane Company gets caught trying to bribe two Saudi Arabian generals and loses billion dollars contract&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&#x2F;&gt;
&lt;blockquote&gt;
&lt;p&gt;Sexually repressed people generally make good, docile workers, so you develop a sex-education program which makes young people disgusted by their natural functions. Easily worth a couple of assets.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&#x2F;&gt;
&lt;blockquote&gt;
&lt;p&gt;The C. I. A. mistakenly assassinates the leader of a friendly country. Capitalists deny everything and move 2 spaces back.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&#x2F;&gt;
&lt;blockquote&gt;
&lt;p&gt;Capitalists fool workers into equating communism with spying, with the result that communists Ethel and Julius Rosenberg can be executed for a crime they didn‚Äôt commit.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;The first card references the 1975 bribing of Saudi generals by Northrop (which still exists in some form)! Changing the name a little bit is such a great joke! The Rosenberg thing approximately happened. The CIA assassination thing is maybe in reference to Frank Olson, or perhaps a more niche situation I don‚Äôt know about? I really don‚Äôt know whether people explicitly did sexual repression to get better workers (honestly I‚Äôd expect it to go the other way). I like using humour to promote things, as opposed to insulting things (this uhh, did both but I think it is primarily intending to promote). Humorously promoting and warming people to ideas through shitposts is a key property to how shitposts work.&lt;&#x2F;p&gt;
&lt;p&gt;Some chance cards for the workers‚Äô deck. &lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;You have just been laid off from work. If you blame yourself, or foreign competition, or the Blacks, or Jews, move two spaces back. If you blame the Capitalists, move two spaces ahead.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&#x2F;&gt;
&lt;blockquote&gt;
&lt;p&gt;You get caught stealing food from the supermarket. You get thirty days in jail and are ordered to move back 1 space. Stealing is no answer to the problem of poverty.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&#x2F;&gt;
&lt;blockquote&gt;
&lt;p&gt;If religion is the opium of the older workers, then opium (pot) is the religion of the younger set. While you‚Äôre looking at the lights inside your head ‚Äî ‚ÄúGroovy, man, real groovy‚Äù‚Äîthe Capitalist slips you one of his debits.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Shitposts can be used to highlight a critique of an idea, while not agreeing with it in its full expression. Class Struggle doesn&#x27;t really balance between positive and negative implications, but that&#x27;s fine really.&lt;&#x2F;p&gt;
&lt;p&gt;Class Struggle is what some may call a ‚Äúhigh effort shitpost‚Äù, which is something we‚Äôve lost with the ease of the internet. It has brought me aesthetic euphoria for two months now, may there be more content like this!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;chance-cards&quot;&gt;Chance Cards&lt;&#x2F;h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;You purposefully produce cars to wear out sooner than is technologically necessary in order to keep up the demand for new ones. For such good Capitalist thinking, move ahead to the next Chance square.&lt;&#x2F;td&gt;&lt;td&gt;Small Businessmen are so frightened by the possibility of going broke and becoming workers that they generally do what the Capitalists say. Move directly to the next square that that allows for an Alliance with the Small Businessment&lt;&#x2F;td&gt;&lt;td&gt;Capitalists fool workers into equating communism with spying, with the result that communists Ethel and Julius Rosenberg can be executed for a crime they didn‚Äôt commit. Capitalists move ahead 3 spaces.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;It‚Äôs not clever to take so many chances. Skip your next turn at the dice.&lt;&#x2F;td&gt;&lt;td&gt;There is less chance in having lots of chances than you think. Your hard work in the struggle has earned you 2 more Chances.&lt;&#x2F;td&gt;&lt;td&gt;If you haven‚Äôt washed the dishes or made supper this week, move 2 spaces. ahead. (Divisions between the people serve the Capitalist class.)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;You get caught with your hands in the public‚Äôs pocket ‚Äî they‚Äôre in deeper than usual. In an attempt to white-wash your reputation, you set up a charitable foundation (tax exempt and named after your family), but are forced to make a public announcement of your assets and debits.&lt;&#x2F;td&gt;&lt;td&gt;You are caught feeling sorry for the Workers. Victory in class struggle comes to people who think about their own class. Miss 2 turns at the dice.&lt;&#x2F;td&gt;&lt;td&gt;Your class allies have lost confidence in your leadership and want to keep a closer eye on what you do. Take all your allies and go back to the beginning of the stage of the class struggle on which you stand.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;All your propaganda says a person is free when the Government lets him alone. But almost everything one wants to do or have costs money, so only Capitalists are really free. You can use your freedom to move 2 spaces ahead, after paying the Workers 2 assets. (If you can‚Äôt pay up, move 2 spaces back)&lt;&#x2F;td&gt;&lt;td&gt;Your daughter has just eloped with the garbage collector. Skip a turn at the dice while you‚Äôre thinking of something to tell the neighbours.&lt;&#x2F;td&gt;&lt;td&gt;Farmers are fooled into blaming consumers (instead of the profits Capitalist middlemen) for the low prices they get for their crops. Move directly to the next square that allows for an Alliance with the Farmer Class.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Skill at red baiting, getting Workers to fight among themselves by calling some of them communists: next confrontation, take away 1 asset from the Workers.&lt;&#x2F;td&gt;&lt;td&gt;Sexually repressed people generally make good, docile workers, so you develop a sex-education program which makes young people disgusted by their natural functions. Easily worth a couple assets.&lt;&#x2F;td&gt;&lt;td&gt;Rockefeller gets photographed giving people the finger. It‚Äôs not wise letting people see what Capitalists really think of them. Miss a turn at the dice while you think of new ways to to fool the people.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;The next time one of your minor class allies threatens to act against your interests, give him this card and he will go along with you. Your power rests in money‚Äî$$$$$$$$$$$$&lt;&#x2F;td&gt;&lt;td&gt;You know your interest and the interests of the other classes in the class struggle. Such ‚Äòclass consciousness‚Äô is worth double the assets you now have. Take them.&lt;&#x2F;td&gt;&lt;td&gt;The Mafia makes you a proposition you can‚Äôt refuse: for 2 assets, it will see to it that the Workers miss 2 turns at the dice.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Paperback edition of the Marx&#x2F;English Collected Writings (100 volumes) sweeps the country. Your days are numbered ‚Äî 2 debits.&lt;&#x2F;td&gt;&lt;td&gt;You are treating your allies so well that they want to be at your side. Bring all your allies, from wherever they are on the board, into the square you are now in. (They do not get to pick a Chance Card however).&lt;&#x2F;td&gt;&lt;td&gt;You embezzle one million dollars from your stockholders. No one sees or cares. Move 1 space ahead.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Northtop Airplane Company gets caught trying to bribe two Saudi Arabian generals and loses billion dollar contract ‚Äî 2 debits.&lt;&#x2F;td&gt;&lt;td&gt;Coal mine disaster caused by absence of safety equipment that you refused to put back in because, you said, it was too expensive. Send roses to the funeral, and move back 3 spaces until the public outcry blows over.&lt;&#x2F;td&gt;&lt;td&gt;Most Government welfare goes to Big Business (tax write-offs, price supports, incentive payments, guaranteed loans, etc.) While making a big fuss over the little welfare that goes to the poor, who really need it, help yourself to more welfare in the form of 2 assets.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Bribe money to pay union officials. While Capitalists or their allies hold this, the Workers and their allies can‚Äôt get any assets from squares which mark the establishment of trade unions.&lt;&#x2F;td&gt;&lt;td&gt;The C.I.A. mistakenly assassinates the leader of a friendly country. Capitalists deny everything and move 2 spaces back.&lt;&#x2F;td&gt;&lt;td&gt;The class struggle is progressing faster than you think. Move immediately to the next Confrontation square.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;In an effort to balance the budget, your school district has abolished free milk for rich and poor alike. When all are equal before the law, you get richer‚Äî2 assets this time.&lt;&#x2F;td&gt;&lt;td&gt;Capitalists fool workers into equating anarchism with criminality, with the result that anarchists Sacco and Vanzetti can be executed for a crime they didn‚Äôt commit. Capitalists move ahead 3 spaces.&lt;&#x2F;td&gt;&lt;td&gt;You are treating your class allies very badly, giving the Workers a chance to force a switch in the alliance of any class it chooses.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Your son has become a follower of Reverend Moon and your daughter is hooked on heroin. So what good is all your money? Worrying about it all causes you to forget your next turn at the dice.&lt;&#x2F;td&gt;&lt;td&gt;Tax Refund: many big corporations don‚Äôt pay any taxes so there is nothing to refund them, but your tax accountants are less talented and more honest so you have paid something and now you get something back. Take 4 assets.&lt;&#x2F;td&gt;&lt;td&gt;Tired of breathing polluted air and drinking polluted water? Thon It&#x27;s time to make pollution less profitable to the factory owners who are responsible for it. Move together with all your allies to the square on which the Capitalists are now standing for a protest demonstration. Let &#x27;em hoar you&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Workers finally understand that, with America&#x27;s wealth and democratic traditions, socialism here will be different than what exists in Russia and China‚Äîor &amp;quot;the Russian bogey-man no longer scares us&amp;quot;. A biggie‚Äîworth 5 assets.&lt;&#x2F;td&gt;&lt;td&gt;Because you have been brainwashed to respect everyone in authority, you continue to respect your boss no matter what he&#x27;s done. While learning to respect only those who deserve your respect, you miss a turn at the dice.&lt;&#x2F;td&gt;&lt;td&gt;Candidate Carter promised to reduce the Defense budget by $5-7 billion, but President Carter has just increased it by $4 billion, while cutting corners on aid to cities, the poor, the old and the unemployed. The Workers&#x27; anger at such deception is worth 2 assets.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Together with your fellow workers, you have occupied your factory and locked your boss in the toilet. Capitalists miss 2 turns at the dice.&lt;&#x2F;td&gt;&lt;td&gt;It&#x27;s no, clever to take so many chances. Skip your next turn at the dice.&lt;&#x2F;td&gt;&lt;td&gt;There is less chance in having lots of chances than you think. Your hard work in the struggle has earned you 2 more Chances.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;You join a protest against the Government for paying businessmen-farmers $3 billion each year not to grow food. Don&#x27;t they know a lot of people are hungry, or don&#x27;t they care? Collective action moves you forward 2 spaces this time.&lt;&#x2F;td&gt;&lt;td&gt;The next time one of your minor class allies threatens to act against your interests, give them this card and they will go along with you. Your power relies on numbers and organization.&lt;&#x2F;td&gt;&lt;td&gt;You know your Interest and the Interests of the other classes in the class struggle. Such &#x27;class conscious-ness&#x27; is worth double the assets you now have. Take them.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;You are treating your class allies very badly, giving the Capitalists a chance to force a switch in the alliance of any class it chooses.&lt;&#x2F;td&gt;&lt;td&gt;You are caught feeling sorry for the Capitalists. Victory in class struggle comes to people who think about their own class. Miss 2 turns at the dice.&lt;&#x2F;td&gt;&lt;td&gt;If you haven&#x27;t washed the dishes or made supper in the last week, move 2 spaces back. (Divisions between the people serve the Capitalist Class).&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;A socialist teacher has just gotten fired from the local school for playing &amp;quot;Class Struggle&amp;quot; with her class. You help organize the community to get the teacher&#x27;s job back, and earn 2 assets by the show of solidarity.&lt;&#x2F;td&gt;&lt;td&gt;Integrity insurance against Capitalist bribes of trade union officials. This card neutralizes the Capitalists&#x27; Chance Card on bribe money.&lt;&#x2F;td&gt;&lt;td&gt;If religion is the opium of the older workers, then opium (pot) is the religion of the younger set. While you&#x27;re looking at the lights inside your head‚Äî&amp;quot;Groovy, man, real groovy&amp;quot;‚Äîthe Capitalist slips you one of his debits.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;If all wealth is produced by the Workers, then what right do Capitalists have to any part of it, let alone the largest part? This &amp;quot;dangerous&amp;quot; question sends shivers up the spines of Capitalists every-where. Grab 2 extra turns at the dice while the Capitalists are still shivering.&lt;&#x2F;td&gt;&lt;td&gt;Teachers and engineers are beginning to recognize that they have bosses just like other workers. Move directly to the next square that allows for an Alliance with the Professional Class.&lt;&#x2F;td&gt;&lt;td&gt;UNION CARD &lt;br&#x2F;&gt; You&#x27;ve joined the union. The union makes us strong. Take 2 extra turns with the dice.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Yesterday you shook hands with Republicrat Senator Kennewater, and you believed him when he said he is the workingman&#x27;s candidate. Lose 1 asset for being so gullible.&lt;&#x2F;td&gt;&lt;td&gt;Your boss died, but the new one acts in much the same way. You begin to understand the problem is not a mean boss but the class of bosses-2 assets.&lt;&#x2F;td&gt;&lt;td&gt;The class struggle is progressing faster than you think. Move immediately to the next confrontation square.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;A few Capitalists have recognized the injustice of our present economic system and have decided to support the Workers&#x27; Movement. Individual exceptions in the class struggle are possible. Worth 2 assets.&lt;&#x2F;td&gt;&lt;td&gt;You get caught stealing food from the supermarket. You get thirty days in jail and are ordered to move back 1 space. Stealing is no answer to the problem of poverty.&lt;&#x2F;td&gt;&lt;td&gt;You are treating your allies so well that they want to be at your side. Bring all your allies, from wherever they are on the board, into the square you are now in. (They do not get to pick a chance card however.)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;You have just been laid off from work. If you blame yourself, or foreign competition, or the Blacks, or Jews. move two spaces back. If you blame the Capitalists, move two spaces ahead.&lt;&#x2F;td&gt;&lt;td&gt;A fire destroys your home‚Äîyou lose everything‚Äîbut your Capitalist landlord collects insurance money. You miss a turn at the dice while looking for another apartment.&lt;&#x2F;td&gt;&lt;td&gt;Students are beginning to recognize that when they finish school most of them will become Workers. Move directly to the next square that allows you to make an alliance with the Students.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Socialist ideas are spreading in the army. (Worth 1 asset in the General Strike Confrontation, 3 assets in the Revolution).&lt;&#x2F;td&gt;&lt;td&gt;Tax Refund: with taxes deducted from each week&#x27;s pay check, workers are the only people who can&#x27;t cheat on their taxes. The Government makes up for this exception by cheating the Workers, taxing them too much and giving them too little, even when it comes to tax refunds. Take 2 assets.&lt;&#x2F;td&gt;&lt;td&gt;Serious illness of mother-in-law bankrupts the whole family and drives you to drink-1 debit. Drinking Is no answer to poverty.&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h3 id=&quot;rule-book&quot;&gt;Rule Book&lt;&#x2F;h3&gt;
&lt;p&gt;DON&#x27;T BE SCARED BY ALL THESE RULES
The three sets of rules differ in regard to complexity and the roles they give to chance and strategy, with BEGINNERS RULES relying most on chance and TOURNAMENT RULES permitting the most strategy.
BEGINNERS RULES-The basic structures for the game are laid down. Everyone should start here. READING THE SENTENCES WHICH ARE CAPITALIZED IN EACH RULE IS USUALLY ALL THE PREPARA TION THAT IS NEEDED TO BEGIN PLAYING
FULL RULES-The structures are filled in with the life of capitalist society. Adults and older adolescents should move on to these rules as quickly as possible, even-by common consent-in the middle of a game. But don&#x27;t stop here. Be- fore rigor mortis sets in, go on to...
TOURNAMENT RULES-This is where the real action is. See, for example, TOURNAMENT RULE number 8 (this rule can be added to FULL RULES whenever players feel ready for it). No adult should linger more than one game each in BEGINNERS and FULL RULES before taking on the wheeling and dealing made possible by TOURNAMENT RULES.
It is possible to play &amp;quot;Class Struggle&amp;quot; with two players, but-given the importance of alliances-it is better to play with four, and best with six. Go ahead, invite another friend to play.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Full Rules and Some Strategies&lt;&#x2F;strong&gt;
OBJECT OF THE GAME
&amp;quot;Class Struggle&amp;quot; reflects the real struggle between the classes in our society. THE OBJECT OF THE GAME IS TO WIN THE REVOLUTION... ULTIMATELY. Until then, classes-represented by different players- advance around the board, making and breaking alli- ances, and picking up strengths and weaknesses that determine the outcome of the elections and general strikes which occur along the way.
PLAYERS&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&amp;quot;Class Struggle&amp;quot; can be played by two to six players. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The real players in &amp;quot;Class Struggle,&amp;quot; however, are classes, not individuals. Workers (those who produce shoes, cars, houses and so on) and Capitalists (those who own the machines and factories with which these things are pro- duced) are the Major Classes. Farmers, Small Business- men, Professionals (doctors, lawyers, professors, etc.) and Students are the Minor or Allied Classes. In the game, the hammer symbolizes the Workers, the top hat-the Capi- talists, the tractor-the Farmers, the cash register-the Small Businessmen, the brief case-the Professionals, and the mortarboard-the Students.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Only Workers and Capitalists can win this game. The other classes participate in winning or losing through alliances with one or another Major Class. (See Rule 15) While Workers and Capitalists struggle to win, the Minor Classes struggle to be on the winning side.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Individual players cannot choose their class. In real life, ONE&#x27;S CLASS IS DETERMINED BY CHANCE, which usually means by the kind of family into which one is born. Also in our society, WOMEN AND BLACKS HAVE LESS CHANCE THAN WHITE MALES TO BECOME CAPITALISTS. This has nothing to do with the human qualities of women and Blacks and everything to do with the unfair rules set by our society. Attempting to reflect these rules (and not by any means to justify them), &amp;quot;Class Struggle&amp;quot; calls for the following: beginning with the lightest White male and ending with the darkest Black female, everyone takes turns with the Genetic (or luck-of-birth) Die, the one with the symbols on it, to see who throws the Capitalist Class first. (If the people playing include a black man and a white woman, the players themselves have to decide which one has the greater handicap in becoming a Capitalist). After the Capitalists are chosen in this way, the players throw the Genetic Die in just the opposite order to see who plays the Workers. The remaining players can throw the Genetic Die in any order to see who plays the other classes.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;It is important that Workers and Capitalists be represented in the game, so if there are only two players these are the classes they should play. If there are less than six players, one person can represent two Minor Classes. It is also possible in a two-person game for each player to represent a Minor as well as a Major Class. It is simply more inter- esting when all or most of the Minor Classes are represented, but it is also possible to play &amp;quot;Class Struggle&amp;quot; with one or more of the Minor Classes left out.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Again, to be true to real life, where the Capitalists&#x27; wealth and power over people and factories give them many unfair advantages, the Capitalist Class is the first to throw the numbered dice. They also decide whether the order in which the other classes take their turn at the dice proceeds from their left or their right. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Classes now throw the numbered dice and move forward as many squares as the number shown, except when this number is the same as the one thrown by the class that Z went before. In this case, the class which has just thrown the dice does not move at all. THINKING FOR ONE- SELF, AND NOT JUST DOING WHAT OTHERS DO, IS ESSENTIAL FOR WINNING AT CLASS STRUGGLE. If a class throws a double number, it gets an extra turn at the dice, and this rule holds for as long as any class throws double numbers.&lt;&#x2F;p&gt;
&lt;p&gt;ASSETS AND DEBITS&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Most of the squares on the board are divided between Workers (red) and Capitalists (blue), and list the real strengths and weaknesses of these two classes. Depending on its importance in the Class Struggle, each strength is worth one to three plus-points (called &amp;quot;assets&amp;quot;) and each weakness one to three minus-points (called &amp;quot;debits&amp;quot;). Whenever Workers or Capitalists land on a square which carries its name, it picks up the number of assets or debits listed there. Landing on its opponent&#x27;s squares earns the trespasser neither assets nor debits, unless this happens on three successive throws of the dice (and only if one&#x27;s opponent has kept track of this). In this case, the offend- ing class picks up one debit. PRETENDING TO BELONG TO A CLASS OTHER THAN YOUR OWN WEAKENS YOUR CAUSE IN THE CLASS STRUGGLE. NEW&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;As part of their unfair advantages, the Capitalists decide which of the other classes should do the hard but neces- sary work of handing out assets and debits, that is of taking care of the &amp;quot;Bank.&amp;quot;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The Minor Classes pick up assets and debits whenever they land on either Capitalist or Worker Squares until they enter an alliance with one of the Major Classes, after which they get points only from squares that carry the name of their ally. (See Rule 15).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;CHANCE&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When landing on a Chance square, Capitalists pick up a Chance Card from the pack marked &amp;quot;Capitalist&amp;quot;, and Workers from the pack marked &amp;quot;Worker&amp;quot;. WHAT IS SAUCE FOR THE GOOSE MAY BE SAUCE FOR THE GANDER, BUT WHAT IS GOOD LUCK FOR 27 THE CAPITALISTS IS BAD LUCK FOR THE WORKERS, AND VICE VERSA.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Until they enter into an alliance with one of the Major Classes, the Minor Classes can take their Chance Cards from either pack. After an alliance, they must pick their cards from the same pack as their Major Class ally. (See Rule 15.)
on squares 16 or 56&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Trade Union and Workers&#x27; Political Party Cards: if the Workers or their allies land on squares 11 or 52, they receive a Trade Union Card; landing earns them a Political Party Card. Minor Classes can acquire these cards only while they are allied with the Workers, and must return them should this alliance be broken (See Rule 15).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;On the highest level of &amp;quot;Class Struggle&amp;quot;, starting with square no. 65, classes have a choice of receiving the num- ber of assets and debits listed on the squares on which they land or forcing any one of their opponents to move double that number of squares (backward when it is assets that are listed, forward in the case of debits). The latter class then picks up the assets, debits, chance card, etc. listed on the square to which it has been forced to move.&lt;&#x2F;p&gt;
&lt;p&gt;ALLIANCES&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Squares which read &amp;quot;Chance for an Alliance with the Farmers&amp;quot; (or Small Businessmen, or Professionals, or Students) permit the Major Class which lands there to enter into an alliance with the Minor Class named there. Each Minor Class has a Class Alliance Card which it gives to its new ally to seal the alliance. Like the player pieces, Alliance Cards can be mounted on the blocks of wood which are provided. Though each allied class retains its own assets and debits, their points are counted together in any future &amp;quot;Confrontation&amp;quot; (See Rule 27).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;When there are less than six players in the game, a Major Class which lands on the Alliance Square of a Minor Class that is not represented by a player still receives the latter&#x27;s Alliance Card and a bonus of five assets.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Whenever the Capitalists or Workers enter into an alliance with a Minor Class that is represented by a player they agree-in order to cement their new relationship-to Z accept from the Bank a number of debits equal to the number showing on their new ally&#x27;s next turn at the dice, except when a double number is thrown, in which case there is no need to accept any debits at all. THERE IS OFTEN A PRICE TO PAY IN FORMING NEW ALLIANCES, AND CLASSES MUST ASK THEMSELVES, &amp;quot;IS IT WORTH IT?&amp;quot;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Minor as well as Major Classes have a chance to enter into alliances if they land on an Alliance Square. Rule 17 also applies here, and again it is the class which lands on the Alliance Square and initiates the alliance which receives the Alliance Card from the other class and picks up the extra debits.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If a Minor Class (say Farmers), which is already allied to a Major Class (say Capitalists), lands on a square that makes possible an alliance with the Students, the lat- ter automatically becomes an ally of the Capitalists as well. In this way, the Minor Class allies of each Major Class can pick up alliances for their Major Class ally.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If a Minor Class is not allied to either of the Major Classes, it can still enter into an alliance with another Minor Class. In this case, the two Minor Classes have made themselves doubly valuable to the first Major Class to enter into an alliance with either of them; for-given the alliance of the two Minor Classes-to ally with either one of them is to ally with both. This also implies, of course, that the Major Class in question agrees to accept from each new ally a number of debits equal to the number showing on its next turn at the dice, except-again
-when double numbers appear.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;After two Minor Classes enter into an alliance with a Major Class, their special relationship comes to an end. Thus, if the other Major Class forces either of these Minor Classes to change alliances, its one-time partner is unaffected.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Change of alliances: whenever any class (Major or Minor, allied or unallied) lands on an Alliance Square of a Minor Class already allied to its opponent (or picks up a Chance Card which speaks to the same thing), a change of alliances becomes possible. Rule 17 also applies in every change of alliances.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If there are less than six players in the game, forcing a change of alliances with a Minor Class that is not represented by a player is simply a matter of transferring the Alliance Card and the five assets which came with it from the old Major Class ally to the new one.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Right to refuse alliances: whenever there is a chance for an alliance or a change of alliances, the classes directly affected have a right to accept or refuse it. If both classes agree, an alliance is formed. If both classes reject it, there is no alliance. If one wants the alliance and the other does not, the two throw the dice and class with the higher number has its way. In case of a tie, they throw the dice again.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Natural Alliances: SOME CLASS ALLIANCES ARE MORE VALUABLE THAN OTHERS. If the Capitalists gain an alliance with both the Small Business and Professional Classes, the assets and debits of the latter two classes are counted twice in &amp;quot;Confrontations&amp;quot;. (See Rule 27). This applies only if both of these classes are allied with the Capitalists at the same time. If the Workers gain alliances with the Farmers and Students, the same thing applies: the assets and debits of these two classes are counted twice.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The Natural Alliance Rule holds even if one or both of the Minor Classes involved are not represented by players. That is, the five assets the Workers would have received for allying with the Farmers and the five assets they would have received for allying with the Students assuming neither class is represented by players (see Rule 16)-is worth twenty assets as long as this double alliance holds.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;CONFRONTATION&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;There are six Confrontation Squares: Life in the factory, two Elections, two General Strikes (when all the workers lay down their tools) and the Revolution. If either Major Class or its allies lands on a Confrontation Square, it has a choice whether or not to call a Confrontation. Non- allied Minor Classes cannot call a Confrontation, and only the Major Classes (not even their allies) can call the final Confrontation, which is the Revolution. In a Con- frontation, each side adds up its assets and debits (allies&#x27; points are counted together), and the side with the highest number of assets after debits are subtracted wins. In the case of the Elections and General Strikes, winning the Confrontation secures the victorious Major Class three free throws of the dice, improving in this way its position in the overall Class Struggle. Rule 7 regarding double numbers does not apply to these three throws. To keep opponents guessing as to whether they can win a Con- frontation, each class should keep its own assets and debits
securely covered.&lt;&#x2F;li&gt;
&lt;li&gt;It is obviously not in the interest of a class to provoke a Confrontation unless it believes it can win. To make an intelligent judgment on this matter, each class should try to keep track of the assets and debits acquired by other classes. IN CLASS STRUGGLE, VICTORY GEN- ERALLY GOES TO THE CLASS WHICH KNOWS THE STRENGTHS AND WEAKNESSES OF THE OTHER SIDE AS WELL AS ITS OWN.&lt;&#x2F;li&gt;
&lt;li&gt;Elections are true Confrontations only if the Workers, or one of its allies, has already landed on Squares 16 or 55 indicating that a Working Class political party has been formed. Otherwise, the Capitalists automatically win this Confrontation. IN AN ELECTION BETWEEN THE CAPITALIST PARTIES OF TWEEDLE DEEmocrats AND TWEEDLE DUMlicans, THE WORKERS CAN ONLY LOSE.&lt;&#x2F;li&gt;
&lt;li&gt;Revolution is the last square on the board and the final Confrontation. The winner of this Confrontation wins the game. If the Workers win, humanity enters a new era of peace, democracy and equality, which is called SOCIAL- ISM. A Capitalist victory, on the other hand, simply means the rich get richer while the poor are left to stew in their own juice, leading eventually to the collapse of civilization. HENCE THE CHOICE BEFORE US SOCIALISM OR BARBARISM?&lt;&#x2F;li&gt;
&lt;li&gt;A Revolution can be called by either of the Major Classes once it arrives in the final square. As in earlier Confrontations, the assets and debits of both Workers and Capitalists are counted no matter where these classes are on the board. The allies of the Major Class which calls the Revolution, however, are counted only if they are safely in the final square when the Revolution is called. The points of the allies of the other Major Class are counted no matter where these classes are on the board. REVOLUTION IS THE GREAT TEST OF ALLIANCES AND SOME CLASSES ARE FOUND WANTING.&lt;&#x2F;li&gt;
&lt;li&gt;For the Natural Alliance Rule (See Rule 25) to apply in the Revolution, the Major Class and both of its natural allies must be in the final square. If only one natural ally has made it to the final square in time for the Revolution, its assets and debits are counted but once. In the case of classes not represented by players, simply having the Natural Alliance is sufficient for doubling their assets in the Revolution as in all other Confrontations.&lt;&#x2F;li&gt;
&lt;li&gt;For any class to advance to the final square, it must roll an exact number on the dice. If it is two squares away, it has to keep throwing the dice until it gets a two. If it is one square away, it throws only one die. &lt;&#x2F;li&gt;
&lt;li&gt;Once any class (Major or Minor) arrives in the final square, it continues to receive a turn at the dice which it can use to advance any of its allies. The ally that it wishes to help must be chosen before the dice is thrown.&lt;&#x2F;li&gt;
&lt;li&gt;As the Capitalists control the Government, only they not even their allies can trigger off a nuclear war and destroy the whole world. IN DANGER OF LOSING THEIR POWER, THE CAPITALISTS ARE CAPABLE OF ANYTHING. If the Capitalists land on Square 81, then, this means nuclear war and the automatic end of the game. Nobody wins. If the Workers or any of its allies land on this square first, however, the possibility of the Capitalists starting a nuclear war has been removed for the remainder of the game.&lt;&#x2F;li&gt;
&lt;li&gt;It is in the interest of every class to become part of a Natural Alliance (see Rule 25), and it is this interest which determines most efforts to establish alliances.&lt;&#x2F;li&gt;
&lt;li&gt;Since establishing an alliance with a Minor Class generally means accepting a few extra debits (except when the latter throws a double number on the dice), there will be occasions when a Major Class may want to refuse such an alliance. These are when the Minor Class in question has few or no assets, early in the game when changes in alliances are still very likely, or late in the game when the Major Class has a large lead in assets and believes it can win without this alliance. Should this happen, the Minor Class on whose Alliance Square the Major Class has landed-wishing to be on the winning side-may insist on forming an alliance, in which case the two classes throw the dice with the higher number deciding the issue.&lt;&#x2F;li&gt;
&lt;li&gt;The necessity of getting one&#x27;s Minor Class allies into the final square in order to have their assets counted in the Revolution gives a Major Class with few and even no Z allies a chance to win. Though it is usually an advantage to have as many alliances as possible early in the game for the help they provide in the early Confrontations, this is not always so in the end. As the Revolution approaches, the value of alliances depends in large part on the position of one&#x27;s Minor Class allies on the board, and this should be kept in mind in deciding whether to accept a new alliance. &lt;&#x2F;li&gt;
&lt;li&gt;For a Minor Class, the possibility of being left out of the Revolution (being short of the final square when the Revolution is called, or being there but not having an alliance with either Major Class) offers a third possible outcome to the game besides winning or losing. Again, the main objective of each Minor Class is to be on the winning side, but if this goal is beyond its reach it should try at least to avoid being on the losing side. In pursuit of this second best outcome, a Minor Class should refuse an alliance with a Major Class if it believes the latter is going to lose.&lt;&#x2F;li&gt;
&lt;li&gt;Because it picks up assets and debits from both Capitalist and Worker Squares before it enters into an alliance with a Major Class, there is some advantage to a Minor Class&#x27; steering clear of alliances until it sees which of the Major Classes is ahead. &lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;SOCIALISM OR BARBARISM&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The class which wins the Revolution has only won in one country, but Class Struggle is taking place throughout the capitalist world. Give the winning class(es) a bonus of five assets (VICTORY IN ONE COUNTRY HELPS ONE&#x27;S CLASS IN OTHER COUNTRIES), roll the Genetic Die to see who is going to represent which class (AS ALWAYS, EACH PERSON&#x27;S CLASS IS LEFT UP TO CHANCE), and let the struggle begin anew. &lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;INNOVATION&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;But before you start, look around you at life in capitalist America and add at least one new Chance Card for each Capitalists and Workers. Several blank Chance Cards have been provided for this purpose. The player who offers the best idea for a Chance Card should be rewarded with two assets for the new game.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;strong&gt;Tournament Rules&lt;&#x2F;strong&gt;
(These rules are for older adolescents and adults who are already familiar with the FULL RULES and who favor games with more complex strategies.)&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In BEGINNERS and FULL RULES, winning has been simply a matter of having more assets at the end of the game. TOURNAMENT RULES, however, recognizes three kinds of victories: smashing victory, middling vic- tory and bare victory, which is no less than what can happen in any real revolution.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Here, Workers or Capitalists win a smashing victory if it&lt;&#x2F;p&gt;
&lt;p&gt;a) beats the other Major Class by a margin of fifteen or more assets,
b) has more allies than its opponent in the final square at the end of the game, and
c) has won all of the confrontations which were called. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;A Major Class wins a middling victory if it satisfies any two of these criteria. If less than two of these criteria are satisfied, the winning class wins but a bare victory.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In the real world, the larger the victory, the quicker the winning class can put its program into effect. It also contributes to the success of this same class in the Class Struggles going on in other countries. Consequently, in the next game of &amp;quot;Class Struggle&amp;quot;, the class which has just won a smashing victory starts the game with nine assets. A middling victory is worth six assets and a bare victory three. In every case, the allies of the winning class receive the same bonus. These assets go to the winning class and not to the player who represented it, as each new game starts with a throw of the Genetic Die.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;It is obviously in the interest of each Major Class, therefore, not only to win but to win big, or if it is losing to lose by as little as possible.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;TOURNAMENT RULES, unlike FULL RULES, also allows for the possibility of a Minor Class, or an alliance of Minor Classes, winning. This occurs when the two Major Classes have fought to a standoff in their struggle. This standoff is represented in the game by the following:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;no more than ten assets separates the totals of the Major Classes,&lt;&#x2F;li&gt;
&lt;li&gt;neither has won more than one Confrontation, and&lt;&#x2F;li&gt;
&lt;li&gt;neither has more than one ally.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;In these circumstances, an unallied Minor Class, or an alliance of Minor Classes, which has more assets than either Major Class can-when it arrives at the final square-call a Revolution and win. Again, for the points of the allies of the class calling the Revolution to be counted, these allies must have arrived in the final square. If a Minor Class calls a Revolution and the criteria for its victory are not met, the Major Class with the most assets wins. If the Minor Class wins, it receives a bonus of nine assets for the next game, and so too any of its allies.
This unusual outcome corresponds to the equally unusual outcome of real Class Struggles in which a standoff be- tween Major Classes permits representatives of a Minor Class to assume temporary control of the state. Louie Boneparte&#x27;s rise to power as representative of the small farmers in mid-19th century France is an example of this.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The variety of possible outcomes increases the number of options before any class. A Major Class which takes an early lead can try to win big or simply try to make sure that it wins. While a Major Class which falls behind early in the game now has the option of still trying to win or trying to limit the size of its loss. And Minor Classes, if circumstances allow, can strive to defeat both Major Classes, or as before-to be on the side of the winning Major Class, or at least not to be allied to the losing Major Class. Clearly, the possibility and attractiveness of these different options will change as the game progresses with its changing relations between the classes.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In order to give each class greater flexibility to pursue these different outcomes, TOURNAMENT RULES permits the following:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;any class can buy from another its turn(s) at the dice for whatever (assets, future Chance Cards, decision making power in the alliance, or alliances) that the latter will accept.&lt;&#x2F;li&gt;
&lt;li&gt;a class can also buy from another, using whatever the latter will accept, future Chance Cards (in the hope of coming up with the one or two cards that could change the course of the game). Such a purchase must be concluded, of course, before the card in question is picked.&lt;&#x2F;li&gt;
&lt;li&gt;class alliances can be made, traded or sold, again for whatever the parties will accept. (Only Minor Classes can be sold or traded, whether by a Major or Minor Class ally). As before, the class landing on a Class Alliance Square can force the class named there to enter into an alliance, whether or not it is already part of another alliance (given, of course, that the class which lands on the square wins the subsequent throw of the dice), but now alliances can also be forged and broken in other ways. The only exception to this open market in alliances is that Workers and Capitalists can never ally together.
The only time when alliances can be made, traded. sold or broken in the above manner is when a class, any class, lands on an Alliance Square. Besides per- mitting the class which lands there to enter into an alliance with the class named, an open market is de- clared on all such transactions. If the class being traded or sold objects, however, the issue is decided as always by a throw of the dice. This means too that a Major Class which was denied the right to trade or sell its ally because of an unlucky throw of the dice has another opportunity to do so as soon as someone lands on the next Class Alliance Square. A class simply wishing to get out of an alliance cannot force the issue in this way, but must find a price to buy its freedom that its ally finds acceptable.&lt;&#x2F;li&gt;
&lt;li&gt;a Major Class can concentrate as many of its assets as it wishes on any upcoming Confrontation other than the Revolution. This is the political equivalent of &amp;quot;putting all of one&#x27;s eggs in the same basket&amp;quot;. In this case, if the betting class or its allies are lucky enough to land on this square, the assets which have been &amp;quot;sent ahead&amp;quot; count for triple in the Confrontation. If this square is passed over without a Confrontation, or if the Confrontation is called and lost, the assets which were &amp;quot;sent ahead&amp;quot; are returned to the Bank. Given the danger of losing these assets, this strategy is best suited to a Major Class which is already losing but hopes to win at least one Confrontation and in this way keep its opponent from a smashing victory.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;STRATEGY&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;All the strategies listed in Full Rules apply here (See Full Rules numbers 36-40).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Knowing that other classes can and are even likely to land on the Class Alliance Squares coming up, it is unwise to make &amp;quot;expensive&amp;quot; alliance deals early in the game, for this will just mean losing alliances for which one has paid dearly. On the other hand, if a Major Class is pursuing a strategy directed toward winning an early (or middle) Confrontation, paying a lot for an alliance-especially if the price is in future turns of the dice or future Chance Cards-may be a clever move.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If a Major Class is behind in assets and lagging far behind on the board, it should consider giving one or more of its allies their independence in exchange for assets or future turns at the dice. It is always preferable for a Major Class to strike a bargain with a Minor Class than with the other Major Class, since bargains generally strengthen both parties.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If a Major Class is far behind in everything, only luck will save it and it is probably a good idea to trade future turns at the dice, assets, etc. with other classes for future Chance Cards. Generally speaking, this a desperation move, but there are a couple of Chance Cards which could turn the game around. Each Major Class picks up Chance Cards from the pack that carries its name no matter where and from whom it has purchased the right to do so.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;A Minor Class trying to win by itself (or in alliance with other Minor Classes) will not only use its assets to keep or buy back its independence, but also to bolster the posi- tion of the losing Major Class so that the criteria necessary for a Minor Class to win can be satisfied. (See Rule 6). It can&#x27;t simply hand over assets to a Major Class which is losing badly, but it can buy a Chance Card from it, for example, at an inflated price.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;If allied to a losing Major Class which refuses to sell it its independence, a Minor Class may refuse to follow its ally&#x27;s advice on whether to accept an advantageous alli- ance with another Minor Class or to reject a disadvantage- ous one, or to call or not call a Confrontation should the opportunity arise. The very possibility that one&#x27;s Minor Class ally might force a Confrontation when one is sure to lose serves as pressure on a Major Class to trade or sell its troublesome ally.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;An independent Minor Class with a great many assets can offer itself as an ally to a Major Class in return for the power to take all decisions pertaining to the alliance, i.e., whether to call a Confrontation, including the Revolution, whether to accept and&#x2F;or trade for other allies, what kind of victory to aim for, etc. A Major Class is unlikely to give up such power, of course, unless it sees no other way of winning.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In TOURNAMENT &amp;quot;Class Struggle&amp;quot;, the relations be- tween the classes are likely to change often and drastically, requiring frequent reassessments of what outcomes are possible, which desirable, and what strategies are best to obtain them. Flexibility in choosing one&#x27;s goal is as important as skill in choosing effective means in determining both who will win and what kind of victory it will be. 17. For the rest, all the rules given in FULL RULES, except where specifically superceded by 1-16 of the above, also apply to TOURNAMENT &amp;quot;Class Struggle&amp;quot;.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;&#x2F;strong&gt;
&lt;em&gt;Explanations for the assets and debits awarded on each square&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Class Struggle begins.&lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: in the factory every day. With neither land or tools to call their own, workers are forced to sell their labor-power to capitalists for as much as they can get in order to stay alive. Capitalists buy this labor- power for as little as they can give in order to make things which they can sell at a profit. They then try to expand this profit by making workers work harder, faster and longer (no matter how unhealthy and unpleasant the conditions of work, since every improvement in these conditions costs money); while workers struggle to defend themselves against capitalist greed by doing as little as they can as slow as they can.&lt;&#x2F;li&gt;
&lt;li&gt;Growth of industry leads to an increase in the number (hence the power) of workers. There are about 95 million people (or 62% of everybody over 16) who work for wages in America today. These are the workers. Growth of industry also leads to an increase in the profits (hence the power) of capitalists. Workers-2 assets; Capitalists -2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Market spreads overseas giving capitalists an important influence in the lives of foreign peoples and their governments. The capitalist system&#x27;s need for the continuous expansion of this market (since workers are not paid enough to buy all that they make) is at the core of what is called &amp;quot;imperialism&amp;quot;. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Increasing concentration of industry makes workers the majority in most cities. The workers&#x27; power lies not only in their numbers but in the fact that they live in cities which are the nerve centers of capitalist society. Workers -2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Competition between capitalists drives many of them out of business. The result is fewer capitalists in relation to the growing number of workers. While many Americans own a few shares of stock, there are only about one half million people who own so many shares that they have an influence on how the business is run and&#x2F;or can live off their dividends. These are the capitalists. Capitalists-1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;Growth in church attendance. Because it encourages the poor and oppressed to think more about the next life than about this one, Karl Marx called religion, &amp;quot;the opium of the people&amp;quot;. Workers-1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Farmers.&lt;&#x2F;li&gt;
&lt;li&gt;Congress is supposed to represent all the people, but most of its members (Democrats and Republicans) are capital- ists and lawyers for capitalist interests. It is no wonder then that most of the laws which Congress passes favor the capitalist class. In the words of Anatole France, &amp;quot;The law in all its majesty forbids rich and poor alike from stealing bread and sleeping under bridges&amp;quot;. So much for what capitalists, without recognizing the irony, call &amp;quot;equality under the law&amp;quot;. Capitalists-2 assets. &lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Trade Unions are established to defend workers&#x27; interests (higher wages, shorter hours, safer conditions and the like). Only through organization can the workers&#x27; power be felt. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Natural disaster. Floods, hurricanes, etc. mean workers lose their homes and cars, while for the capitalists dis- asters generally mean more business, since workers have to buy more homes and cars. Workers-1 debit; Capitalists-1 asset.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Professional Class.&lt;&#x2F;li&gt;
&lt;li&gt;Competition between workers for jobs and, inside each work place, for the few easier and higher paid jobs makes it difficult for workers to cooperate on behalf of their common interests. Workers-1 debit. &lt;&#x2F;li&gt;
&lt;li&gt;Police are not for directing traffic, nor soldiers for march- ing in parades. The main job of the police and the army is to protect the factories, stores and fine homes of the capitalists. Capitalists-2 assets. &lt;&#x2F;li&gt;
&lt;li&gt;Workers organize a working class political party. Only when they stop relying on capitalist parties to represent them can the workers hope to win in class struggle. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Big drop in the stock market. Millions of small investors lose their savings and capitalism momentarily gets a bad name. Capitalists-2 debits.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE. &lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: election. An election is a true confrontation only if the workers have their own political party. If elections are a matter of choosing between bosses who look like elephants and bosses who look like donkeys, the workers can only lose.&lt;&#x2F;li&gt;
&lt;li&gt;Trade Unions are taken over by union bureaucrats (only applies if the Workers or their allies have landed on number 11 above). When the unions are led by people who think only of their own careers, the workers&#x27; interests are forgotten. Workers-2 debits.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Small Shopkeepers. &lt;&#x2F;li&gt;
&lt;li&gt;Press, radio and T.V. are owned by the capitalists and present their point of view on everything. This is not just a matter of editorials, but of what the media merchants choose to call news and the slant they give it. Capitalists -3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;The success of the Tennessee Valley Authority (T.V.A.) shows that production can go on without capitalists. An important lesson. A public corporation, the T.V.A. pro- duces and sells electricity more cheaply than any private power company could... or would. Workers-2 assets; Capitalists-1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists control the courts. With laws biased on behalf of the rich, establishment judges who naturally sympathize with their own kind, and the best lawyers working for those who pay most, there is little real justice. As a general rule, the richer the criminal (for those few rich criminals who are caught and tried), the shorter the sentence. Capitalists-1 asset. &lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Students.&lt;&#x2F;li&gt;
&lt;li&gt;Strike. By withholding their work from the capitalists, the workers force them to give in to their demands, and win a new self-confidence. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Through their control of school boards and the publication of text books, the capitalists determine most of what is taught in the schools. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Workers party is taken over by party bureaucrats (only applies if the Workers or their allies have landed on number 16 above). Workers-2 debits. &lt;&#x2F;li&gt;
&lt;li&gt;Inflation. With higher prices, workers buy less but capitalists make more profit. Workers-1 debit; Capitalists 1
asset.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Farmers.&lt;&#x2F;li&gt;
&lt;li&gt;Development of a socialist press to present the workers&#x27; point of view. The big job now is making people aware that it exists and encouraging them to read it. Workers -3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;State and federal regulatory commissions (like the Inter- state Commerce Commission) are supposed to protect the public from overly greedy (as distinguished from typically greedy) businessmen. When the capitalists them- selves or their lawyers are appointed to these commissions, the wolf has been given the job of guarding the sheep. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;You are about to enter a higher stage of the class struggle. Knowledge of this helps you plan accordingly. On pass- ing: Workers-2 assets; Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Professional Class. &lt;&#x2F;li&gt;
&lt;li&gt;Workers organize community action groups and put pressure on landlords, local hospitals and schools for better services. In the process, they learn how to struggle more effectively. Workers--3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists provoke an imperialist war in their constant search to find new countries in which to turn a fast buck. In such wars, the workers are usually fooled by patriotic propaganda into supporting their bosses, at least at the
start. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: election. (See number 19).&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Small Shopkeepers.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Watergate scandal forces the Government, momentarily, to put aside its &amp;quot;dirty tricks&amp;quot; operations against the workers and their allies. Workers-1 asset; Capitalists 2 debits&lt;&#x2F;li&gt;
&lt;li&gt;Crime in the streets is no answer to poverty. It only debits. divides the workers and increases repression. Workers - 1 debit&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists expand their profits by getting the Government -1 debit. to waste more of the tax payer&#x27;s money on arms, or what they hypocritically call &amp;quot;defense&amp;quot;. Before all the double- talk set in, the Defense Department was called the War Department. Capitalists-1 asset. &lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;When the capitalists&#x27; profit is the deciding factor, progress in inventions leads to fewer jobs rather than to lighter work. That&#x27;s why workers often oppose the introduction of new machines. Science will work for the people only when the people, not the capitalists, control it. Workers -1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;Strike. (See number 27) Strikes become bigger and more frequent as the class struggle intensifies. Workers-3 assets. But the capitalist often responds by locking the workers out of the factory until they accept his conditions. Capitalists-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with the Students.&lt;&#x2F;li&gt;
&lt;li&gt;State legalizes gambling to fool each worker into believing that one day he will become rich. The only sure winners in this game are the capitalists. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;More trade unions. (See number 11) In the United States today, less than a quarter of our workers are in unions (much less than in any other capitalist country), so a lot of organizing remains to be done. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Successful workers&#x27; revolution abroad reduces the capital- ists&#x27; business opportunities in that country and encourages the workers&#x27; movement at home. Workers-2 assets; Capitalists-1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;Workers start a new, more broadly based political party. The more people within the working class who get in- volved in the political struggle, the greater the power of the workers. Workers-3 assets. &lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with any of the minor classes. &lt;&#x2F;li&gt;
&lt;li&gt;Watergate scandal is forgotten. Government resumes its &amp;quot;dirty tricks&amp;quot;. If people only had a better memory for historical injustices, capitalism would have been put to bed a long time ago. It doesn&#x27;t help, of course, that history teachers spend so little time talking about these injustices. Workers-1 debit; Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: general strike. All the workers lay down their tools. The workers&#x27; power is evident as all economic life comes to a halt.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Black and white workers unite to fight racism. Racism is one of the main reasons for the division and resulting weakness of the working class. The capitalists understand this all too well, and do their best to promote hostility between black and white workers. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Using the excuse of the fiscal crisis, the banks refuse to lend the cities any more money until they get rid of free higher education. It is dangerous for capitalism when too many young people from the working class are learning how to think for themselves. It is also not very profitable. Workers-1 debit; Capitalists-1 asset. &lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Increase in attendance and in the T.V. audience of mass spectator sports, another &amp;quot;opium of the people&amp;quot;. By making people of all classes into &amp;quot;fans&amp;quot; of the same teams, capitalists also make it difficult for the workers to think about their interests as workers (and turn a neat profit in the process). Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;You are about to enter the highest stage in the class struggle. (See number 36 above) Workers-2 assets; Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Crisis (or &amp;quot;depression&amp;quot;, or &amp;quot;recession&amp;quot;, now called a &amp;quot;pause&amp;quot;): production and sales go down, unemployment goes up, while machines and often the things they produce are left to go to waste and even destroyed. All this at a time when millions of people are going hungry. More and more workers begin to see how irrational it is to let capitalists, who are only interested in their profit, decide what our society needs. Workers-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists enlarge the size of the police and the army as their surest means of staying in power. Capitalists-2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Rent and tax strikes are spreading throughout the country. Squeezed by a tight economic situation and encouraged by a growing working class movement, people are ceasing to play by the capitalist-imposed &amp;quot;rules of the game&amp;quot;. Respect for traditional authorities is weakening. Workers -2 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Like religion, T. V. thrillers, spectator sports and gambl ing, pornography keeps workers from thinking about their class interests and organizing to do something about them. The name of the capitalist game seems to be to get work- ers to think about everything except what is really hap- pening to them. Workers-1 debit.&lt;&#x2F;li&gt;
&lt;li&gt;Police scandal exposes the links between the Mafia, Big Business and the cops. Watch out when workers learn that at the top of high society the cops and the robbers are the same people. Capitalists-2 debits.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: general strike. (See number 58).&lt;&#x2F;li&gt;
&lt;li&gt;Male and female workers unite to fight sexism. Along with racism, sexism is among the greatest barriers to working class unity and power. Again, the capitalists understand this very well, and do their best to promote hostility between male and female workers. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;F.B.I. spies have infiltrated the leadership of the workers&#x27; party. In politics, as in business, when the capitalists can&#x27;t win by playing within the rules (rules which they themselves have made), they don&#x27;t mind breaking them. Capitalists-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists throw many workers&#x27; leaders in prison. This is an act of desperation by the capitalists that temporarily stalls the workers&#x27; advance. Workers-2 debits.&lt;&#x2F;li&gt;
&lt;li&gt;Chance for an alliance with any of the Minor Classes. &lt;&#x2F;li&gt;
&lt;li&gt;Strike. &amp;quot;Nobody throws our leaders in jail and gets away with it&amp;quot;, say the workers. In a strike, new leaders are formed. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CHANCE.&lt;&#x2F;li&gt;
&lt;li&gt;Cold Feet. In the final stages of the class struggle, they who hesitate are lost. Think about this as you miss as many turns at the dice as you have allies.&lt;&#x2F;li&gt;
&lt;li&gt;Capitalists start another imperialist war but the workers have wised up and refuse to fight. Why kill and be killed in a war that only benefits the capitalists? Capitalists-2 debits.&lt;&#x2F;li&gt;
&lt;li&gt;Nuclear War. The capitalists control the state, so only they can trigger off nuclear war. And the capitalists are capable of any folly once they sense their days in power are numbered. If the capitalists land on this square before the workers or their allies, the game is automatically over.&lt;&#x2F;li&gt;
&lt;li&gt;Government orders the destruction of all copies of that dangerous game, &amp;quot;Class Struggle&amp;quot;. It may be too late, however. Capitalists-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;Socialist ideas are spreading in the police and the army. Policemen and soldiers, especially in the lower ranks, begin to understand that they too have bosses and that they share many interests with the workers. The time when they have unthinkingly served as watchdogs for capitalism has come to an end. Workers-3 assets.&lt;&#x2F;li&gt;
&lt;li&gt;CONFRONTATION: revolution. No one knows what a revolution in America would look like. All that can be said for sure is that the more people who want it, who reject capitalism and who want a society shaped in the interests of the workers and their allies, the swifter, more democratic and less violent it will be. Yes, revolution, which means a radical change in capitalist social and economic structures, can come about democratically and without major violence. Whether it will or not depends less on the workers than on the means the capitalists use to defend their privileges at that moment when the long suffering majority have decided they have had enough.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;strong&gt;Hints Classroom for Use&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;It is best if there is one set of &amp;quot;Class Struggle&amp;quot; for every six players. But if only one copy of &amp;quot;Class Struggle&amp;quot; is available, several people can represent each class. In this case, they can take turns throwing the dice, but decisions regarding strategy--whether to enter into an alliance, for example-should be taken by a majority vote of the whole group.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;With several people representing each class, it is probably not possible, even with college students, to use TOURNA- MENT RULES. Younger students should stick to BE- GINNERS RULES, while older students (fourteen and over) should play by the FULL RULES.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Again, with several people representing each class: as classes land on the different squares, someone-perhaps the teacher-should read the explanations of why these squares offer the number of assets and debits that they do (See &amp;quot;Why?&amp;quot; section of this booklet).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;As the game progresses from one level of Class Struggle to the next, it is a good idea-no matter how many play- ers are representing each class-to pause for questions and discussion.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Time should also be left at the end of the game to discuss whether what has been depicted is fact or fiction. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Don&#x27;t let any of the above interfere with the students&#x27; fun
and enjoyment of the game. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;7There are literally thousands of good socialist books and journals available these days, but those which I believe would be particularly appropriate to read along with (or after) using &amp;quot;Class Struggle&amp;quot; in class include- &lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Dowd, Douglas F., The Twisted Dream: Capitalist
Development in the United States since 1776 (Win-
throp Publishers, 1974).&lt;&#x2F;li&gt;
&lt;li&gt;Edwards, Richard, et al., The Capitalist System (Prentice-Hall, 1972). A reader containing many excellent articles. &lt;&#x2F;li&gt;
&lt;li&gt;Huberman, Leo, We, the People, (Monthly Review Press, many editions). The simplest of the radical histories of the U.S.&lt;&#x2F;li&gt;
&lt;li&gt;Huberman, Leo, and Sweezy, Paul, Introduction to Socialism, (Monthly Review Press, many editions).&lt;&#x2F;li&gt;
&lt;li&gt;Katznelson, Ira, and Kesselman, Mark, The Politics of Power (Harcourt Brace Janovich, 1975). The best socialist introduction to the workings of American government. &lt;&#x2F;li&gt;
&lt;li&gt;Marx, Karl, and Engels, Frederick, The Communist Manifesto.&lt;&#x2F;li&gt;
&lt;li&gt;Marx, Engels, and Rius, The Communist Manifesto Comic Book (Quixote Publishers, 153 East Gilman St., Madison, Wis., 53703). Excellent.&lt;&#x2F;li&gt;
&lt;li&gt;McLellan, David, The Thought of Karl Marx (Har- per and Row, 1971). The simplest of the many books of selections of Marx&#x27;s writings. Contains a brief biography.&lt;&#x2F;li&gt;
&lt;li&gt;Tressel, Robert, The Ragged Trousered Philanthro- pist (Lawrence and Wishart, London, 1976; and Monthly Review Press, forthcoming). My favorite socialist novel. Contains several simple explanations of difficult socialist ideas.&lt;&#x2F;li&gt;
&lt;li&gt;Williams, William A., America Confronts a Revolu- tionary World: 1776-1976 (William Morrow and Co., 1976). Eye opening history.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;For teenagers, let me add, FPS: A Magazine of Young People&#x27;s Liberation (2007 Washtenaw, Ann Arbor, Mich., 48104). Like it says.
&amp;quot;CLASS STRUGGLE&amp;quot; NEWSLETTER
Send us your name and address to receive one free copy of the &amp;quot;Class Struggle&amp;quot; newsletter, where we will print what you think of &amp;quot;Class Struggle&amp;quot;, what we think of what you think, and what you think of what we think of what you think.
CLASS STRUGGLE, INC., 487 Broadway,
N.Y., N.Y., 10013.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Dear Friend,
Please do not read the rest of this letter until you have played the game...
Now that you have played &amp;quot;Class Struggle&amp;quot; (and if you have enjoyed it), you may be asking &amp;quot;What can I do to get &#x27;Class Struggle&#x27; into the hands of more people?&amp;quot;. The answer is that you can do a lot that is beyond the power of our limited distribution network. You can, for ex- ample, show your copy of the game to local book, toy, game, stationery, gift, department, and magazine stores, and encourage them to order. The back cover of the box tells most of the story.
With you allied to us, we cannot lose...nor can you.
Yours In Struggle,
Bertell Ollman
(For Class Struggle, Inc.)
*If &amp;quot;Class Struggle&amp;quot; is not available in your community, individual copies can be obtained directly from Class Struggle, Inc., 487 Broadway, N.Y., N.Y., 10013 for $11.95 (includes postage in U.S.) (N. Y. residents add $.96 sales tax). Foreign buyers should inquire from their local post offices what it costs to send a three pound package by mail and send that sum together with $11.95 in a check drawn on a U.S. bank.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;game-board&quot;&gt;Game Board&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;marx&#x2F;Untitled%204.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Sept&#x2F;Oct 2022</title>
		<published>2022-10-31T00:00:00+00:00</published>
		<updated>2022-10-31T00:00:00+00:00</updated>
		<link href="https://kipp.ly/sept-oct-2022/"/>
		<link rel="alternate" href="https://kipp.ly/sept-oct-2022/" type="text/html"/>
		<id>https://kipp.ly/sept-oct-2022/</id>
		<content type="html">&lt;p&gt;Jan Leike characterizes &lt;a href=&quot;https:&#x2F;&#x2F;aligned.substack.com&#x2F;p&#x2F;alignment-solution&quot;&gt;possible solutions to the alignment problem&lt;&#x2F;a&gt;, the most concerning aspect of which is eliciting human values imo. A characteristically excessively long but correct post about &lt;a href=&quot;https:&#x2F;&#x2F;forum.effectivealtruism.org&#x2F;posts&#x2F;xomFCNXwNBeXtLq53&#x2F;bad-omens-in-current-community-building&quot;&gt;EA Bad Vibes&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;irmckenzie.co.uk&#x2F;round1&quot;&gt;Inverse Scaling Prize winners&lt;&#x2F;a&gt;. DeepMind published needed post on &lt;a href=&quot;https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;how-our-principles-helped-define-alphafolds-release&quot;&gt;principles behind releasing AlphaFold&lt;&#x2F;a&gt;. Ben Todd‚Äôs new &lt;a href=&quot;https:&#x2F;&#x2F;www.effectivealtruism.org&#x2F;articles&#x2F;introduction-to-effective-altruism#what-values-unite-effective-altruism&quot;&gt;intro to EA&lt;&#x2F;a&gt;, also all his &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;ben_j_todd&#x2F;status&#x2F;1586338738841751552&quot;&gt;tweets&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;ben_j_todd&#x2F;status&#x2F;1585615622993596416&quot;&gt;this&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;ben_j_todd&#x2F;status&#x2F;1586347168344178688&quot;&gt;month&lt;&#x2F;a&gt; have been amazing. Spencer Greenberg on &lt;a href=&quot;https:&#x2F;&#x2F;www.spencergreenberg.com&#x2F;2022&#x2F;08&#x2F;tensions-between-moral-anti-realism-and-effective-altruism&#x2F;&quot;&gt;moral realism in EA&lt;&#x2F;a&gt;, which is also a great philosophy lesson. &lt;&#x2F;p&gt;
&lt;p&gt;I was thinking about Interpretability as a Natural Science when I decided I should review the old interpretability literature and found out that Chris Olah &lt;a href=&quot;https:&#x2F;&#x2F;distill.pub&#x2F;2020&#x2F;circuits&#x2F;zoom-in&#x2F;#claim-1&quot;&gt;has already written about this in 2020&lt;&#x2F;a&gt;. Also looked at &lt;a href=&quot;https:&#x2F;&#x2F;colah.github.io&#x2F;posts&#x2F;2014-03-NN-Manifolds-Topology&#x2F;&quot;&gt;2014 topology interpretability&lt;&#x2F;a&gt;, which gave a really good intuition of why we need activations. In this crossover episode, a really good blog post about the &lt;a href=&quot;https:&#x2F;&#x2F;blog.janestreet.com&#x2F;does-batch-size-matter&#x2F;&quot;&gt;theory of batch size&lt;&#x2F;a&gt; from our favourite proprietary trading firm. Anthropic published the &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2022&#x2F;toy_model&#x2F;index.html&quot;&gt;superposition paper&lt;&#x2F;a&gt;. An additional &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;sbeckerkahn&#x2F;status&#x2F;1572255478666649602&quot;&gt;tweet thread&lt;&#x2F;a&gt; of an exploration of superposition, and &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;NeelNanda5&#x2F;status&#x2F;1570217241618305024&quot;&gt;another&lt;&#x2F;a&gt; about superposition in relation to Dettmer‚Äôs LLM.int8(). Human brains &lt;a href=&quot;https:&#x2F;&#x2F;www.matrig.net&#x2F;publications&#x2F;articles&#x2F;fusi2016.pdf&quot;&gt;do superposition&lt;&#x2F;a&gt; too! Neel Nanda‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;www.neelnanda.io&#x2F;mechanistic-interpretability&#x2F;favourite-papers&quot;&gt;favourite interpretability papers&lt;&#x2F;a&gt;, I specifically want to review the &lt;a href=&quot;https:&#x2F;&#x2F;www.alignmentforum.org&#x2F;posts&#x2F;AcKRB8wDpdaN6v6ru&#x2F;interpreting-gpt-the-logit-lens&quot;&gt;ROME paper&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=NpsVSN6o4ul&quot;&gt;this Sept 2022 ICLR submission&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;whisper.pdf&quot;&gt;Whisper&lt;&#x2F;a&gt; speech-to-text from OpenAI, gosh, finally. Nvidia &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.05433.pdf&quot;&gt;FP8 paper&lt;&#x2F;a&gt;, also gosh finally ü•∫. I‚Äôm trying to learn about GPUs, here is a &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2206.02874.pdf&quot;&gt;really good microbenchmarking paper&lt;&#x2F;a&gt; with unfortunate typography. Google multimodal model, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2209.06794&quot;&gt;PaLI&lt;&#x2F;a&gt;. Chris R√©‚Äôs lab puts out another banger, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.14135&quot;&gt;FlashAttention&lt;&#x2F;a&gt;. DeepMind sticks with the trusty naming scheme and comes out with &lt;a href=&quot;https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;d41586-019-03083-5&quot;&gt;AlphaTensor&lt;&#x2F;a&gt;, of which the RL I don‚Äôt totally understand. I‚Äôm impressed though it seems like the matmul algorithm won‚Äôt actually be useful. &lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;githubcopilotinvestigation.com&#x2F;&quot;&gt;most beautiful lawsuit website&lt;&#x2F;a&gt;, which includes &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;kipperrii&#x2F;status&#x2F;1585040378709037057&quot;&gt;a custom font&lt;&#x2F;a&gt;. Butterick occupies a special  space of extremely admirable (he‚Äôs basically a superhero?) yet has a versatility where none of his works are quite &lt;em&gt;perfect&lt;&#x2F;em&gt;. I stan this Hilel Wayne newsletter on &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;on-the-benefits-of-humanities-in-software&#x2F;&quot;&gt;benefits of humanities in swe&lt;&#x2F;a&gt;. Adept puts out &lt;a href=&quot;https:&#x2F;&#x2F;www.adept.ai&#x2F;act&quot;&gt;a demo&lt;&#x2F;a&gt; for their ACT-1 model. I didn‚Äôt feel carnally upset by Dall-E, but watching it use Google Sheets I was like ‚Äúnooooo... my art!‚Äù&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Helvetica_(film)&quot;&gt;Helvetica&lt;&#x2F;a&gt; documentary is the best thing I‚Äôve seen in a while. ‚Äú&lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;kipperrii&#x2F;status&#x2F;1581705698265640961&quot;&gt;It‚Äôs the real thing period coke period in helvetica period any questions? of course not. drink coke period simple&lt;&#x2F;a&gt;‚Äù is my favourite quote, and literally got me to drink coke. It also discusses why Helvetica caused the Vietnam war, though I think it‚Äôs platonically socialist. &lt;a href=&quot;https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Leader_(web_series)&quot;&gt;An anime about Karl Marx&lt;&#x2F;a&gt; commissioned by the CCP‚Äôs Marxism office (spoiler, he dies at the end).&lt;&#x2F;p&gt;
&lt;p&gt;Boot Boyz Biz &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;collections&#x2F;archive&#x2F;products&#x2F;brick-pencil&quot;&gt;essay on bricks&lt;&#x2F;a&gt;, because I got the shirt and wanted to know about quirky Estonian architects. They also made a shirt (which I‚Äôve acquired) that is perfect (includes a picture of the game ‚Äúset‚Äù) so of course I like this &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;products&#x2F;games&quot;&gt;essay&lt;&#x2F;a&gt; on play, though I‚Äôd skip the situationist stuff. A copy of the Marxist board game, &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Class_Struggle_(board_game)&quot;&gt;Class Struggle&lt;&#x2F;a&gt; was purchased for me as a gift! I will document the gameplay soon, as the current literature of it does not do justice. It‚Äôs worth remembering now, that Monopoly is a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Landlord%27s_Game&quot;&gt;fucked up version&lt;&#x2F;a&gt; of what it was supposed to be. My favourite thing about Boot Boyz Biz essays is that they bother putting in source material that is somewhat non-trivial to locate, as they do in &lt;a href=&quot;https:&#x2F;&#x2F;boot-boyz.biz&#x2F;collections&#x2F;archive&#x2F;products&#x2F;stafford-beer-techne&quot;&gt;‚ÄúTechne‚Äù&lt;&#x2F;a&gt; with Stafford Beer works.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo&quot;&gt;MMAcevedo&lt;&#x2F;a&gt;, a short story about perverse immortality. Gwern with &lt;a href=&quot;https:&#x2F;&#x2F;www.gwern.net&#x2F;fiction&#x2F;Clippy&quot;&gt;‚ÄúIt Looks Like You‚Äôre Trying To Take Over The World‚Äù&lt;&#x2F;a&gt; üñáÔ∏è. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;gravitylobby.club&#x2F;decisions.html&quot;&gt;Unbounded problem-spaces and rationality&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;gravitylobby.club&#x2F;dewey.html&quot;&gt;Dewey‚Äôs aesthetics&lt;&#x2F;a&gt;. Ah yes, &lt;a href=&quot;https:&#x2F;&#x2F;gravitylobby.club&#x2F;trashcan.html&quot;&gt;Georgism&lt;&#x2F;a&gt;, here we go. I can‚Äôt believe I read the whole &lt;a href=&quot;https:&#x2F;&#x2F;danluu.com&#x2F;futurist-predictions&#x2F;&quot;&gt;Dan Luu post on futurists&lt;&#x2F;a&gt;, but I think it was worth it. Much better than Superforecasting (book). My favourite idea was that of Jacque Fresco, about how people of the future will apply scientific method to everything. &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;ctbeiser&#x2F;status&#x2F;1557185814500708353&#x2F;photo&#x2F;1&quot;&gt;Mao, Georgism and Uber&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;chrislakin.substack.com&#x2F;p&#x2F;117519ef-c95e-45bb-86d9-080a4bd418c8&quot;&gt;Golden Rule for Communication&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;tobyshooters&#x2F;status&#x2F;1569815892996853771&quot;&gt;On text as interface&lt;&#x2F;a&gt;, or why I‚Äôm a grandma who really hates the idea of ‚Äútext as the universal interface‚Äù &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Refrigerator_mother_theory&quot;&gt;Refrigerator mother theory&lt;&#x2F;a&gt; üòï¬†&lt;a href=&quot;https:&#x2F;&#x2F;psyarxiv.com&#x2F;ktgwv&quot;&gt;17 Interventions to Implicit Bias tests&lt;&#x2F;a&gt;, none of which worked, but which I thought about of a lot for &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;ideas-about-discrimination&#x2F;&quot;&gt;this blog post&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;FTX publishes &lt;a href=&quot;https:&#x2F;&#x2F;www.ftxpolicy.com&#x2F;posts&#x2F;possible-digital-asset-industry-standards&quot;&gt;Possible Digital Asset Industry Standards&lt;&#x2F;a&gt;, which includes the 5-5 standard, which is basically a standard to say that if you execute a security breach you can only keep 5 million? That is, unless people are losing money, in which case you have to return as much as they need. Look, I don‚Äôt know much about crypto, I can‚Äôt say I like them, but if they do this then they will have my undying admiration. &lt;&#x2F;p&gt;
&lt;p&gt;Some Money Stuff highlights (non-Twitter) include a deepdive into &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-09-29&#x2F;uk-pensions-got-margin-calls#xj4y7vzkg&quot;&gt;UK Pension Margin Calls&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-10-04&#x2F;barclays-lost-track-of-its-notes#xj4y7vzkg&quot;&gt;Barclays loosing track of it‚Äôs notes&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-09-12&#x2F;citi-got-its-500-million-back#xj4y7vzkg&quot;&gt;Citi getting the 500M back&lt;&#x2F;a&gt; from the oopsie it made a while ago, the &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-09-28&#x2F;the-deli-was-allegedly-a-fraud#xj4y7vzkg&quot;&gt;shell deli&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-09-20&#x2F;morgan-stanley-lost-some-hard-drives#xj4y7vzkg&quot;&gt;lost Morgan Stanley computers&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-09-15&#x2F;patagonia-has-no-more-owners#xj4y7vzkg&quot;&gt;Patagonia owners got sad about being rich&lt;&#x2F;a&gt; in the best way. Also Elon has Twitter now and the Ethereum merge happened. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;cool-gray-city-of-love-gary-kamiya-2013&quot;&gt;Cool Gray City of Love, Gary Kamiya 2013&lt;&#x2F;h3&gt;
&lt;p&gt;I started reading this a several months after moving to San Francisco, because I asked for a book that was like ‚Äúsomeone giving a tour of their suburban hometown‚Äù. The 49 chapters of San Francisco held a few moments that were more grand than anything you‚Äôd find about a suburban hometown. The Great Fire, the Gold Rush, the Summer of Love, the dot-com boom, the AIDs epidemic. History lessons are ok, but Gary Kamiya did also write about random grocery stores he used to go to that passed a while ago. &lt;&#x2F;p&gt;
&lt;p&gt;It‚Äôs a super romantic book! It‚Äôs full of sentiment, vibe and poetry. In describing the earliest failures to discover SF in the fog and the earliest settlements, Kamiya gave a really romantic characterization of the city‚Äôs complex and unique relationship with the ocean. For poetry, it of course gives little tidbits about the Beats but also about a magazine called the Lark. The Lark was a literary magazine written by a bunch of young people with a small but happy following, elaborate graphics and humorous but sophisticated essays, poetry, et cetera. This was just like, the best shit because this 1895 magazine feels like the epitome of writing that San Francisco produces today, whether it be the tweets, the Medium articles or &lt;a href=&quot;https:&#x2F;&#x2F;www.kernelmag.io&#x2F;&quot;&gt;the&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;www.palladiummag.com&#x2F;&quot;&gt;actual&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;logicmag.io&#x2F;&quot;&gt;magazines&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;The first edition of the Lark debuted a now-famous poem by Gelett Burgess, which is perhaps now more notable than the magazine itself.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I never saw a Purple Cow,&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I never hope to see one;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;But I can tell you, anyhow,&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;d rather see than be one&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The last edition of the Lark contains this following. Present magazines that the Bay Area produces really lacks this sophisticated tongue-in-cheek energy. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Ah, yes, I wrote the &amp;quot;Purple Cow&amp;quot;‚Äî&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;m Sorry, now, I wrote it;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;But I can tell you Anyhow&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;ll Kill you if you Quote it!&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I‚Äôm rather illiterate, so when I read I‚Äôm often googling about people or concepts or looking things up in a dictionary. With Cool Gray City of Love, my references were walking around the city, and pulling up a map whenever Kamiya referenced a specific intersection or a neighbourhood I forgot the location of. I didn‚Äôt like San Francisco Chinatown. It‚Äôs tacky, it doesn‚Äôt have particularly good food (Richmond is tasty though) and I went there once for tourism purposes and never quite set foot there again. The book describes Chinatown after the Great Fire, where the Chinese population fought to be allowed to rebuild in the place of their original homes. This is when the caricature of San Francisco Chinatown was built, eventually becoming a tourist attraction for the city. I don‚Äôt feel so much anymore that Chinatown lacks authenticity. Insofar as it‚Äôs one of the few places in North America where a Chinese population could determine from rubble what they wanted to build, it is exceedingly authentic. &lt;&#x2F;p&gt;
&lt;p&gt;The book ends on a chapter about Land‚Äôs End, describing the views of places that no one can quite reach, that even Gary Kamiya who spent his life in SF (partly as a taxi driver) will never fully discover the city. Excellent pairing for my months settling into SF, every walk around the city is more colourful and the memetic hatred of the city has certainly been cut. &lt;&#x2F;p&gt;
&lt;p&gt;There are probably few other cities for which such a book exists. Just the right amount of history such that you can go back in forth between benign flavouring and historical retellings. I tried to find one for New York, and ended up sorting books into specific neighbourhoods of New York (I don‚Äôt mean ‚ÄúManhattan‚Äù, I mean, I needed a book for ‚ÄúLower East Side‚Äù). Closest I got with NYC, was a &lt;a href=&quot;https:&#x2F;&#x2F;www.goodreads.com&#x2F;book&#x2F;show&#x2F;9824.Rats&quot;&gt;book about rats&lt;&#x2F;a&gt; and it sits on my shelf now.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>flavourings on discrimination</title>
		<published>2022-10-17T00:00:00+00:00</published>
		<updated>2022-10-17T00:00:00+00:00</updated>
		<link href="https://kipp.ly/flavourings-on-discrimination/"/>
		<link rel="alternate" href="https://kipp.ly/flavourings-on-discrimination/" type="text/html"/>
		<id>https://kipp.ly/flavourings-on-discrimination/</id>
		<content type="html">&lt;p&gt;part of the reason i spent a bunch of time thinking about discrimination in theory, were my experiences with credentialism, specifically thinking about how it has been far worse for me than gender discrimination. here are some short, caricaturizing tales about my interactions with discrimination. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;deja-vu&quot;&gt;deja vu&lt;&#x2F;h3&gt;
&lt;p&gt;when i started programming, i was asked a lot about whether i was worried about sexism or whether i had experienced it. this eventually stopped. maybe people don‚Äôt ask me anymore because the space i‚Äôve found is so lovely and devoid of sexism, or maybe because they‚Äôve figured i‚Äôve been around long enough to be sick of talking about it. i dare say in the past few years i don‚Äôt think i‚Äôve experienced gender discrimination at all. &lt;&#x2F;p&gt;
&lt;p&gt;in the past few months i‚Äôve met more people in the machine learning industry than i have since i learned what a neural network was. they‚Äôre friendly! they ask me questions!&lt;&#x2F;p&gt;
&lt;p&gt;at my first attendance at an academic or machine learning conference, i got a lot of ‚Äúdo you worry that people won‚Äôt hire you without a degree?‚Äù and  ‚Äúdo the people you work with underestimate you?‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;deja vu! how many times have i answered questions like ‚Äúdo you feel like working in tech has been harder as a woman‚Äù? it was bitter how this discrimination was happening to me again but sweet how it didn‚Äôt feel nearly as heavy and that people still cared. but, like, omg, it‚Äôs the same!&lt;&#x2F;p&gt;
&lt;p&gt;that same conference highlighted the similarities between the two causes of discrimination for me. a former harasser of mine who had propositioned me as a minor was there, as was a person who repeatedly undermines my competency on the grounds of credentials. as i hid behind posters avoiding my harassers, i noticed that my mind had glommed these two characters into one (not to say that the offenses are remotely equal). &lt;&#x2F;p&gt;
&lt;p&gt;my feelings and reasonings about them were all the same, just in differing magnitudes. the difference highlighted, was that one of these was a clear cut situation everyone has a knee jerk reaction to while the other is difficult to explain to people. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;discrimination-looks-a-lot-like-stupidity&quot;&gt;discrimination looks a lot like stupidity&lt;&#x2F;h3&gt;
&lt;p&gt;when the subject of the discrimination (credentials) is so close to the merit being evaluated (skills), it‚Äôs much easier to see a correlation between discrimination and stupidity. &lt;&#x2F;p&gt;
&lt;p&gt;going to icml, i was really happy to find that all the people whose work i admired were disproportionately unfazed by my lack of education and publishing history. i was so excited and comfortable to get people to explain undergraduate (highschool?) calculus to me. &lt;&#x2F;p&gt;
&lt;p&gt;credentialism is much more about accurate judgement than other forms of discrimination. it doesn‚Äôt come so much from religion, culture or history. &lt;&#x2F;p&gt;
&lt;p&gt;this was showcased to me that the judgement of educators was particularly charitable. it makes sense that they would know better about how people can be skilled! funky corollary here is that most of credentialism is not a product of morality. &lt;&#x2F;p&gt;
&lt;p&gt;i‚Äôm so utterly grateful to the not one but two companies who had to come up with a new interview for me because i could not so much as approach a math interview and wanted to hire me anyway. i like to think that the charitability was a good move for them. &lt;&#x2F;p&gt;
&lt;p&gt;stupidity being the cause of discrimination is a really important framing for me. nerds (like me) have a sense (which i only sometimes endorse) where we get carnally frustrated when we think people aren‚Äôt behaving intelligently. that sense is more native to me than my sense of justice. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;leveled-up&quot;&gt;leveled up&lt;&#x2F;h3&gt;
&lt;p&gt;so like, i‚Äôve escaped sexism and had a long break to not think about discrimination but in the past bit credentialism has kind of been all up in my face. &lt;&#x2F;p&gt;
&lt;p&gt;is this leveling up? &lt;&#x2F;p&gt;
&lt;p&gt;some of the same tactics from last time work. the ‚Äúshow them what you‚Äôre made of‚Äù, the ‚Äúdon‚Äôt let them get to you‚Äù. the ‚Äúsimply find a place where they‚Äôre not going to do this to you‚Äù (i recently interviewed at &lt;a href=&quot;&#x2F;job-search-love-letters&quot;&gt;five places&lt;&#x2F;a&gt;, none of them will do this [any kind of discrimination, i think] to you). these are actually everything i personally need, so maybe this level isn‚Äôt that much harder than the last.&lt;&#x2F;p&gt;
&lt;p&gt;unfortunately some tactics don‚Äôt work. there‚Äôs no anonymous hr form for this. there‚Äôs no social norm to be outraged. it‚Äôs very true that my inability to do math has impeded my competency and so the situation is harder to explain. no employee resource groups, no norm of politely calling it out. seems like some of the tools that were available in the last level will have to be recreated. &lt;&#x2F;p&gt;
&lt;p&gt;i wonder what the boss battle will be. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;malevolence&quot;&gt;malevolence&lt;&#x2F;h3&gt;
&lt;p&gt;being told i can‚Äôt get a senior research position without a PhD by someone who knows my work well seems pretty bad. it came with other comments about how i don‚Äôt care about being productive, and how i should not be trusted on anything i say (who says that??!)&lt;&#x2F;p&gt;
&lt;p&gt;that was too comical to take to heart, much like that guy who told me i must‚Äôve cheated on my interviews because i‚Äôm female. with that guy, i told my friends about it, got their support and limited the places where they could do further damage. with the credentialist i got only two thirds of the way. &lt;&#x2F;p&gt;
&lt;p&gt;at this extremity, the negative feelings are more disgust and disappointment. the core offense is not bigotry or ignorance but plain hatred and a fixation on disparaging others. it would be reasonable for one to not consider this discrimination, but this kind of asshattery is how it all starts! the legacy of an excuse to treat someone poorly easily is canonical discrimination. &lt;&#x2F;p&gt;
&lt;p&gt;given that discrimination starts as malevolence that becomes a burden of history, producing that fresh malevolence may be more of an offense than carrying forth an aged one. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;ghosts&quot;&gt;ghosts&lt;&#x2F;h3&gt;
&lt;p&gt;it‚Äôs always a little personal when you‚Äôre on a crusade to get a project kicked off and you‚Äôre seeking buy-in from colleagues. it‚Äôs supposed to be hard, as it was for me. someone noticed that it was maybe harder than it should be, and they were kind and conscientious enough to ask if i was worried about sexism. &lt;&#x2F;p&gt;
&lt;p&gt;at the time i immediately passed it off and said no ‚Äî my colleagues were better than that! upon reflection, it seemed that it was credentialism.&lt;&#x2F;p&gt;
&lt;p&gt;then, what was up with that extremely lowball offer i didn‚Äôt know better than to take? what about every time i was passed on for promotion? when my colleagues refused to trust my work? every time i was talked over in a meeting? &lt;&#x2F;p&gt;
&lt;p&gt;seeing ghosts is bad, they turn you to stone if you look at them! i saw sexism-ghosts when i started learning programming as i was overly cautioned about sexism to the point of it being an infohazard. there aren‚Äôt many mechanisms through which looking for the monsters equips oneself for defense. &lt;&#x2F;p&gt;
&lt;p&gt;the judgement that people exercise when they‚Äôre open to my competency is not about &lt;em&gt;precision&lt;&#x2F;em&gt;, but accepting a broad range of possibility. for me to see ghosts would be violating that practice. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;get-up-and-leave&quot;&gt;get up and leave&lt;&#x2F;h3&gt;
&lt;p&gt;‚Äúok so people are being mean to me &lt;em&gt;now,&lt;&#x2F;em&gt; what do i do?‚Äù. having done the dance twice, it seems like the best way to do it is to find a place where no one is mean to you (though you should be emotionally equipped anyway). &lt;&#x2F;p&gt;
&lt;p&gt;perhaps i‚Äôm merely fortunate, but it seems like a natural progression to find places that are less discriminatory. the forces of morality and the incentives they‚Äôve put in place have made it increasingly the case that more prestigious places are less discriminatory, and they‚Äôll continue to do so.&lt;&#x2F;p&gt;
&lt;p&gt;sometimes people are irked by the idea that i just don‚Äôt really experience sexism anymore, or that i don‚Äôt think about it often or exercise much agency to fix it. i empathize with that, it‚Äôs like when i‚Äôm upset about something but the other involved party is not. &lt;&#x2F;p&gt;
&lt;p&gt;what‚Äôs strange to me, is that when people gave me advice on sexism it was always like ‚Äúhere‚Äôs how you get the assholes in trouble, be a powerful independent women, advocate for minorities‚Äù, where the default advice for credentialism is ‚Äúoh yeah, you‚Äôve just gotta find somewhere where it‚Äôs not a problem‚Äù ‚Äî which is what i‚Äôve always gone for. &lt;&#x2F;p&gt;
&lt;p&gt;it shall remain my advice, that the solution to discrimination in one‚Äôs life is to be a cog in the morality machine by not being in places where bad things happen to you.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Ideas About Discrimination</title>
		<published>2022-10-17T00:00:00+00:00</published>
		<updated>2022-10-17T00:00:00+00:00</updated>
		<link href="https://kipp.ly/ideas-about-discrimination/"/>
		<link rel="alternate" href="https://kipp.ly/ideas-about-discrimination/" type="text/html"/>
		<id>https://kipp.ly/ideas-about-discrimination/</id>
		<content type="html">&lt;p&gt;When I think about what the future &lt;em&gt;feels&lt;&#x2F;em&gt; like, what optimality is, I‚Äôm often lost for what‚Äôs supposed to happen with discrimination, or how we‚Äôre to try to grasp at what‚Äôs to be. What are the properties of discrimination in the abstract, and what exactly has our progress so far been? What‚Äôs in the way? What does a world without discrimination look like?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;humps&quot;&gt;Humps&lt;&#x2F;h2&gt;
&lt;p&gt;I think there are broadly, three humps in discrimination, things that are in the way of us making further progress. &lt;&#x2F;p&gt;
&lt;p&gt;1. Different value systems cause different treatments&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Differing ethical systems often don‚Äôt cause different treatments, in which case there isn‚Äôt a problem. I find that the moral framework is not often the easiest thing to adjust, rather some more particular value adjustment can get people to agree on a treatment.&lt;&#x2F;li&gt;
&lt;li&gt;A crux that often occurs is whether people discriminate differently if the group at hand &lt;em&gt;choses&lt;&#x2F;em&gt; their identifying feature. Another example is those with strong (traditional) family values have untanglable implications for sexism.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;2. Deciding what to do given your morality is hard (some discrimination groups don‚Äôt need to be balanced to ‚Äúequal treatment‚Äù).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Dealing with racism and sexism is relatively easy, since all you have to do is apply ‚Äúequal treatment‚Äù. Discrimination against non-equal treatment groups is much harder, as you have to decide exactly how much worse one group is under the infinite number of contexts to evaluate.&lt;&#x2F;li&gt;
&lt;li&gt;The worst of this I think is classism. It‚Äôs really messy if you have probably reasonable values like ‚Äúsmart people are cool‚Äù or ‚Äúcontributions to society are good‚Äù but need to apply those accurately as not to be overly unfair to people. Secondarily, there‚Äôs even more calibration problem when there are conflicting values like ‚Äúcorrecting imbalance‚Äù where you have responsibility to help people. Also in this category are parts of fatphobia, credentialism, and the outskirts of basically any form of discrimination.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;3. Subconscious biases&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We already are at a point where we‚Äôve noticed that this can do harm, but like, how the hell do we solve it? Our two options are to stop these from forming in the first place, or trying to gain sufficient control over our cognition to remove it. Both seem hard.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I think Hump 0 was actually a precursor to Hump 2, which was something like ‚Äúwe‚Äôre not sure who counts as human!‚Äù. The answer was something like ‚Äúsure seems like we were doing some extreme motivated reasoning to convince ourselves that these people weren‚Äôt human‚Äù and now we‚Äôre more careful about it. Hump 4 might be something like ‚Äúwe‚Äôve reached the ends of what systematic solutions can accomplish, and we simply need people to stop being assholes‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Discrimination against ugly people&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I‚Äôm increasingly convinced that this is the most terrifying (as in, upsetting on moral grounds and not necessarily the one that does most damage) discrimination we perform as a society. Naively, the only excusable of lookism is in romantic&#x2F;sexual endeavours, but it‚Äôs all wrapped up into things like fitness, fashion and general care. &lt;&#x2F;p&gt;
&lt;p&gt;I do still think it‚Äôs a massive historical injustice (and especially sad one as it‚Äôs largely uncontrollable by the individual), and is fueled by something quite monkey brained. We should be far beyond treating people based on perceived mating value, not to mention that appearance has much less to do with mating value than our monkey brains would have us believe. &lt;&#x2F;p&gt;
&lt;p&gt;Yet, it‚Äôs mostly normal (though a little untasteful) to comment negatively on someone‚Äôs unattractiveness as a reason to be uncharitable. It‚Äôs often not viewed as untasteful at all if it were in the context of romance or sexual activity, even if the person was being excessively mean. This registers in peoples‚Äô careers, crime enforcement, social activities and we are rather upsettingly numb to it. Too much ‚Äúthat‚Äôs just the way the world works‚Äù attitude. &lt;&#x2F;p&gt;
&lt;p&gt;The more terrifying thing though, is that we might be making excuses to never acknowledge that we do this, by offloading it into ‚Äúthey don‚Äôt put enough effort into themselves‚Äù or when people mix up ‚Äúcreepy‚Äù with ‚Äúugly‚Äù. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;utopia&quot;&gt;Utopia&lt;&#x2F;h3&gt;
&lt;p&gt;My definition of discrimination is probably broader than most, I define it as a sort of excess bad. It‚Äôs encompasses all forms of unjustness, but is not prejudice-free. I think utopia is a place that does not hav discrimination. &lt;&#x2F;p&gt;
&lt;p&gt;My utopia is not a place where we never do bad things to each other, I think that would require compromising the differing values we have as humans. My utopia does involve people acting in accordance with their own values, which will often be similar to other peoples‚Äô. &lt;&#x2F;p&gt;
&lt;p&gt;This goes wrong quickly. ‚ÄúI value murdering people who don‚Äôt have blond hair and blue eyes‚Äù, it screams! Surely we can‚Äôt avoid calling this discrimination. I would claim that this is a bad mesa-value. The underlying value would be something like ‚ÄúI value making other groups seem lesser to mine‚Äù. Under that, ‚ÄúI value feeling safe and supported by a community‚Äù. Presumably if this were you, and an omniscient being traced your values for you, you‚Äôd say ‚Äúoh ok the core value seems fine, but the downstream values seem inefficient, or conflicting with other values I have, like that murder is bad‚Äù. &lt;&#x2F;p&gt;
&lt;p&gt;There are some reasonable mesa-values, like ‚Äúart is great‚Äù ‚Üí ‚ÄúI value people with artistic talent‚Äù, and it would be ok to treat those people better. Maybe you really hate people who are lazy, and you might be mean to those people which feels less obviously ok, especially if the laziness identified has some chance of being mislabeled (as it often is today). The line may be a little fuzzy and I‚Äôm not sure how we‚Äôll ever be able to clear it up, though we‚Äôre currently far from it. &lt;&#x2F;p&gt;
&lt;p&gt;Utopia, will in some ways remove biases that we don‚Äôt currently have the cognitive capacity to. Some discrimination has been solved by us thinking harder (or new evidence being provided), and realising we‚Äôve been bad. But what about implicit biases? Perhaps much further down into the future, we‚Äôll live in a world where society doesn‚Äôt create implicit biases against black people. &lt;&#x2F;p&gt;
&lt;p&gt;Unless the utopia involves significantly changing the way humans generate emotion and interact socially, I suspect we‚Äôll still be very capable of being discriminatory. We have tried to create treatments for &lt;a href=&quot;https:&#x2F;&#x2F;psyarxiv.com&#x2F;ktgwv&quot;&gt;implicit association tests&lt;&#x2F;a&gt;, though it was comically unsuccessful. The only things that worked were basically cheating, and creating racism against white people. But what a world it would be if we had such treatments! ‚ÄúDoctor, I‚Äôm feeling a little racist, can you fix it?‚Äù&lt;&#x2F;p&gt;
&lt;p&gt;Jacque Fresco once predicted that humans would eventually become free from bias and apply ‚Äúthe scientific method‚Äù to their lives. I think people who value artistic talent should have room to treat those with artistic talent more kindly, to want to hang out with them and whatnot. Running around stoning those who can‚Äôt paint is definitely causing excess harm. In the giant gray area though, how do you decide? Superior cognition will probably be necessary in a discrimination-free utopia.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;good-will-is-no-longer-enough-we-need-good-judgement&quot;&gt;Good will is no longer enough, we need good judgement&lt;&#x2F;h3&gt;
&lt;p&gt;Even given identical moral values, epistemic processes will start showing up here. Say we‚Äôre thinking about discrimination against pregnant, skilled, women in the workforce, and two people agree that these situations should be treated with a strong utilitarian ideal ‚Äî they don‚Äôt care about the pregnancy itself, only the performance of an employee. The case here could be one person reasons to believe that generous maternity leave to allow for the employee to be kept long term is a good option while another believes that it would be easier to replace the employee. The difference is just in their world models, and well, probably one of them is smarter than the other. &lt;&#x2F;p&gt;
&lt;p&gt;But I think we (at least in the western blue states) are at the fringes of what we can solve by being a good person, in that the easiest ways to improve are through being smarter. This is primarily because I think a majority of problems in discrimination are being blocked by Hump 2. It‚Äôs very much a judgement problem, since it‚Äôs all about calibrating the optimal treatment for non-equal discrimination classes. Classism, credentialism, what‚Äôs remaining of sexism, lookism, ableism are all mostly hump 2 problems. We‚Äôve certainly tried to work on these things, but I was kind of disappointed with how the anti-fatphobia was executed, though it seems to be going better for ableism. &lt;&#x2F;p&gt;
&lt;p&gt;I‚Äôve considered that the problem all along was good judgement. The strongest argument for this is that moral progress in the form of ideas passed along generations seems a lot more plausible than generational increase of good will. Those ideas are the product of cumulative judgement. The ideas passed down though, was not so much an information passing of ‚Äúwe learned something new, turns out other races have moral value‚Äù but more ‚Äúwe should think more about whether we‚Äôre treating people fairly‚Äù. As far as I‚Äôm concerned, having that idea passed down is generational increase of good will. &lt;&#x2F;p&gt;
&lt;p&gt;There is already a lot of evidence that we‚Äôre at the new frontier. For example, we now have bias tests for people who want to do good, but are worried about subconscious biases to try to correct this. Building the test itself, is a demonstration of good judgement. The whole nature of this ‚ÄúI want to do good, but I need to think clearer to be able to exercise it‚Äù is a new practice for discrimination, at least as a burden that everyone will carry. &lt;&#x2F;p&gt;
&lt;p&gt;It‚Äôs certainly not news that smart people are often kinder or carry moral values better in various ways, but I think it‚Äôs kind of imperative for discrimination now. This is scary, as it takes away our Forrest Gump narrative that an extremely kind man can be rather dumb. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;some-half-baked-thoughts&quot;&gt;Some half baked thoughts&lt;&#x2F;h3&gt;
&lt;p&gt;I started listing instances of discrimination in my head, and there are some outliers like fatphobia and anti-semitism, but the one that updated me the most was the Cagot. There‚Äôs a canonical ideal of discrimination which involves very systematic, long-term harm, often caused by religion or some sort of historical baggage. The Cagot were a group of people who had no notable ethnic or cultural differences, and were severely discriminated against ‚Äî forced to wear goose feet on their clothing to segregate themselves. They were not allowed to marry non-Cagot, were buried separately, and were not allowed to even work with livestock (this varied between regions, hated of the Cagot was widespread). &lt;&#x2F;p&gt;
&lt;p&gt;There was no consensus as to why we hated them so much, but they do in fact no longer exist. They practiced the same religion, spoke the same language, and were not an ethnic group. We don‚Äôt really know why we hated them so much, but accusations included werewolves, lepers, cannibals or just being intrinsically evil. &lt;&#x2F;p&gt;
&lt;p&gt;My update from thinking about the Cagot, is this model that discrimination starts as people being mean, making excuses to be mean, then letting the burden of history carry it forth. &lt;&#x2F;p&gt;
&lt;p&gt;Why that update is important, is that it changes my model of how we can make progress. The reason what happened to the Cagot can no longer happen today is that globalization and the progress on discrimination holds us accountable. At the same time, it seems squarely the case that if discrimination comes from being mean, then we might not be able to fully eliminate it until people are no longer mean. I‚Äôm pretty sure people haven‚Äôt become less mean? It‚Äôs weird that it seems like society has made moral progress where individuals have not.&lt;&#x2F;p&gt;
&lt;p&gt;Another angle to the ‚Äúbeing mean‚Äù is that all discrimination cases are witch hunts. The literal witch hunts were discrimination. Witch hunts express why people are mean, which is broadly because people feel the need to have an outgroup, and will create it when it does not exist. I‚Äôve started reading about this aspect of human behaviour, why we need the outgroup (enemy group) and why it‚Äôs so hard to exist in neutrality, specifically from the lens of political theory (which seems to produce more useful&#x2F;correct models than sociology). This is of interest since it seems relevant to how discrimination occurs and if it‚Äôs even possible to ever solve without mutating this basic human desire. &lt;&#x2F;p&gt;
&lt;p&gt;The energy of discrimination as a witch hunt shines through with anti-semitism, given the Jewish migration across Europe (and eventually to New York and the rest of the New World). An oversimplification of the situation is something like, the Jewish were forced out of one country then travelled to another, only soon to be evicted from their new homes as well. It wasn‚Äôt literally the same people chasing them around, but it might as well have been. No discrimination has geographically travelled quite like this (I think the Crusades might be an example, but that has all its other complications [war]). Imagine fleeing Hungary to Germany due to anti-semitism in the 1920‚Äôs and seeing it follow you to Germany like watching a storm coming in (the Italy&#x2F;Mussolini situation was also peculiar).&lt;&#x2F;p&gt;
&lt;p&gt;Anti-semitism is also extremely special in how it affected the Jewish narrative, I don‚Äôt think any other discrimination has embedded this much historical impact into the psyche of a whole group. Another weird case of this though, is the commercialisation of gay and black culture as those humps in moral progress were passed. &lt;&#x2F;p&gt;
&lt;p&gt;I have a bunch of thoughts about how various discriminations are funky, this was a surprisingly strong nerd snipe. I think fatshaming was special because it was the first time that we sort of had consensus that we might‚Äôve overcorrected? I think credentialism is super weird, since we actually put up very discrete systematic barriers against the uncredentialed, unlike most forms of discrimination which are discretionary. I‚Äôm still kind of confused as to how we‚Äôve let lookism run so far and model minority based discrimination seems rather new? I haven‚Äôt even started to think religion!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Jul&#x2F;Aug 2022</title>
		<published>2022-09-03T00:00:00+00:00</published>
		<updated>2022-09-03T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jul-aug-2022/"/>
		<link rel="alternate" href="https://kipp.ly/jul-aug-2022/" type="text/html"/>
		<id>https://kipp.ly/jul-aug-2022/</id>
		<content type="html">&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;red_teaming.pdf&quot;&gt;Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned&lt;&#x2F;a&gt;, in which Anthropic finds that larger models are harder to redteam and releases a redteaming dataset. A little more clarity about &lt;a href=&quot;https:&#x2F;&#x2F;drive.google.com&#x2F;file&#x2F;d&#x2F;1TsB7WmTG2UzBtOs349lBqY5dEBaxZTzG&#x2F;view&quot;&gt;why and how to worry about alignment&lt;&#x2F;a&gt; from a technical perspective from Richard. Anthropic‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2022&#x2F;solu&#x2F;index.html&quot;&gt;SoLU Interpretability Paper&lt;&#x2F;a&gt;, with more intense math than last time but I‚Äôm managing. &lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;ai-safety&quot;&gt;Set Sail for Fail&lt;&#x2F;a&gt;, a really long nintil post about worrying about AI risk, with some hands tied behind his back. Jack Clark‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;jackclarkSF&#x2F;status&#x2F;1555980412333133824&quot;&gt;tweet thread&lt;&#x2F;a&gt; on AI Policy. &lt;a href=&quot;https:&#x2F;&#x2F;www.alignmentforum.org&#x2F;posts&#x2F;N6WM6hs7RQMKDhYjB&#x2F;a-mechanistic-interpretability-analysis-of-grokking&quot;&gt;A Mechanistic Interpretability Analysis of Grokking&lt;&#x2F;a&gt; from Neel Nanda, who I made explain fourier bases to me.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;timdettmers.com&#x2F;2022&#x2F;08&#x2F;17&#x2F;llm-int8-and-emergent-features&#x2F;&quot;&gt;LLM.int8() and&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2208.07339.pdf&quot;&gt;Emergent Features&lt;&#x2F;a&gt;, basically we should open the box (weights) and then think about solutions. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.14255.pdf&quot;&gt;Efficient Training of Language Models to Fill in the Middle&lt;&#x2F;a&gt;, a teaser of how we can get more out of our data. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.10342.pdf&quot;&gt;Language Model Cascades&lt;&#x2F;a&gt;, a framework for thinking about and building inference(ish) time model-thought-paths. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2201.02177.pdf&quot;&gt;Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets&lt;&#x2F;a&gt;, in which models generalize after overfitting (phase changes?). &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.07051.pdf%60&quot;&gt;Language models show human-like content effects on reasoning&lt;&#x2F;a&gt;, really nice DeepMind paper that captures how language models are flawed in the same way humans are, referencing 70‚Äôs psych papers. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2206.07137.pdf&quot;&gt;RHO-LOSS&lt;&#x2F;a&gt; for better data selection. Salesforce &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2207.01780.pdf&quot;&gt;Code RL paper&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Jos√© Luis Ric√≥n Fern√°ndez de la Puente‚Äôs &lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;us-immigration&#x2F;&quot;&gt;O1 Visas&lt;&#x2F;a&gt; post at last. Someone &lt;a href=&quot;https:&#x2F;&#x2F;www.thediff.co&#x2F;p&#x2F;jane-street?triedSigningIn=true&quot;&gt;explained Jane Street&lt;&#x2F;a&gt; in a way that didn‚Äôt make me sad. wtf someone &lt;a href=&quot;https:&#x2F;&#x2F;jayriverlong.substack.com&#x2F;p&#x2F;42-against-food&quot;&gt;dislikes food&lt;&#x2F;a&gt;. Aella on &lt;a href=&quot;https:&#x2F;&#x2F;aella.substack.com&#x2F;p&#x2F;learning-the-elite-class&quot;&gt;Learning the Elite Class&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bryanbraun.com&#x2F;2022&#x2F;07&#x2F;16&#x2F;scratch-is-a-big-deal&#x2F;&quot;&gt;Scratch is a Big Deal&lt;&#x2F;a&gt;. Someone captured a lot of the important aspects of &lt;a href=&quot;https:&#x2F;&#x2F;www.robinsloan.com&#x2F;newsletters&#x2F;visions&#x2F;#miyazaki&quot;&gt;Miyazaki films&lt;&#x2F;a&gt;, time for me to start rewatching.&lt;&#x2F;p&gt;
&lt;p&gt;A &lt;a href=&quot;https:&#x2F;&#x2F;www.vox.com&#x2F;future-perfect&#x2F;2022&#x2F;8&#x2F;8&#x2F;23150496&#x2F;effective-altruism-sam-bankman-fried-dustin-moskovitz-billionaire-philanthropy-crytocurrency&quot;&gt;Vox article about EA&lt;&#x2F;a&gt;, don‚Äôt think I‚Äôve ever related so much to a journalist. The &lt;a href=&quot;https:&#x2F;&#x2F;time.com&#x2F;6204627&#x2F;effective-altruism-longtermism-william-macaskill-interview&#x2F;&quot;&gt;Times profile on MacAskill&lt;&#x2F;a&gt; was such a throwback. Kelsey Piper on the &lt;a href=&quot;https:&#x2F;&#x2F;www.vox.com&#x2F;future-perfect&#x2F;2022&#x2F;8&#x2F;10&#x2F;23298108&#x2F;ai-dangers-ethics-alignment-present-future-risk&quot;&gt;divides in AI Safety&lt;&#x2F;a&gt;, usually epistemic and moral philosophy is a stronger divider than cause area. The &lt;a href=&quot;https:&#x2F;&#x2F;archive.ph&#x2F;pY4gF&quot;&gt;Elon &amp;lt;&amp;gt; EA story&lt;&#x2F;a&gt; finally came out and it‚Äôs sad but dramatic? The &lt;a href=&quot;https:&#x2F;&#x2F;hai.stanford.edu&#x2F;sites&#x2F;default&#x2F;files&#x2F;2022-08&#x2F;HAI%20Explainer%20-%20What%20The%20CHIPS%20and%20Science%20Act%20Means%20for%20AI.pdf&quot;&gt;CHIPS Science Act&lt;&#x2F;a&gt;, a plan to spend 280B on semiconductor manufacturing.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>System Design Interview Meta</title>
		<published>2022-08-25T00:00:00+00:00</published>
		<updated>2022-08-25T00:00:00+00:00</updated>
		<link href="https://kipp.ly/system-design-interviews/"/>
		<link rel="alternate" href="https://kipp.ly/system-design-interviews/" type="text/html"/>
		<id>https://kipp.ly/system-design-interviews/</id>
		<content type="html">&lt;p&gt;This is a slightly unorganized document containing thinking about system design interviews. It&#x27;s not at all interview advice but it may be helpful for understanding what a system design interview is about. It would be more helpful for a team thinking about how to conduct and design the interviews.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;skills&quot;&gt;skills&lt;&#x2F;h3&gt;
&lt;p&gt;The reason there are different kinds of interviews is to test for different skills. It‚Äôs worth thinking about what skills a system design interview test for.&lt;&#x2F;p&gt;
&lt;p&gt;The list is something like:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;background knowledge
&lt;ul&gt;
&lt;li&gt;all interview questions will call for knowledge of varying types, but system design will also call on &lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;scaling-tacit-knowledge&#x2F;#tacit-knowledge&quot;&gt;tacit knowledge&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;ability to adapt for constraints or new tools
&lt;ul&gt;
&lt;li&gt;in system design, you‚Äôll get a lot of ‚Äúok but we can‚Äôt compromise x‚Äù, &amp;quot;let&#x27;s say we can&#x27;t use x&amp;quot; and ‚Äúhow can you use z to help you?‚Äù as subproblems.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;planning
&lt;ul&gt;
&lt;li&gt;the planning here differs from say implementation problems since it&#x27;ll be less about laying out the steps and more about preparing for adaptability (the steps become a graph) and predicting circumstances.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;communication
&lt;ul&gt;
&lt;li&gt;you want to accurate communicate your solution, the reasoning for applying that solution and how you plan to execute it. system design tests the latter two parts more extensively.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;problem solving
&lt;ul&gt;
&lt;li&gt;main difference from implementation questions is that the solved state is less defined. that relates to the fact that he process will involve more exploration (sampling of tools, edge cases, use cases, contstraints to consider, etc) and creativity.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;background-knowledge&quot;&gt;background knowledge&lt;&#x2F;h3&gt;
&lt;p&gt;System design interviews almost always cover and expect background knowledge. Applying the knowledge demonstrates ability to pattern match problems, to reflect on solutions they have tried and the past. This is the main reason system design interviews are better for more senior &#x2F; experienced people, ass they capture how valuable their experience is.&lt;&#x2F;p&gt;
&lt;p&gt;Domain expertise allows a big advantage, and it may be hard to evaluate skills (say, their ability to think critically about solutions they‚Äôve attempted) in isolation. Being able to isolate the skills improves reasoning about performance and improves calibration.&lt;&#x2F;p&gt;
&lt;p&gt;One could cleanly separate it out by just asking them questions about their domain, but I find it‚Äôs possible to isolate in the system design interview.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;As an aside, I&#x27;m quite optimistic about the idea of quizzes as interviews. Not like &amp;quot;fill out a form&amp;quot; but someone will talk to you with a checklist of things they&#x27;d like you to know.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Some conducting guidelines about this.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Start by asking lots of questions to get a good understanding of their background to help you more accurately evaluate their reasoning and analysis skills and also guide them more effectively through the problem solving&lt;&#x2F;li&gt;
&lt;li&gt;Solutions that would be a bad idea to execute do not necessarily indicate poor candidate performance. Sometimes missing information can result in a bad idea, but perhaps the ideation and evaluation process was still impressive given what they knew&lt;&#x2F;li&gt;
&lt;li&gt;Let the candidate make incorrect assumptions if you think that simplifies the problem&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I think these conducting guidelines are quite common, and are the reason why I find lots of people are surprised about their evaluation on system design questions where they can accurately evaluate their own performance on implementation questions. It‚Äôs very easy for the candidate to not know that there might be a better solution given more knowledge, especially of the tacit kind.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;guidance&quot;&gt;guidance&lt;&#x2F;h3&gt;
&lt;p&gt;System design interviews should be very interactive, as they tend to be open-ended so candidates should be asking questions like ‚Äúwell we can perform a trade off between latency and throughput here, which do we care about more?‚Äù. They&#x27;re also harder to conduct for this reason, as you may need to guide the candidate to cover grounds for evaluation.&lt;&#x2F;p&gt;
&lt;p&gt;Here are some useful prompts to capture skills&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Give the candidate an additional piece of information, say a constraint or a tool they have access to and evaluate how well they update their thinking based on the new information.&lt;&#x2F;li&gt;
&lt;li&gt;Engage in discussion for questions the candidate asks. If they asked the question about latency and throughput I proposed above, don‚Äôt just give an absolute answer but discuss which one makes more sense for whatever is being worked on&lt;&#x2F;li&gt;
&lt;li&gt;Talk about whether they‚Äôve solved any similar (sub)problems, and how they‚Äôre applying that knowledge to the problem at hand. A good intuition is excellent, but being able to identify where that intuition comes from is even better.&lt;&#x2F;li&gt;
&lt;li&gt;Ask questions to check their understanding or to have them develop it. A common failure mode is for the candidate to give a big blanket solution like ‚Äúoh we can autoscale with kubernetes‚Äù and then not go into it further and either that part gets lost or even the interview could end too early, without enough signal.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;All of these guidance actions are specifically not hints ‚Äì they are not necessarily things that are done when struggle is observed, rather they are ways to stay engaged with the process and get more signal from the interview.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;hint-guide&quot;&gt;hint guide&lt;&#x2F;h3&gt;
&lt;p&gt;Thinking about hinting is really important for calibration but also useful for having a pleasant interview. It&#x27;s not always the case that hints are given for poor performance. Hints are really helpful to help direct the candidate down a certain path where you think you can get a more thorough evaluation or to just unstuck them on things you don&#x27;t expect them to figure out in the interview.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Hints that direct people to solutions are good, and should be only lightly penalised
&lt;ul&gt;
&lt;li&gt;If a solution is hinted, and they can quickly understand the proposed solution and explain the benefits and tradeoffs, that‚Äôs nearly as good. Ideation is really hard in an interview setting, and many of the best systems solutions come passively from prolonged experience with problem.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hints that identify problems for the candidate should usually be penalised
&lt;ul&gt;
&lt;li&gt;Not identifying a problem is evidence of blind-spots or poor reasoning skills. Sometimes they lack information to be certain it‚Äôs a problem, but it‚Äôs often the case that they should be at least capable of exploring whether it‚Äôs a problem.&lt;&#x2F;li&gt;
&lt;li&gt;Exceptions for things like small edge cases that they immediately understand.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hints that add necessary information for the candidate should not be penalised
&lt;ul&gt;
&lt;li&gt;Sometimes the candidate will explore down a solution path, and be missing some information needed to help them formulate a final solution. This can be revealing constants or letting them know about the existence of a feature.&lt;&#x2F;li&gt;
&lt;li&gt;Need to be a little careful with this, because if they lack too much knowledge it may make more sense to direct them down a different solution path&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hints should be penalised if poorly acted on
&lt;ul&gt;
&lt;li&gt;anything from not acknowledging the hint to failing to infer the correct updates from it.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;problem-specification&quot;&gt;problem specification&lt;&#x2F;h3&gt;
&lt;p&gt;The list of properties a good system design question should have is uninteresting. Should be a realistic problem that gives space for candidates to explore the complexities of system design and apply their various experiences. Not too open-ended such that the field of answering is too large and not too closed such that the solution is too narrow. Shouldn‚Äôt be about link shortening.&lt;&#x2F;p&gt;
&lt;p&gt;It actually turned out to be that coming up with the premise for a good question wasn&#x27;t that hard, but specifying it well kind of was. Here are the things I would recommend for that:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Keep a list of possible solution paths
&lt;ul&gt;
&lt;li&gt;It‚Äôs really important for interviewers to be very familiar with the problem. It&#x27;s good for preparing interviewers and helps calibrate. Calibrating by comparing against past evaluations is more effective when the past evaluation is closer to the one at hand&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Keep a list of questions that the candidate might ask
&lt;ul&gt;
&lt;li&gt;This is also a list of questions that candidates &lt;em&gt;should&lt;&#x2F;em&gt; ask&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Keep a list of possible constants &#x2F; specifications the candidate may ask for &#x2F; need
&lt;ul&gt;
&lt;li&gt;this is common for doing some napkin math.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Prepare a clear list of goals to optimise for&lt;&#x2F;li&gt;
&lt;li&gt;Problem spec should include a use case example
&lt;ul&gt;
&lt;li&gt;This is really helpful for the candidate to use as reference when explaining solutions. Not to say that candidate shouldn‚Äôt need to come up with other possible use cases&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Create a rubric of specific skills you‚Äôre trying to capture, with examples specific to the question&lt;&#x2F;li&gt;
&lt;li&gt;Preset notes about common hints to give and questions to ask
&lt;ul&gt;
&lt;li&gt;this is useful for calibration, consistency and for interviewer education&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The specs I maintained grew quickly as I conducted the question for the first few times, it&#x27;s probably not necessary to have the whole document the first time, especially as some are more important for scaling number of interviewers.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Before interviewing for my current job I had actually problem set more system design interviews than I had taken (which is also the time where I developed this thinking, doing more interviews didn&#x27;t give me any new ideas). Not really sure how correct this thinking is but it&#x27;s at least the product of a lot of first principles thinking and iteration so hopefully insightful!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Street Fighting Etiquette</title>
		<published>2022-07-27T00:00:00+00:00</published>
		<updated>2022-07-27T00:00:00+00:00</updated>
		<link href="https://kipp.ly/street-fighting-etiquette/"/>
		<link rel="alternate" href="https://kipp.ly/street-fighting-etiquette/" type="text/html"/>
		<id>https://kipp.ly/street-fighting-etiquette/</id>
		<content type="html">&lt;p&gt;I‚Äôve found many parallels between cinematic street fights (not like people getting robbed, more like mobsters with complex relationships ducking out to the alley) and engaging in sensitive and&#x2F;or extended arguments with people. Following the etiquette prevents things from going sideways!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;circle-your-opponent-to-obtain-consent&quot;&gt;Circle your opponent to obtain consent&lt;&#x2F;h4&gt;
&lt;p&gt;No good street fight starts with a surprise attack. Express your intent to fight, circle each other a bit to give the other person a chance to walk away. Are their fists up or are their hands up? This is your first demonstration of respect for the other! It sets the tone and prepares for escalation.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;communicate-the-purpose-of-the-fight&quot;&gt;Communicate the purpose of the fight&lt;&#x2F;h4&gt;
&lt;p&gt;People often start a street fight with phrases like ‚Äúlet‚Äôs settle this once and for all‚Äù, and if it‚Äôs responded to with ‚Äúthat‚Äôs what I want too‚Äù, it‚Äôs relevant for understanding the dynamics! Sometimes it doesn‚Äôt have to be explicit, like if an instigator is obviously angry their goal is probably some kind of catharsis.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;no-kicking-when-they-re-down&quot;&gt;No kicking when they‚Äôre down&lt;&#x2F;h4&gt;
&lt;p&gt;Bullying people after defeat is apparent is often counterproductive, and may cause them to feel resentment and ruin the goal of the street fight. Obviously bad etiquette.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;don-t-bring-a-gun-to-a-knife-fight&quot;&gt;Don&#x27;t bring a gun to a knife fight&lt;&#x2F;h4&gt;
&lt;p&gt;In social situations, it can be bad mannered to end a conversation early by squashing the premise or some core idea. Fight with your left hand if you need to (perhaps it‚Äôs always good practice to steelmanning), it shows respect and is better for achieving cathartic street fights.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;take-breaks-with-active-communication&quot;&gt;Take breaks with active communication&lt;&#x2F;h4&gt;
&lt;p&gt;Perhaps the best part of a street fight is when you‚Äôre both a little tired and need a second to catch your breath. It‚Äôs ok to take these! It‚Äôs also a great chance to do some meta communication, like ‚Äúyou put up a better fight than I expected‚Äù, ‚ÄúI can‚Äôt believe you‚Äôd stoop to biting‚Äù or ‚Äúready to go again?‚Äù.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;escalate-at-a-reasonable-pace&quot;&gt;Escalate at a reasonable pace&lt;&#x2F;h4&gt;
&lt;p&gt;Don‚Äôt suddenly launch an entire different style of attack or start going harder. Escalate at a reasonable pace that can be silently agreed upon. Post-breaks are a good time to escalate.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;it-s-honourable-to-help-the-other-person-up&quot;&gt;It‚Äôs honourable to help the other person up&lt;&#x2F;h4&gt;
&lt;p&gt;This is not really etiquette, but it&#x27;s nice! It‚Äôs important to know that accepting a hand does not necessarily mean that the fight is over, and that offering a hand should not be out of condescendance.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;express-your-updated-sentiment-upon-completion&quot;&gt;Express your updated sentiment upon completion&lt;&#x2F;h4&gt;
&lt;p&gt;Whatever the purpose of the fight was, it‚Äôs good to communicate before leaving. Like, ‚Äúwe‚Äôre not done here‚Äù, ‚ÄúI hope you‚Äôve learned your lesson‚Äù, ‚Äúok fine [you win]‚Äù, or even a simple ‚ÄúI‚Äôm glad we did that‚Äù. It‚Äôs a good time to appreciate that maybe some catharsis was achieved even if your specific goal was not met. Leaving a fight with more respect for your opponent is always a win!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;avoid-rehashing&quot;&gt;Avoid rehashing&lt;&#x2F;h4&gt;
&lt;p&gt;Street fights in spirit are ephemeral and spontaneous. Unless something was communicated to imply otherwise, it‚Äôs also bad etiquette to try to rematch or air out the problem again. It‚Äôs certainly ok to ask though!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Job Search Love Letters</title>
		<published>2022-07-03T00:00:00+00:00</published>
		<updated>2022-07-03T00:00:00+00:00</updated>
		<link href="https://kipp.ly/job-search-love-letters/"/>
		<link rel="alternate" href="https://kipp.ly/job-search-love-letters/" type="text/html"/>
		<id>https://kipp.ly/job-search-love-letters/</id>
		<content type="html">&lt;p&gt;I recently had the incredible privilege and experience of interviewing at five places, all of which I&#x27;d be very happy to go to. Even more than the details of interview processes, the ins and outs of considerations, emotional whims and impactful conversations are rarely documented. I write this as love letters to these companies and to eternalise this experience for myself, complete with dramatic Bad Apple lyrics.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;blue-rose-research&quot;&gt;Blue Rose Research&lt;&#x2F;h3&gt;
&lt;p&gt;Comparing the efficacy of two good deeds is often executed poorly, and is always deeply uncomfortable. I had the difficult experience of comparing working on getting Democrats elected and working on AI Alignment. I never really reached a conclusion, but at least for me the positive impact I could make in either endeavour was a close call. Blue Rose is a group that &amp;quot;helps campaigns make higher quality strategic decisions by democratizing access to accurate measurement&amp;quot; and talking to them made that feel like a drastic understatement. I&#x27;m quite confident that working at Blue Rose is a great way to make a positive impact and that they have a really stellar engineering team.&lt;&#x2F;p&gt;
&lt;p&gt;My relationship with Blue Rose started in the summer of 2021 when I tagged along to a party (at what I later learned was at the apartment of &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;davidshor&quot;&gt;David Shor&lt;&#x2F;a&gt;) last minute and somehow found the only two other machine learning people there (I was wearing a shirt that said frontend developer on the front, and backend developer on the back). They were both Blue Rose engineers and I left deciding that they were extremely smart, dedicated (they could all be making oodles more money elsewhere, though Blue Rose pays very well) and it was a shame they were not on my radar before. I&#x27;m genuinely not inspired often, but the combination of dedication and whatever the opposite of learned helplessness is that they demonstrated did that for me.&lt;&#x2F;p&gt;
&lt;p&gt;They also had one of the better interview questions I had come across, where the format was being given a small project written with various bugs &#x2F; code quality flaws and being asked to investigate and fix various parts of it -- this was pretty neat!&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s surely not uncommon for people to consider jobs based on morality, but this was at least my first time thinking about it. What was difficult for me is that what I cared about most was not the same as what I emotionally respond to. Building impactful products is a thrill! Doing AI research doesn&#x27;t have the same kick. Politics certainly has that kick. I believe in doing what I think is most important, which pointed to staying in AI work but it was hard for me to tell if that was really the case or if I was just picking money and status.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m still a little bothered in this decision, but the least I can do is suggest you to &lt;a href=&quot;https:&#x2F;&#x2F;boards.greenhouse.io&#x2F;blueroseresearch&quot;&gt;apply&lt;&#x2F;a&gt; and do what I couldn&#x27;t.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;openai&quot;&gt;OpenAI&lt;&#x2F;h3&gt;
&lt;p&gt;I nearly did not apply to OpenAI out of loyalty to Cohere. As a direct competitor this seemed like a significant betrayal, not just to the team I&#x27;d leave behind but also to myself. OpenAI did a lot for me in terms of getting me to stop mulling over &amp;quot;why am I leaving&amp;quot; and translating that into a much more productive &amp;quot;what am I looking for?&amp;quot;. Some of it was just the situation (they were one of the earlier interviews) but it was also the talking to the people there. The part that activated this switch was that they didn&#x27;t pigeonhole me into a role, rather we explored roles together as if I was capable of anything (given time) which also speaks strongly to the culture.&lt;&#x2F;p&gt;
&lt;p&gt;In my intro call with Rob (recruiter) he asked what I want to work on and I half-jokingly said &amp;quot;haha not sure, wanna help me figure it out?&amp;quot; and Rob proceeded to pick a team for me that I would later come to believe was the most exciting team at OpenAI to me. My interviews included talking with Jerry Tworek, whose team I was angling to join, and Jerry performed best in my manager screening criteria of &amp;quot;would I be comfortable crying in front of them&amp;quot; (I had other criteria too, btw). OpenAI came off as a place with an intense nerdiness about shipping things (nerdiness oft detracts from shipping things because technically-interesting will veer away from productive and vice versa) which I particularly liked and think is quite rare.&lt;&#x2F;p&gt;
&lt;p&gt;I think Rob (and probably other OAI recruiters) are possibly just magnitudes better than others I&#x27;ve seen in terms of being able to understand all the context, people&#x27;s values and have productive conversations with them. It&#x27;s hard to describe how good (both enjoyable and effective) the recruiting was here without going through all the details, but it was phenomenal. Of course, OpenAI is also an exceptional company in terms of the caliber of people to work with, impact, technical interestingness and resources but I knew that going in. It was the recruiting process that impressed me. In fact a few months later a friend was telling me that they were really impressed with OpenAI recruiting.&lt;&#x2F;p&gt;
&lt;p&gt;It turned out that OpenAI was not the best fit for what I was looking for, which is misrepresentative to say because it was also a fantastic fit. I‚Äôm generally grateful for the process. I think it&#x27;s good evidence that interviewing with companies you don&#x27;t end up working at can be productive for one&#x27;s job search.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;can you tell me who you are? can you tell me where i am?&lt;&#x2F;br&gt;
i&#x27;ve forgotten how to see, i&#x27;ve forgotten if i can&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;adept-ai&quot;&gt;Adept AI&lt;&#x2F;h3&gt;
&lt;p&gt;It&#x27;s a little obscene how much I came to love &lt;a href=&quot;https:&#x2F;&#x2F;www.adept.ai&#x2F;&quot;&gt;this company&lt;&#x2F;a&gt;, quite tangibly the recruiting equivalent of limerence.&lt;&#x2F;p&gt;
&lt;p&gt;What made it magical was that when I had just taken a call to get to know them in January my takeaway was something like &amp;quot;very competent team, but nothing to show for it yet and lacking direction&amp;quot; and seeing where they ended up just months later caused too much of an adrenaline rush for something I had nothing to do with. The most compelling part about Adept to me was that early-stage startup adrenaline, having an intense and unique direction and emotionally registering to me as a chance to be a part of something like Cohere again.&lt;&#x2F;p&gt;
&lt;p&gt;The team communicated their culture exceptionally, it was really a show don&#x27;t sell situation. I somewhat hesitantly asked if they&#x27;d be interested in interviewing in person and was thrilled when they said yes (I&#x27;m a big remote work hater) and walked into the office to be greeted by three beautiful dogs all excited to love me! I had lunch at their office before the four hours of interviewing and the team (incl. dogs) did a great job of having relaxed vibe-y time with me. In between interviews I rested on a couch, surrounded by dogs and ate some mango. I petted a dog during an interview too! The culture shone through in that this was the only set of interviews where I felt perfectly safe butting heads with the leadership. It was evidence of good communication norms, culture etc. but also way more respect for me than I expected. From the outside Adept was a perfect earlier version of Cohere where I could build the future with my friends.&lt;&#x2F;p&gt;
&lt;p&gt;Adept is going to be in my mind a lot partially because it was a really close call. Maybe if OpenAI hadn&#x27;t shifted my mindset from thinking about what I wanted about Cohere to be different to thinking about what I want from scratch Adept would&#x27;ve been exactly what I wanted. Maybe a little less EA influence in my life, maybe if they had set up their home base in New York City. Maybe if I were more ambitious or adventurous.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;persimmon.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I got them these stickers (they were almost called Persimmon AI Labs) and showed up at the office to gift it to them as a surprise but ended up chickening out and dropped them off in the lobby. I&#x27;m still not quite sure what I was worried about, I&#x27;m not a particularly nervous person. Probably some combination of social awkwardness, possible regret, and just high stress of interacting with situations related to life decisions. Oh well!&lt;&#x2F;p&gt;
&lt;p&gt;This is a place for my feelings, but I also happen to have thought and investigated pretty hard about whether they will be very successful + a great place to work, and the answer is approximately yes. You should &lt;a href=&quot;https:&#x2F;&#x2F;jobs.lever.co&#x2F;adeptailabs&quot;&gt;apply&lt;&#x2F;a&gt;, I&#x27;ll be jealous if you go.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;to tell me who i am, who i was&lt;&#x2F;br&gt;
uncertainty enveloping my mind&lt;&#x2F;br&gt;&lt;&#x2F;br&gt;
maybe it&#x27;s a dream, maybe nothing else is real&lt;&#x2F;br&gt;
but it wouldn&#x27;t mean a thing if i told you how i feel&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;jane-street&quot;&gt;Jane Street&lt;&#x2F;h3&gt;
&lt;p&gt;I was unconfident if I wanted to stay in ML. It was for bad reasons, like I thought maybe I wasn&#x27;t good enough at machine learning (or rather that what I was doing wasn&#x27;t machine learning at all as I do entirely engineering) or that the stakes in ML were too high for me to handle. I was confident these were bad feelings, and they weren&#x27;t prominent but I still felt the need to explore them. When I applied, a part of me really wanted to go, not just for the leaving-ML reasons but also because I love Jane Street.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m &lt;em&gt;very&lt;&#x2F;em&gt; picky about where I&#x27;m willing to work, in that I refuse to work anywhere that I&#x27;m not very familiar with. I&#x27;ve partied and become friends with the Blue Rose people and leadership, the OAI team I angled for had a friend I&#x27;d known for over half a decade. There are also other standards like having fun problems and good people which of course Jane Street meets.&lt;&#x2F;p&gt;
&lt;p&gt;My history with Jane Street started when I was in high school and stranded in Waterloo because of a snow storm. A then-former Jane Street intern now-fulltimer fed me, called my mom and made sure I made it home. Several of my friends from high school and previous internships went on to work at Jane Street, including a few of my former partners and best friends. It sounds a little bit capitalist dystopia, but my many years of having many friends there and living in the unmistakable and beloved Jane Street culture resulted in me forming a very sentimental relationship with this proprietary trading firm.&lt;&#x2F;p&gt;
&lt;p&gt;Jane Street represented moving back to New York City to me. I moved to San Francisco in January with my former partner because he was leaving Jane Street for a job in SF, and I probably prefer to live in NYC. It made this job feel like going home to live the dreamy life I was starting to build and all the sentimentality I had left behind. I had only been in NYC for half a year! This is a jpg of me visiting the office for the first time in 2018, which was also the first time I visited and fell in love with NYC.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;janestreet.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The two things I&#x27;d really like to communicate is 1. that the culture is wonderful. People really enjoy working there, it&#x27;s not a big scary evil bank that&#x27;s going to drain your soul and hours while providing no fun (I think they have an immense amount of fun!). A few words I&#x27;d pick to describe the culture are playful, delightfully nerdy and genuine. Secondly, they had hands-down &lt;em&gt;the best&lt;&#x2F;em&gt; technical interviews.&lt;&#x2F;p&gt;
&lt;p&gt;They were better than I thought possible and impressively staffed at two people per interview. I went through five fantastic interview problems, not algorithmic or LeetCode like in nature and very representative of possible work people might do. They opened room for collaboration, and tested skills of problem solving, thinking about edge cases and implementation. I believe most &amp;quot;interview with real-world problems&amp;quot; questions are better than algorithmic ones, but are genuinely much harder to design but Jane Street really nailed it. &lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m a little sad I didn&#x27;t finally get my chance to learn functional programming. Uh, sometime after the AGI I guess.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;if i opened up my eyes, &lt;&#x2F;br&gt;
there&#x27;d be no more going back&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;cohere&quot;&gt;Cohere&lt;&#x2F;h3&gt;
&lt;blockquote&gt;
&lt;p&gt;am i hurting am i sad? should i stay, or should i go?&lt;&#x2F;br&gt;
ive forgotten how to tell. did i ever even know?&lt;&#x2F;br&gt;
can i take another step? i&#x27;ve done everything i can&lt;&#x2F;br&gt;
all the people that i see, they will never understand&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;anthropic&quot;&gt;Anthropic&lt;&#x2F;h3&gt;
&lt;p&gt;There&#x27;s some narrative that&#x27;s only a little true where I was always supposed to go to &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;&quot;&gt;Anthropic&lt;&#x2F;a&gt;, that it was inevitable and the right choice for me from the get-go. Like I said there were some close calls even though I&#x27;m really confident about it now. Here are the two things that won me over with Anthropic:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;I believe that AGI is the most important problem of our time, both because it could be so bad and because we could make it so good. My actual beliefs are a lot more specific than this, and Anthropic (as well as its structural incentives) aligned most. This is captured in really donation matching, investors with shared values, the existing and incoming work and the beliefs of the team there.&lt;&#x2F;li&gt;
&lt;li&gt;I&#x27;ve come to know lots of people at Anthropic and they&#x27;re all really nice and lovely! It&#x27;s really comforting and provides lots of positive signal about what working at the company will be like. I didn&#x27;t interview at some relevant and at least technically impressive AI companies because of this.&lt;&#x2F;li&gt;
&lt;li&gt;Kind of 1. again, but I believe Anthropic to be really focused on doing good for the world in a way that I think will be effective (and also probably effective at making me a better person in various ways).&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;The first time I heard of Anthropic I felt very detached from the AI Alignment scene, which was weird because I had been an EA for years and at that point had been working in AI for a while. I applied in fall of 2021 and got rejected. The things I discussed about alignment back then are very different from my thoughts now, which are also a little different from the ideas I had before I started this interview process. That&#x27;s nice, because this does genuinely seem like a &amp;quot;not a good fit at the time&amp;quot; situation. It&#x27;s very likely I wouldn&#x27;t have interviewed again if they hadn&#x27;t so sweetly reached out and asked me to. I think their &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;#careers&quot;&gt;hiring ethos&lt;&#x2F;a&gt; is quite good.&lt;&#x2F;p&gt;
&lt;p&gt;My greatest hesitancy about Anthropic was about just not thinking about alignment the way I currently do. Not so much &amp;quot;is alignment important&amp;quot; and &amp;quot;is working at Anthropic one of the best things I can do for alignment&amp;quot; but more &amp;quot;why do I have to be a good person&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Worrying about alignment and related EA things is hard? It means I can&#x27;t be as financially rich as I secretly want to be, it&#x27;s a little alienating and I often worry I have to deal with anxiety about being an insufficiently good person. My career choice here was a defining moment in how I practice morality in my life. All these other places are also doing great things for the world, some of them very competitively good, how was I to choose? I&#x27;m quite lucky in that this decision was choosing between several wonderful things, compared to other moral crosswords which usually involve notably bad options.&lt;&#x2F;p&gt;
&lt;p&gt;Those questions are mostly unanswered. I can&#x27;t be fully confident that my ideas about what&#x27;s good are correct, and it&#x27;s much harder to decide how to act on them especially when the ideas are so utilitarianly charged and I, as a human, am not. Some of the decisioning came to maintaining my character -- I&#x27;d be pretty disappointed in myself if I gave up on something I love so much (and has done so much good for me) because it was hard.&lt;&#x2F;p&gt;
&lt;p&gt;I am excited to show up for my first day and be shown up in various and many ways, and of course excited for the growth that&#x27;ll provide. The end of my recruiting journey doesn&#x27;t end until I find my place and feel at home at Anthropic, and I can only expect that to be as lovely a process as the rest of it has been. If Anthropic resonates with you as a place to work, &lt;a href=&quot;https:&#x2F;&#x2F;www.anthropic.com&#x2F;#job-postings&quot;&gt;here&lt;&#x2F;a&gt; is where you apply.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;if i find a way to change, if i step into the light&lt;&#x2F;br&gt;
then i&#x27;ll never be the same, and it all will fade to white&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Happy to chat about how to think about job searches, big life decisions and being emotionally attached to your place of work. Also to pitch you on Blue Rose and Anthropic!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | May&#x2F;June 2022</title>
		<published>2022-07-02T00:00:00+00:00</published>
		<updated>2022-07-02T00:00:00+00:00</updated>
		<link href="https://kipp.ly/may-2022/"/>
		<link rel="alternate" href="https://kipp.ly/may-2022/" type="text/html"/>
		<id>https://kipp.ly/may-2022/</id>
		<content type="html">&lt;p&gt;Please stop stepping on my acronyms, &lt;a href=&quot;https:&#x2F;&#x2F;ai.facebook.com&#x2F;blog&#x2F;democratizing-access-to-large-scale-language-models-with-opt-175b&#x2F;&quot;&gt;OPT&lt;&#x2F;a&gt; is a visa not a language model. &lt;a href=&quot;https:&#x2F;&#x2F;www.deepmind.com&#x2F;publications&#x2F;a-generalist-agent&quot;&gt;Gato&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2022&#x2F;in-context-learning-and-induction-heads&#x2F;index.html&quot;&gt;I&#x27;m&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;www.deepmind.com&#x2F;publications&#x2F;improving-language-models-by-retrieving-from-trillions-of-tokens&quot;&gt;behind&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2021&#x2F;framework&#x2F;index.html&quot;&gt;on&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15556&quot;&gt;papers&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;Blog&#x2F;tackling-multiple-tasks-with-a-single-visual-language-model&#x2F;flamingo.pdf&quot;&gt;Like&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2012.14913.pdf&quot;&gt;really&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;vpt&#x2F;&quot;&gt;behind&lt;&#x2F;a&gt;.  Good stats work on &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;measuring-goodharts-law&#x2F;&quot;&gt;best-of-n sampling&lt;&#x2F;a&gt; from OpenAI, not really about Goodhart&#x27;s law. AIs doing things that &lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;critiques&#x2F;&quot;&gt;help&lt;&#x2F;a&gt;! &lt;a href=&quot;http:&#x2F;&#x2F;karpathy.github.io&#x2F;2015&#x2F;11&#x2F;14&#x2F;ai&#x2F;&quot;&gt;Fanfiction&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;It feels a little strange that I work on AI but we &lt;a href=&quot;https:&#x2F;&#x2F;lea.verou.me&#x2F;2020&#x2F;04&#x2F;lch-colors-in-css-what-why-and-how&#x2F;&quot;&gt;can&#x27;t even do colours right&lt;&#x2F;a&gt;. &lt;a href=&quot;http:&#x2F;&#x2F;thbecker.net&#x2F;articles&#x2F;rvalue_references&#x2F;section_01.html&quot;&gt;This&lt;&#x2F;a&gt; is my life now. &lt;a href=&quot;https:&#x2F;&#x2F;www.inkandswitch.com&#x2F;peritext&#x2F;#&quot;&gt;Conflict free replicated data types&lt;&#x2F;a&gt; should be called cfrdts. &lt;a href=&quot;https:&#x2F;&#x2F;facebook.github.io&#x2F;zstd&#x2F;#small-data&#x2F;&quot;&gt;Zstandard&lt;&#x2F;a&gt; is better zipping (particlarly high decompression speed) and offers speed&#x2F;compression tradeoffs. Obviously better options for old tech, zstandard is this for compression, ripgrep for grepping, and &lt;a href=&quot;https:&#x2F;&#x2F;www.blake2.net&#x2F;&quot;&gt;BLAKE2&lt;&#x2F;a&gt; for hashing. It took &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eigenvalues_and_eigenvectors&quot;&gt;a&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;www.mathsisfun.com&#x2F;algebra&#x2F;eigenvalue.html&quot;&gt;few&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;math.libretexts.org&#x2F;Bookshelves&#x2F;Linear_Algebra&#x2F;A_First_Course_in_Linear_Algebra_%28Kuttler%29&#x2F;07%3A_Spectral_Theory&#x2F;7.01%3A_Eigenvalues_and_Eigenvectors_of_a_Matrix#:~:text=Definition%207.1.,-2%3AMultiplicity%20of&amp;amp;text=For%20example%2C%20suppose%20the%20characteristic,of%20multiplicity%20equal%20to%202.&quot;&gt;tries&lt;&#x2F;a&gt; but I learned about eigenvalues. &lt;a href=&quot;http:&#x2F;&#x2F;prize.hutter1.net&#x2F;&quot;&gt;Wikipedia&lt;&#x2F;a&gt; compression contest! &lt;a href=&quot;https:&#x2F;&#x2F;justine.lol&#x2F;ape.html&quot;&gt;Cosmopolitan&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Excellent format for &lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;critiques-ea&quot;&gt;EA critique critique&lt;&#x2F;a&gt;. Excellent &lt;a href=&quot;https:&#x2F;&#x2F;michaelnotebook.com&#x2F;eanotes&#x2F;&quot;&gt;EA critique&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;reboothq.substack.com&#x2F;p&#x2F;ineffective-altruism?s=r&quot;&gt;EA critique&lt;&#x2F;a&gt; that&#x27;s too Gen Z. Investigating &lt;a href=&quot;https:&#x2F;&#x2F;80000hours.org&#x2F;problem-profiles&#x2F;climate-change&#x2F;&quot;&gt;Climate Change&lt;&#x2F;a&gt;, see also, &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;ardenlkoehler&#x2F;status&#x2F;1526992382889283585&quot;&gt;Tweet Thread&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bbc.com&#x2F;future&#x2F;article&#x2F;20220615-do-we-need-a-better-understanding-of-progress&quot;&gt;Lovely!!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;mirror.xyz&#x2F;herndondryhurst.eth&#x2F;eZG6mucl9fqU897XvJs0vUUMnm5OITpSWN8S-6KWamY&quot;&gt;Memes are embeddings&lt;&#x2F;a&gt;. Lim-lim-&lt;a href=&quot;https:&#x2F;&#x2F;ava.substack.com&#x2F;p&#x2F;the-agony-of-eros-on-limerence?s=r&quot;&gt;limerence&lt;&#x2F;a&gt;, my fave. Being &lt;a href=&quot;https:&#x2F;&#x2F;ava.substack.com&#x2F;p&#x2F;how-to-avoid-half-heartedness?s=r&quot;&gt;half-hearted&lt;&#x2F;a&gt; seems hard, my crushes will receive maximum affection. &lt;a href=&quot;https:&#x2F;&#x2F;chrislakin.substack.com&#x2F;p&#x2F;thoughts-on-and-conjectures-about&quot;&gt;Creepiness&lt;&#x2F;a&gt; as the feeling when you are playing an infinite game but someone else is treating it as a finite game.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hans_Reiser&quot;&gt;Known for	ReiserFS, murder&lt;&#x2F;a&gt;. Psychedelic &lt;a href=&quot;https:&#x2F;&#x2F;invisible.college&#x2F;project&#x2F;psiloscoby&quot;&gt;kombucha&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-05-02&#x2F;twitter-s-board-gave-up&quot;&gt;sick of hearing about Twitter&lt;&#x2F;a&gt; tbh. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-06-16&#x2F;private-markets-will-pump-the-oil&quot;&gt;Private Markets Will Pump The Oil&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Apr 2022</title>
		<published>2022-04-30T00:00:00+00:00</published>
		<updated>2022-04-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/april-2022/"/>
		<link rel="alternate" href="https://kipp.ly/april-2022/" type="text/html"/>
		<id>https://kipp.ly/april-2022/</id>
		<content type="html">&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.nelhage.com&#x2F;post&#x2F;transformers-for-software-engineers&#x2F;&quot;&gt;Transformers for Software Engineers&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;blog.eleuther.ai&#x2F;year-one&#x2F;&quot;&gt;A guilty pleasure&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;software-mise-en-place&#x2F;&quot;&gt;Software Mise en place&lt;&#x2F;a&gt;. A &lt;a href=&quot;https:&#x2F;&#x2F;labs.f-secure.com&#x2F;blog&#x2F;faking-another-positive-covid-test&#x2F;&quot;&gt;hacked Cue Reader&lt;&#x2F;a&gt;, featuring some of the most cursed Java code I&#x27;ve seen in a while. Haha, yes, &lt;a href=&quot;https:&#x2F;&#x2F;webcolorisstillbroken.com&#x2F;&quot;&gt;the colours are wrong&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.02311.pdf&quot;&gt;Pathways&lt;&#x2F;a&gt;, A Language Model. &lt;a href=&quot;https:&#x2F;&#x2F;fasterthanli.me&#x2F;articles&#x2F;lies-we-tell-ourselves-to-keep-using-golang&quot;&gt;The lies we tell ourselves to keep using Golang&lt;&#x2F;a&gt;, but I don&#x27;t think &amp;quot;Its attractive async runtime and GC make up for everything else&amp;quot; is a lie, and then a &lt;a href=&quot;https:&#x2F;&#x2F;fasterthanli.me&#x2F;articles&#x2F;i-won-free-load-testing&quot;&gt;ddos&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;d like to be level 0 on &lt;a href=&quot;https:&#x2F;&#x2F;azatris.github.io&#x2F;levels&quot;&gt;Kegan&#x27;s Levels&lt;&#x2F;a&gt;, alas. &lt;a href=&quot;https:&#x2F;&#x2F;thorconpower.com&#x2F;&quot;&gt;Molten Salt Fission Reactors&lt;&#x2F;a&gt;. DK is &lt;a href=&quot;https:&#x2F;&#x2F;andersource.dev&#x2F;2022&#x2F;04&#x2F;19&#x2F;dk-autocorrelation.html&quot;&gt;fake&lt;&#x2F;a&gt;? Look it&#x27;s all a &lt;a href=&quot;https:&#x2F;&#x2F;software.rajivprab.com&#x2F;2020&#x2F;08&#x2F;18&#x2F;if-founders-treated-their-investors-the-same-way-they-treated-their-employees&#x2F;&quot;&gt;scam&lt;&#x2F;a&gt;. Eric Jang &lt;a href=&quot;https:&#x2F;&#x2F;evjang.com&#x2F;2022&#x2F;04&#x2F;25&#x2F;rome.html&quot;&gt;on his way&lt;&#x2F;a&gt; to Rome. Pessimism is &lt;a href=&quot;https:&#x2F;&#x2F;rootsofprogress.org&#x2F;why-pessimism-sounds-smart&quot;&gt;stupid&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-04&#x2F;elon-musk-bought-some-twitter&quot;&gt;Elon Musk Bought Some Twitter&lt;&#x2F;a&gt; and got bounced from a techno club. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-05&#x2F;elon-musk-got-a-twitter-board-seat&quot;&gt;Elon Musk Got a Twitter Board Seat&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-06&#x2F;elon-musk-is-active-now&quot;&gt;Elon Musk Is Active Now&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-07&#x2F;distressed-debt-deal-makes-people-mad&quot;&gt;Distressed-Debt Deal Makes People Mad&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-11&#x2F;elon-musk-s-work-on-twitter-s-board-is-done&quot;&gt;Elon Musk‚Äôs Work on Twitter‚Äôs Board Is Done&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-12&#x2F;will-elon-musk-buy-more-twitter&quot;&gt;Will Elon Musk Buy More Twitter?&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-15&#x2F;sure-elon-musk-might-buy-twitter&quot;&gt;Sure Elon Musk Might Buy Twitter&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-18&#x2F;twitter-has-a-poison-pill-now&quot;&gt;Twitter Has A Poison Pill Now&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-19&#x2F;the-stability-of-algorithmic-stablecoins&quot;&gt;The Stability of Algorithmic Stablecoins&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-20&#x2F;elon-checks-his-pockets&quot;&gt;Elon Checks His Pockets&lt;&#x2F;a&gt;. Oh Fuck, &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-21&#x2F;elon-got-his-money&quot;&gt;Elon Got His Money&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-25&#x2F;elon-closes-in&quot;&gt;Elon Closes In&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-04-26&#x2F;elon-got-his-deal&quot;&gt;Elon Got His Deal&lt;&#x2F;a&gt;!!!!!!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Mar 2022</title>
		<published>2022-03-31T00:00:00+00:00</published>
		<updated>2022-03-31T00:00:00+00:00</updated>
		<link href="https://kipp.ly/march-2022/"/>
		<link rel="alternate" href="https://kipp.ly/march-2022/" type="text/html"/>
		<id>https://kipp.ly/march-2022/</id>
		<content type="html">&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;cozy-futurism&quot;&gt;Cozy futurism&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;nintil.com&#x2F;science-funding-evidence&quot;&gt;Meta-science&lt;&#x2F;a&gt; feels a lot like EA cause area research. I googled &amp;quot;longtermism&amp;quot; for the first time and the first result was &lt;a href=&quot;https:&#x2F;&#x2F;aeon.co&#x2F;essays&#x2F;why-longtermism-is-the-worlds-most-dangerous-secular-credo&quot;&gt;this hit piece&lt;&#x2F;a&gt;. Aella summarizes &lt;a href=&quot;https:&#x2F;&#x2F;aella.substack.com&#x2F;p&#x2F;the-polyamory-post&quot;&gt;everything about polyamory any rationalist has ever said to me&lt;&#x2F;a&gt;. &amp;quot;Longtermism&amp;quot; was named &lt;a href=&quot;https:&#x2F;&#x2F;forum.effectivealtruism.org&#x2F;posts&#x2F;qZyshHCNkjs3TvSem&#x2F;longtermism&quot;&gt;less than three years ago&lt;&#x2F;a&gt;! Prepare for your startup to pivot, but &lt;a href=&quot;https:&#x2F;&#x2F;mindingourway.com&#x2F;dive-in-2&#x2F;amp&#x2F;&quot;&gt;for your life&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Never debug off-by-one in a &lt;a href=&quot;https:&#x2F;&#x2F;blog.tylerhou.io&#x2F;posts&#x2F;binary-search-with-confidence&#x2F;&quot;&gt;binary search&lt;&#x2F;a&gt; ever again. Old &lt;a href=&quot;https:&#x2F;&#x2F;timdettmers.com&#x2F;2018&#x2F;10&#x2F;17&#x2F;tpus-vs-gpus-for-transformers-bert&#x2F;&quot;&gt;comparison of TPUs vs GPUs&lt;&#x2F;a&gt;. Cranks are dangerously relatable, though &lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;hillelwayne&#x2F;archive&#x2F;that-time-indiana-almost-made-p-32&#x2F;&quot;&gt;one of them tried to let pi = 2&lt;&#x2F;a&gt;. We all &lt;a href=&quot;https:&#x2F;&#x2F;horace.io&#x2F;brrr_intro.html&quot;&gt;live by the same accelerator limitations&lt;&#x2F;a&gt; for deep learning brrrr. Finally read the &lt;a href=&quot;https:&#x2F;&#x2F;www.deepmind.com&#x2F;research&#x2F;publications&#x2F;2022&#x2F;Red-Teaming-Language-Models-with-Language-Models&quot;&gt;DeepMind Red Teaming blogpost&lt;&#x2F;a&gt;. Nvidia&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;performance&#x2F;dl-performance-gpu-background&#x2F;index.html#gpu-arch&quot;&gt;GPU Performance Background&lt;&#x2F;a&gt; doc, also &lt;a href=&quot;https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;performance&#x2F;dl-performance-matrix-multiplication&#x2F;index.html&quot;&gt;this one&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-01&#x2F;nobody-wants-russian-assets&quot;&gt;Nobody Wants Russian Assets&lt;&#x2F;a&gt;, Kenny G plays CoD. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-02&#x2F;russia-s-finances-are-closing-up&quot;&gt;Russia&#x27;s Finances Are Closing Up&lt;&#x2F;a&gt;, tax-free Russian tanks. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-08&#x2F;nickel-is-canceled&quot;&gt;Nickel Is Cancelled&lt;&#x2F;a&gt;, if someone at the SEC is looking to hire an intern to analyse Elon tweets, I&#x27;ll do it. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-09&#x2F;esg-goes-to-war&quot;&gt;ESG Goes To War&lt;&#x2F;a&gt;, &amp;quot;If you are perfectly honest, that will limit your career&amp;quot;. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-14&#x2F;nickel-blowup-made-a-lot-of-trouble&quot;&gt;Nickel Blowup Made a Lot of Trouble&lt;&#x2F;a&gt;, &amp;quot;Yeah, no, you don&#x27;t want to be too correct&amp;quot; is generally good advice. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-15&#x2F;amc-bought-a-gold-mine&quot;&gt;AMC Bought A Goldmine&lt;&#x2F;a&gt;, I&#x27;m waiting for someone to buy tungsten mines. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-17&#x2F;nickel-can-t-find-a-price&quot;&gt;Nickel Can&#x27;t Find A Price&lt;&#x2F;a&gt;, I&#x27;m so glad Matt&#x27;s not doing crypto. &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;articles&#x2F;2022-03-21&#x2F;everyone-wants-to-do-esg-now&quot;&gt;Everyone Wants to do ESG Now&lt;&#x2F;a&gt; except i only read the nickel section.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Breakdown of H100s for Transformer Inferencing</title>
		<published>2022-03-30T00:00:00+00:00</published>
		<updated>2022-03-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/h100-inferencing/"/>
		<link rel="alternate" href="https://kipp.ly/h100-inferencing/" type="text/html"/>
		<id>https://kipp.ly/h100-inferencing/</id>
		<content type="html">&lt;p&gt;This new Nvidia &lt;a href=&quot;https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;h100&#x2F;&quot;&gt;GPU&lt;&#x2F;a&gt; just dropped! This post will analyse what it offers for transformer inferencing.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;specs&quot;&gt;specs&lt;&#x2F;h3&gt;
&lt;p&gt;Here&#x27;s a spec table to start. The &amp;quot;16-bit format&amp;quot; refers to BFLOAT16 and FLOAT16 while &amp;quot;8-bit format&amp;quot; refers to FP8 or INT8. For INT8 they aren&#x27;t actually flops, because the &amp;quot;fl&amp;quot; is for float, but I&#x27;ll continue referring to them as flops because we don&#x27;t care about the difference for this context. Also the A100s only support INT8 and not FP8.&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;th&gt;A100 40GB PCIe&lt;&#x2F;th&gt;&lt;th&gt;A100 80GB PCIe&lt;&#x2F;th&gt;&lt;th&gt;A100 40GB SXM&lt;&#x2F;th&gt;&lt;th&gt;A100 80GB SXM&lt;&#x2F;th&gt;&lt;th&gt;H100 SXM&lt;&#x2F;th&gt;&lt;th&gt;H100 PCIe&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;16-bit format Flops&lt;&#x2F;td&gt;&lt;td&gt;312TF&lt;&#x2F;td&gt;&lt;td&gt;312TF&lt;&#x2F;td&gt;&lt;td&gt;312TF&lt;&#x2F;td&gt;&lt;td&gt;312TF&lt;&#x2F;td&gt;&lt;td&gt;1000TF&lt;&#x2F;td&gt;&lt;td&gt;800TF&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;8-bit format Flops&lt;&#x2F;td&gt;&lt;td&gt;624TF&lt;&#x2F;td&gt;&lt;td&gt;624TF&lt;&#x2F;td&gt;&lt;td&gt;624TF&lt;&#x2F;td&gt;&lt;td&gt;624TF&lt;&#x2F;td&gt;&lt;td&gt;2000TF&lt;&#x2F;td&gt;&lt;td&gt;1600TF&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Capacity&lt;&#x2F;td&gt;&lt;td&gt;40GB&lt;&#x2F;td&gt;&lt;td&gt;80GB&lt;&#x2F;td&gt;&lt;td&gt;40GB&lt;&#x2F;td&gt;&lt;td&gt;80GB&lt;&#x2F;td&gt;&lt;td&gt;80GB&lt;&#x2F;td&gt;&lt;td&gt;80GB&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;GPU Memory Bandwidth&lt;&#x2F;td&gt;&lt;td&gt;1.5TB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;1.9TB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;1.5TB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;2TB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;3TB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;2TB&#x2F;s&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Communication Bandwidth&lt;&#x2F;td&gt;&lt;td&gt;300GB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;300GB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;300GB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;300GB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;450GB&#x2F;s&lt;&#x2F;td&gt;&lt;td&gt;450GB&#x2F;s&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Max Number GPUs With Fast Connections&lt;&#x2F;td&gt;&lt;td&gt;8&lt;&#x2F;td&gt;&lt;td&gt;8&lt;&#x2F;td&gt;&lt;td&gt;16&lt;&#x2F;td&gt;&lt;td&gt;16&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;The communication bandwidths are half of what&#x27;s reported because I like to use the bidirectional number when thinking about model parallel communication cost. I discuss this in &lt;a href=&quot;&#x2F;blog&#x2F;transformer-inference-arithmetic&#x2F;#model-parallelism&quot;&gt;&amp;quot;Transformer Inference Arithmetic&amp;quot;&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;There&#x27;s another relevant spec in here, where &amp;quot;up to 256 H100s can be connected to accelerate exascale workloads&amp;quot;. For A100 PCIe this was up to 8 and 16 for for the SXMs.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-to-get-the-30x&quot;&gt;how to get the 30x&lt;&#x2F;h3&gt;
&lt;p&gt;Nvidia claims 30x higher than A100s for the 530B model (&amp;quot;Up to 30X Higher AI Inference Performance on Largest Models&amp;quot;, &amp;quot;H100 to A100 comparison&amp;quot;). Let&#x27;s see if we can decipher how they get that number, and where the speedups come from (none of the specs change that much!). Deriving estimation equations from &lt;a href=&quot;&#x2F;blog&#x2F;transformer-inference-arithmetic&#x2F;#latency-calculations&quot;&gt;this post&lt;&#x2F;a&gt;, starting with large batch sizes. A large batch size means a number higher than the hardware ratio of flops to memory bandwidth. On the 40GB A100s that&#x27;s 208 and for the H100 SXM (by default, when I say H100 I&#x27;ll mean the SXM) it&#x27;s 333. We care about the large batch size because we will be flop bound instead of memory bound. The comms is thoughput + latency, but we&#x27;ll drop the latency which is small. These equations measure running one token through all the blocks in the model.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{compute} = B \cdot \frac{2 \cdot P}{N \cdot A_f}\\
\text{comms} = B \cdot  \frac{2\cdot n_\text{layers} \cdot 4 \cdot d_\text{model}}{A_c}&lt;&#x2F;script&gt;
&lt;p&gt;We calculate two numbers because we have a sense of compute vs communication bound. Sometimes we might add these numbers together, so for this post we&#x27;ll consider both. There&#x27;s a factor of 2 in comms that will get dropped for 8-bit formats.&lt;&#x2F;p&gt;
&lt;p&gt;The Megatron arch is 105 layers, 20480 embedding dimension. We&#x27;ll start with batch size 512 to get us flop bound.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{16 A100s, 16-bit}\\
\text{compute} = 512 \cdot \frac{2 \cdot 530\text{e}9}{16 \cdot 312\text{e}12} = 109\text{ms}\\
\text{comms} = 512 \cdot \frac{2\cdot 105 \cdot 4 \cdot 20480}{300\text{e}9}= 29\text{ms}\\&lt;&#x2F;script&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{16 H100s, 8-bit}\\
\text{compute} = 512 \cdot \frac{2 \cdot 530\text{e}9}{16 \cdot 2000\text{e}12} = 17\text{ms}\\
\text{comms} = 512 \cdot \frac{105 \cdot 4 \cdot 20480}{450\text{e}9} = 10\text{ms}\\&lt;&#x2F;script&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{32 H100s, 8-bit}\\
\text{compute} = 512 \cdot \frac{2 \cdot 530\text{e}9}{32 \cdot 2000\text{e}12} = 8\text{ms}\\
\text{comms} = 512 \cdot \frac{105 \cdot 4 \cdot 20480}{450\text{e}9} = 10\text{ms}\\&lt;&#x2F;script&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{64 H100s, 8-bit}\\
\text{compute} = 512 \cdot \frac{2 \cdot 530\text{e}9}{64 \cdot 2000\text{e}12} = 4\text{ms}\\
\text{comms} = 512 \cdot \frac{105 \cdot 4 \cdot 20480}{450\text{e}9} = 10\text{ms}\\&lt;&#x2F;script&gt;
&lt;p&gt;Technically nothing stops us from 8-bit on A100s, but F8 is going to be a lot easier to use than &lt;a href=&quot;https:&#x2F;&#x2F;www.mathworks.com&#x2F;company&#x2F;newsletters&#x2F;articles&#x2F;what-is-int8-quantization-and-why-is-it-popular-for-deep-neural-networks.html&quot;&gt;INT8 quantisation&lt;&#x2F;a&gt; so I think it&#x27;s reasonable to include the speedup from that availability. We can&#x27;t use 32 A100s because we don&#x27;t have the hardware to communicate between that many A100s quickly.&lt;&#x2F;p&gt;
&lt;p&gt;To attribute all the speedup: 1.7x from going from 16 to 32 chips if we do overlapped comms and compute. 3x from flops difference. 2x from going to 8-bit. Note that the 2x from going to 8-bit might not be exhausted, as we may not want to 8-bit everything to keep model quality up. Also because maybe the practical bandwidth (compared to the theoretical ones, which is whats in the spec) of the 8-bit is lower than the 16?&lt;&#x2F;p&gt;
&lt;p&gt;And here we get a 11x speedup for overlapped comms|compute and 9x for synchronous comms|compute, so we&#x27;re missing something! Nvidia doesn&#x27;t give that much spec as to how the benchmark was run, other than&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Projected performance subject to change. Inference on Megatron 530B parameter model based chatbot for input sequence length=128, output sequence length =20 | A100 cluster: HDR IB network | H100 cluster: NVLink Switch System, NDR IB&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;I think they&#x27;re also comparing against different batch sizes like they &lt;a href=&quot;https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;hgx&#x2F;&quot;&gt;do here&lt;&#x2F;a&gt; because the maximum batch size also changes.&lt;&#x2F;p&gt;
&lt;p&gt;We need at least 16 A100 GPUs for a 530B model, as the weights in BF16 will take about a terabyte (we need the 16x80=1280). It does mean that we only have 1280-530x2=220GB remaining. For F8 on 32 GPUs, we have 80x32-530=2TB remaining. When we sample from large language models, we &lt;a href=&quot;&#x2F;blog&#x2F;transformer-inference-arithmetic&#x2F;#kv-cache&quot;&gt;store kv&lt;&#x2F;a&gt; per token, and the benchmark has them doing 148 tokens.&lt;&#x2F;p&gt;
&lt;p&gt;For 16-bit, thats 2x2x105x20480x148 = 1.27 GB per request. For 8-bit it&#x27;s half, for 0.64GB per request. What this says is that our 220GB remaining only fits 170 requests, while the 2TB can fit somewhere in the thousands. Then, they&#x27;re probably comparing for the time to complete the same number of requests, but the A100 would have to do it in two batches. Because the 170 is under 208, it also means that our A100 inference is memory bandwidth bound as opposed to flops bound. But it&#x27;s also probably much less than 170! A bunch of weights might be duplicated across GPUs, and software loses some memory (having TF load a 40GB A100, TF thinks there&#x27;s only 38.4GB available). So maybe only 190GB remains and we fit ~150 requests.&lt;&#x2F;p&gt;
&lt;p&gt;For convienence, lets say we&#x27;re doing time to complete 450 requests. I&#x27;ll leave out comms on the 16 A100s and assume compute bound. There&#x27;s no factor of batch in the compute anymore because at memory bound, we only count time for loading weights.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{16 A100s, 16-bit}\\
\text{compute} = \frac{2 \cdot 530\text{e}9}{16 \cdot 1.5\text{e}12} = 44\text{ms}\\&lt;&#x2F;script&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{32 H100s, 8-bit}\\
\text{compute} = 450 \cdot \frac{2 \cdot 530\text{e}9}{32 \cdot 2000\text{e}12} = 7\text{ms}\\
\text{comms} = 450 \cdot \frac{105 \cdot 4 \cdot 20480}{450\text{e}9} = 9\text{ms}\\&lt;&#x2F;script&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\textbf{64 H100s, 8-bit}\\
\text{compute} = 450 \cdot \frac{2 \cdot 530\text{e}9}{32 \cdot 2000\text{e}12} = 7\text{ms}\\
\text{comms} = 450 \cdot \frac{105 \cdot 4 \cdot 20480}{450\text{e}9} = 9\text{ms}\\&lt;&#x2F;script&gt;
&lt;p&gt;Now we get 44x3&#x2F;9 = 14.7x. We&#x27;re still missing 2x, though we got closer than last time (10x). We can bully here a bit -- what if we measure the time for 451 requests? Then we&#x27;d still get 9ms for the 32H100s but then the 16A100s would take 44x4=176ms, giving us a 19.5x difference. It&#x27;s actually also probably higher than 44ms, since the memory boundedness isn&#x27;t absolutely independent of batch size, the intermediate calculations are expected to do a number of round trips through memory. The scale of this in practice is less than 10% slower due to those operations.&lt;&#x2F;p&gt;
&lt;p&gt;Another possible cause of the time difference is that 16 A100s is actually comms bound, and might be way higher than 44ms. The spec says it&#x27;s HDR Infiniband. When I put 16 in the table, it&#x27;s actually only for HGX and not DGX, where these are systems that determine how many GPUs we can link quickly. DGX can only do 8, so maybe Nvidia did that!&lt;&#x2F;p&gt;
&lt;p&gt;Infiniband is &lt;em&gt;at most&lt;&#x2F;em&gt; 600 gigabits per second, or 75 gigabytes per second. That&#x27;s a 12x difference! That would mean that the comms time (which we expect to be 9ms throughput, 2ms latency) would take 11*12=132ms, making the A100 setup very comms bound (but we can&#x27;t do less comms due to capacity). 132x3&#x2F;9 = 44, which is uhh too high. If we use the mean batch numbers, it&#x27;s actually 59x.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Transformer Engine utilizes FP8 and FP16 together to reduce memory usage and increase performance while still maintaining accuracy for large language models.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Some of that might be smaller, because maybe not everything is F8? This is also unspecified. If say 50% of their weights were half precision (or specifically, 50% of their computations were half precision) then that would get us exactly 30x. I mean, it seems Nvidia hasn&#x27;t benchmarked yet, this is all &amp;quot;Projected performance subject to change&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s also possible that Nvidia doesn&#x27;t do tensor parallel because of that massive comms time, rather it would do pipeline parallel, where the layers are split across GPUs (first GPU will have first N layers, last GPU will have last M layers). This way, we can have two hosts with 8 GPUs each, and the expensive comms only has to happen &lt;em&gt;once&lt;&#x2F;em&gt; per model pass, instead of four times per layer.&lt;&#x2F;p&gt;
&lt;p&gt;In this case we might want to do something where we pretend the first 50 layers are &amp;quot;one model&amp;quot;, do that tensor parallel on one host and then do the last 50 layers as &amp;quot;one model&amp;quot; with an extra communication time in the middle. We can predict that this will not be comms bound, it&#x27;ll be the same 11 ms between the fast-connection gpus, and then almost nothing for that jump in the middle (which would be 132&#x2F;(105x4)).&lt;&#x2F;p&gt;
&lt;p&gt;But the compute time here does go up! Just not by twelve times. For a half-model unit, we&#x27;ll have half the bytes but also half the memory bandwidth, so each model would take 44ms. That does &lt;em&gt;somewhat&lt;&#x2F;em&gt; take our times to double, but not quite. For a batch size of 150, it would in fact take double. But to do three of those batches, we&#x27;d only take 4x44ms.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;tp.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For that, when the first batch is processing on the second gpu, then the second batch can start processing on the first gpu, hence the &amp;quot;tensor parallel&amp;quot;. All in all, three batches would take 176ms. 176&#x2F;9=19.5 again (it&#x27;s the same effect we get when we bully with the number of requests we&#x27;re measuring). I&#x27;m not going to calculate it, since it&#x27;ll be a similar order of magnitude, but there&#x27;s also a different speedup associated with doing the compute and comms synchronously (in this case, we could insert 128 H100 GPUs).&lt;&#x2F;p&gt;
&lt;p&gt;The intermediate calculations + kv cache reads that we don&#x27;t factor in are somewhat significant. We don&#x27;t know what the paralellism setup is, or if they factored in the in-practice bandwidth of F8 vs F16, or how much this Transformer Engine uses F8 vs F16 but I think I&#x27;ve at least exhausted all the major mechanisms through which the 30x speedup can be acquired.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h3&gt;
&lt;p&gt;Here is a list of all the speedups that can occur with H100s for large language model inferencing (sometimes applicable to training as well).&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;A100s can only connect up to 16 GPUs with fast communication, while H100s can do up to 256. This means that any model that was not already comms bound at 16 chips can have more chips.&lt;&#x2F;li&gt;
&lt;li&gt;The flops are higher by 3x, so for flops bound operations that&#x27;s 3x&lt;&#x2F;li&gt;
&lt;li&gt;The memory bandwidth is higher by 2x, so for memory bound operations it&#x27;s 2x&lt;&#x2F;li&gt;
&lt;li&gt;Being able to have more chips may be the difference between being memory bound (less chips) and being flops bound (more chips) as there&#x27;s more capacity left over to store kv cache for sampling.&lt;&#x2F;li&gt;
&lt;li&gt;Having F8 enables people to easily use 8-bit precisions, halving the compute whether it&#x27;s memory bound or flops bound.&lt;&#x2F;li&gt;
&lt;li&gt;Some models may be forced to use more than the max 16 chips due to capacity, meaning they&#x27;d be heavily comms bound as host to host comms are extra slow. That slowness would be lifted with the 256 for H100s.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;spin me in weight space &lt;br&gt;
paint me in half precision &lt;br&gt;
we&#x27;re best in chaos&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Transformer Inference Arithmetic</title>
		<published>2022-03-30T00:00:00+00:00</published>
		<updated>2022-03-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/transformer-inference-arithmetic/"/>
		<link rel="alternate" href="https://kipp.ly/transformer-inference-arithmetic/" type="text/html"/>
		<id>https://kipp.ly/transformer-inference-arithmetic/</id>
		<content type="html">&lt;p&gt;This article presents detailed few-principles reasoning about large language model inference performance, with no experiments or difficult math. The amount of understanding that can be acquired this way is really impressive and practical! A very simple model of latency for inference turns out to be a good fit for emprical results. It&#x27;s helped me make better predictions and form better explanations about transformer inference.&lt;&#x2F;p&gt;
&lt;p&gt;This post assumes some prior knowledge about transformers, say at having understood most of &lt;a href=&quot;https:&#x2F;&#x2F;jalammar.github.io&#x2F;illustrated-transformer&#x2F;&quot;&gt;The Illustrated Transformer&lt;&#x2F;a&gt; but not having internalised all of it. Familiarity with this &lt;a href=&quot;&#x2F;blog&#x2F;transformer-param-count&#x2F;&quot;&gt;parameter counting&lt;&#x2F;a&gt; post which I developed along with this one may also be useful.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#kv-cache&quot;&gt;kv cache&lt;&#x2F;a&gt; explains the performance improvement of caching self-attention vectors as a part of inferencing, as well as the possible tradeoffs and capacity costs&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#capacity&quot;&gt;capacity&lt;&#x2F;a&gt; takes the storage cost of kv cache and connects it to the storage cost of model weights and what capacity means for performance.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#model-parallelism&quot;&gt;model parallelism&lt;&#x2F;a&gt; builds up an understanding specifically of tensor parallelism to clearly identify the cost of communication&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#latency-calculations&quot;&gt;latency calculations&lt;&#x2F;a&gt; pulls understanding from other concepts to create equations that serve as floorlines for inference speed.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#batch-sizes&quot;&gt;batch sizes&lt;&#x2F;a&gt; discusses what impact batch size has on performance and what sizes may be optimal.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#flops-counting&quot;&gt;flops counting&lt;&#x2F;a&gt; steps through the transformer blocks and identifies which operations meaningfully contribute to flops speed.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#intermediate-memory-costs&quot;&gt;intermediate memory costs&lt;&#x2F;a&gt; covers how the activations take additional memory and what that memory bandwidth costs looks like from some real benchmarks.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#comparing-against-real-benchmarks&quot;&gt;comparing against real benchmarks&lt;&#x2F;a&gt; compares what we can calculate to what Nvidia FasterTransformer benchmarks report and identifies the discrepancies.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;kv-cache&quot;&gt;kv cache&lt;&#x2F;h3&gt;
&lt;p&gt;For sampling, transformer inference consists of processing a provided prompt&#x2F;context (which can happen in parallel), and then sampling additional tokens one by one (this is where the autoregressiveness surfaces). In the sampling, the transformer performs self-attention, which requires the kv values for each item currently in the sequence (whether it was prompt&#x2F;context or a generated token). These vectors are provided a matrix known as the kv cache, aka past cache (the open source GPT-2 implementation called it &lt;code&gt;past&lt;&#x2F;code&gt;). The past cache would be shaped like &lt;code&gt;[batch, 2, num_heads, seq_len, features]&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;kvdiagram.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The purpose of this is to avoid recalculations of those vectors every time we sample a token. With the computed \(k, v \) values, we can save quite a bit of computation at the cost of some storage. Per token, the number of bytes we store is&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;2\cdot 2 \cdot n_\text{layers} \cdot n_\text{heads} \cdot d_\text{head}&lt;&#x2F;script&gt;
&lt;p&gt;The first factor of 2 is to account for the two vectors, \(k\) and \(v\). We store that per each layer, and each of those values is a \( n_\text{heads}\times d_\text{head}\) matrix. Then multiply by 2 again for the number of bytes (we&#x27;ll assume 16-bit formats throughout the post).&lt;&#x2F;p&gt;
&lt;p&gt;The weights that we multiply by the token embeddings are \(W_\text{k}, W_\text{v} \in \mathbb{R}^{d_\text{model}\times d_\text{model}}\) and then each token embedding is \(t_\text{e}\in \mathbb{R}^{1\times d_\text{model}}\). So then the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;FLOPS&quot;&gt;flops&lt;&#x2F;a&gt; to compute \(k\) and \(v\) for all our layers is&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;2 \cdot 2 \cdot n_\text{layers}  \cdot {d_\text{model}}^2&lt;&#x2F;script&gt;
&lt;p&gt;We multiply \(t_\text{e}\) by \(W_\text{k}\), which takes \(2 \cdot {d_\text{model}}^2\) flops. We have another factor of 2 as we do that twice, once each for \(k\) and \(v\) and then repeat for \(n_\text{layers}\).&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;How many flops in a matmul?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The computation for a matrix-vector multiplication is \(2mn\) for \(A \in \mathbb{R}^{m\times n}, b \in \mathbb{R}^{n}\). A matrix-matrix is \(2mnp\) for \(A \in \mathbb{R}^{m\times n}, B \in \mathbb{R}^{n \times p}\). The \(mn\) factor makes a lot of sense, and the two comes from the fact that a matmuls are composed of multiply(1)-add(2) operations. More in these &lt;a href=&quot;https:&#x2F;&#x2F;www.stat.cmu.edu&#x2F;~ryantibs&#x2F;convexopt-F18&#x2F;scribes&#x2F;Lecture_19.pdf&quot;&gt;lecture notes&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;This means for a 52B parameter model (taking &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.00861.pdf&quot;&gt;Anthropic&#x27;s&lt;&#x2F;a&gt;, where \(d_\text{model} = 8192\) and \(n_\text{layers} = 64\)). The flops are&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;2 \cdot 2 \cdot 64 \cdot 8192^2 = 17,179,869,184&lt;&#x2F;script&gt;
&lt;p&gt;Say we have an &lt;a href=&quot;https:&#x2F;&#x2F;www.nvidia.com&#x2F;content&#x2F;dam&#x2F;en-zz&#x2F;Solutions&#x2F;Data-Center&#x2F;a100&#x2F;pdf&#x2F;nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf&quot;&gt;A100 GPU&lt;&#x2F;a&gt;, which does \(312\text{e}12\) flops per second and \(1.5\text{e}12\) bytes per second of memory bandwidth. The following are numbers for just the kv weights and computations.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{memory} = 2 \cdot 2 \cdot n_\text{layers} \cdot {d_\text{model}}^2 \div 1.5\text{e}12\\
\text{compute} = 2 \cdot 2 \cdot n_\text{layers} \cdot {d_\text{model}}^2 \div 312\text{e}12\\&lt;&#x2F;script&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Flops vs Memory Boundedness&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Flops vs memory boundedness is something we deal with a lot for transformer inference, but &lt;a href=&quot;https:&#x2F;&#x2F;horace.io&#x2F;brrr_intro.html&quot;&gt;also in deep learning optimisation in general&lt;&#x2F;a&gt;. To do the computations we do, we need to load weights which costs &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Memory_bandwidth&quot;&gt;memory bandwidth&lt;&#x2F;a&gt;. We assume (correctly, this has been very well optimised) that we can start the computations while we load the weights. Flop bound would then mean that there is time when nothing is being passed through memory, and memory bound would mean that no floperations are occuring. Nvidia uses the term &lt;a href=&quot;https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;performance&#x2F;dl-performance-gpu-background&#x2F;index.html#gpu-arch&quot;&gt;math bandwidth&lt;&#x2F;a&gt; which I find really cute. Technically, this delineation exist per kernel but can be abstracted to exist for groups of operations.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;None of the model architecture matters anymore ‚Äî we get a distinct ratio here of 208 given this hardware specification. This means that if we&#x27;re going to compute kv for one token, it&#x27;ll take the same amount of time to compute for up to 208 tokens! Anything below, we&#x27;re memory bandwidth bound. Above, flops bound. If we used the rest of our weights to do a full forwards pass (run the rest of the transformer) on our context, it&#x27;s also 208 (both the numerator and denominator get a factor of 6 added). This will be reasoned thoroughly in future sections. The intersection of the below diagram is at 208, though in reality the memory line does have a slight slope due to memory cost of intermediate calculations (discussed in the last section).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;roofline.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a 52B model full forwards pass, that&#x27;s \(12\cdot 2 \cdot n_\text{layers} \cdot {d_\text{model}}^2  &#x2F; 1.5\text{e}12 \approx 69\) milliseconds for up to 208 tokens (in practice, we&#x27;d use four GPUs in parallel so it would actually be ~17 milliseconds, more in following sections). If we had 416 (double) tokens in the context, then it would take twice as long, and 312 tokens would take 1.5 times as long.&lt;&#x2F;p&gt;
&lt;p&gt;Calculating for a kv cache token is exactly 1&#x2F;6th of the compute of passing the token through the model. In general, these forwards passes (what we experience in getting logits, embeddings and training) are very cheap because of the parallelism that is possible as opposed to sampling where we&#x27;re forced to read through all the weights for each token and do the autoregression.&lt;&#x2F;p&gt;
&lt;p&gt;This doesn&#x27;t mean that 1&#x2F;6th of the time is saved! Let&#x27;s assume we are flops bound. Then at each sample step, we save \(2 \cdot 2 \cdot n_\text{tokens} \cdot n_\text{layers} \cdot {d_\text{model}}^2 \div 312\text{e}12\) flops while the decoding steps costs \(2 \cdot 12 \cdot n_\text{layers} \cdot {d_\text{model}}^2 \div 312\text{e}12\). Thus at each step we save 1&#x2F;6 of the flops time multiplied by the number of tokens in our sequence (big!) ‚Äî which increases as we sample tokens. It is the case that without a kv cache, sampling would be quadratic in time complexity as we increase the number of tokens.&lt;&#x2F;p&gt;
&lt;p&gt;This is not the whole story (given overheads and &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;pommedeterre33&#x2F;status&#x2F;1491314217370398725?s=21&quot;&gt;tradeoffs&lt;&#x2F;a&gt; associated with storing this cache). If we&#x27;re serving small batches we may be memory bandwidth bound rather than flops, in which case we won&#x27;t even want to use the past cache and will instead happily do recomputations, spending the flops (we&#x27;ll already be paying the memory cost to do our sampling).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;capacity&quot;&gt;capacity&lt;&#x2F;h3&gt;
&lt;p&gt;We have a solid idea of the two things we store in our GPUs ‚Äî kv cache and weights. GPU capacity does come into play for transformer inferencing performance and we have all the understanding we need to evaluate that now!&lt;&#x2F;p&gt;
&lt;p&gt;Nvidia A100 GPUs (which are generally speaking, the best GPUs we can get for inference) have a standard of 40GB of capacity. There are ones with 80GB and higher memory bandwidth (2e12 instead of 1.5e12) but they aren&#x27;t available with any large &lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220316203021&#x2F;https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;docs&#x2F;gpus&quot;&gt;cloud&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;dlami&#x2F;latest&#x2F;devguide&#x2F;gpu.html&quot;&gt;providers&lt;&#x2F;a&gt; yet which means they aren&#x27;t real to me!&lt;&#x2F;p&gt;
&lt;p&gt;Given the parameter count, we can multiply by two to get bytes. So to calculate the size of the weights for a 52B model.
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;52\text{e}12 \cdot 2 = 104\text{e}12 \text{bytes} \approx 104\text{GB}\\&lt;&#x2F;script&gt;
&lt;&#x2F;p&gt;
&lt;p&gt;Oh no! This doesn&#x27;t fit in one GPU! We&#x27;d need at least three GPUs just to have all the weights loaded in (will discuss how to do that sharding later). That leaves us \(120-104 = 16GB\) left for our kv cache. Is that enough? Back to our equation for kv cache memory per token, again with a 52B model;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;2\cdot n_\text{layers} \cdot n_\text{heads} \cdot d_\text{head}  \cdot 2\\
4\cdot n_\text{layers} \cdot n_\text{heads} \cdot d_\text{head} \\
 = 4\cdot 64 \cdot 8192\\
 = 2,097,152 \text{bytes}
\approx 0.002 GB&lt;&#x2F;script&gt;

And then we&#x27;d do \(16&#x2F;0.002 \approx 8000\) tokens can fit into our kv cache with this GPU set up, or that we could do up to a batch size 4 where each request has up to 2048 tokens (and higher sizes for less tokens).&lt;&#x2F;p&gt;
&lt;p&gt;This sucks because we would like to be able to do higher batch sizes, but are capacity limited! Higher batch sizes are more efficient in terms of how much GPU time it takes to process the same request. On the other hand, at batch sizes this low we&#x27;re bound to be memory bound, and should forego the kv cache and just pay the flops cost instead.&lt;&#x2F;p&gt;
&lt;p&gt;For four GPUs, we&#x27;d get \(56&#x2F;0.002 \approx 23000\). We definitely want to go for the four GPUs since we&#x27;ll want to be able to do higher batch sizes, and it&#x27;s silly to to divide powers of two over three GPUs. But it&#x27;s not just batch size! If we have high volume, then we&#x27;d have multiple instances of our models. We approximately want each instance to be able to do as large as a batch size as possible, as we pay the cost of storing the weights anyway.&lt;&#x2F;p&gt;
&lt;p&gt;There&#x27;s some extra space used by intermediate calculation steps, but they&#x27;re negligible.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;model-parallelism&quot;&gt;model parallelism&lt;&#x2F;h3&gt;
&lt;p&gt;I&#x27;m not going to build up full understanding of model parallelism and all the implementation details, because &lt;a href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;parallelism&quot;&gt;many&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1909.08053.pdf&quot;&gt;have&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;timdettmers.com&#x2F;2014&#x2F;11&#x2F;09&#x2F;model-parallelism-deep-learning&#x2F;&quot;&gt;done&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;www.deepspeed.ai&#x2F;tutorials&#x2F;megatron&#x2F;&quot;&gt;so&lt;&#x2F;a&gt;. But we will build out the parts of the understanding that are useful to figure to make performance decisions and calculate communication costs!&lt;&#x2F;p&gt;
&lt;p&gt;The outcome of model parallelism, is that the cost of passing all the weights through through memory and the flops are all divided over the degree (number of accelerators we use).&lt;&#x2F;p&gt;
&lt;p&gt;We will assume tensor parallel (model parallel) where we will split down the middle of the model. Each accelerator will execute as much as it can with its shards of the weights and will communicate whenever synchronisation is required. A more naive way is pipeline parallel, where each GPU will hold onto a fraction of the layers. This does successfully even out the weight loading cost, but has the obvious silly that all but one GPU will be idling! In training you could pipeline through it (as the first batch moves onto the next GPU, start on a new batch on the first GPU) but it doesn&#x27;t work out for a single sample request (though you could still do it for multiple requests). Pipeline also doesn&#x27;t exhaust the memory bandwidth, which is actually ok if you&#x27;re flops bound anyway. The only place where pipeline parallel does better is communications. A pipeline parallel model would communicate \(d_\text{model}\) per accelerator, while a model parallel does \(N\cdot d_\text{model}\) per layer where \(N\) is the number of accelerators.&lt;&#x2F;p&gt;
&lt;p&gt;Here we introduce the last constant for our &lt;a href=&quot;https:&#x2F;&#x2F;www.nvidia.com&#x2F;content&#x2F;dam&#x2F;en-zz&#x2F;Solutions&#x2F;Data-Center&#x2F;a100&#x2F;pdf&#x2F;a100-80gb-datasheet-update-nvidia-us-1521051-r2-web.pdf&quot;&gt;A100 GPUs&lt;&#x2F;a&gt; which is a communication bandwith of 300GB&#x2F;s. The doc marks it as 600GB&#x2F;s because Nvidia is adding up 300GB&#x2F;s into each chip and 300GB&#x2F;s out simultaneously rather than using a bidirectional number (which will be more intuitive for our calculations).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;mp.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In this diagram, we start by following the yellow brick road where we insert our token embeddings into the bottom of the model. The purple boxes outline how our weights would be split across the accelerators, and we work with an extremely tiny model so we can draw everything to scale. A general idea is that if we have two matrices \(X\) and \(Y\) we can shard both of them and multiply the shards. This doesn&#x27;t actually complete the matmul of \(X\cdot Y\), and an easy way to tell (other than our ability to multiply matrices) is that if we concatenated the result of multiplying the shards, we get too big of a matrix. Instead, we would want to communicate, compute a shard sum, communicate that sum back out and then concatenate for the output of \(X \cdot Y\).&lt;&#x2F;p&gt;
&lt;p&gt;For attention the parallelism is intuitive from the fact that we have multiple heads. We go through most of the attention layer without communication because our attention heads are concatenated to multiply by \(W_o\). After we multiply by \(v\), we multiply the result by our shard of \(W_o\) to get a shard of \(o_s \in \mathbb{R}^{d_\text{model}\times n_\text{heads}&#x2F;N}\). Then each accelerator will communicate its own shard to all the others, and all the others will communicate their shards back. This is \((N-1)d_\text{model}&#x2F;N\) of comms cost. Each accelerator will do an even share of the addition to get the output projection, then do the same communication they did last time and the individual hosts will do the concatenation (approximately instant).&lt;&#x2F;p&gt;
&lt;p&gt;The MLP layer is by nature very similar! Just like we have \(W_o\) to project our multi-headed attention results back down to a vector of length \(d_\text{model}\), we have \(W_1\in \mathbb{R}^{4\times d_\text{model}}\) and \(W_2\in \mathbb{R}^{d_\text{model}\times 4}\) to make a dimension 4 times larger and then project it back down. The same two communications are done at the end of the MLP.&lt;&#x2F;p&gt;
&lt;p&gt;Ultimately we do \(4 \cdot (N - 1)d_\text{model}&#x2F;N\) bytes of communication. The kv cache is split across heads by GPU.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;latency-calculations&quot;&gt;latency calculations&lt;&#x2F;h3&gt;
&lt;p&gt;We&#x27;ve discussed the capacity fairly thoroughly, mapped out comms in the model parallelism section and discussed general compute steps. Now we&#x27;ll build it into equations that estimate latency!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;batchsize.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Our latency calculations are mostly about the flops vs memory boundedness. If we have a small number of multiplies to do per parameter, then maybe we&#x27;ll be throttled by memory bandwidth. Flops are increased by both batch size and number of parameters, while memory is only increased by number of parameters.&lt;&#x2F;p&gt;
&lt;p&gt;For comms, it&#x27;s not about boundedness, but rather about adding a latency term and a throughput term (the 300GB&#x2F;s). Something tricky about the latency side of this figure is that it&#x27;s not reported, so the best I can do is guess &amp;quot;approximately small&amp;quot;, which is approximately 8 microseconds per message sent as found in this &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1804.06826.pdf&quot;&gt;Citadel paper&lt;&#x2F;a&gt; but it&#x27;s for V100 NVLink.&lt;&#x2F;p&gt;
&lt;p&gt;Because of the compute factors, to calculate the latency of a single token decoding step we&#x27;d have two formulas - one for memory bandwidth bound (small batch) and another for flops bound (large batch). For large batch, we&#x27;ll drop the latency factor for communications.&lt;&#x2F;p&gt;
&lt;p&gt;Equations for a small batch (say 1, so we can drop the batch factor) would be; (where \(N\) is the number of accelerators and \(P\) is the number of parameters and \(b\) is &amp;quot;byte&amp;quot; as a unit)
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{compute} = \frac{2 \cdot P\cdot\text{b}}{N \cdot A_{\text{bm}} \text{b}\space\text{s}^{-1}}\\
\text{comms} =  4 \cdot n_\text{layers} \cdot  8\mu\text{s}&lt;&#x2F;script&gt;

There is \(2 \cdot P\) because we need to pass all the parameters through the memory, and each parameter is two bytes. \(A_\text{bm}\) is the accelerator memory bandwidth, and this cost is split across accelerators. For comms, we have \( 4 \cdot n_\text{layers} \) communications per layer, and the latency per each request. Comms will usually come out to be relatively small so for the compute bound case we won&#x27;t need to pay attention to it anyway. There&#x27;s also a throughput cost in comms which also rounds away.&lt;&#x2F;p&gt;
&lt;p&gt;There&#x27;s another sometimes-significant factor here which is the read time for the kv cache, which I&#x27;ll leave out of the equation now since it depends on number of context tokens, which can even vary within a batch and total number of tokens we want to sample. This would be calculated as memory bandwidth time. Another missing memory bandwidth time is the read of the unembeddings to calculate logits at each sampling step, which is \( \in \mathbb{R}^{d_\text{model}\times n_\text{vocab}}\).&lt;&#x2F;p&gt;
&lt;p&gt;As previously mentioned, the memory does not actually stay constant, rather some additional memory is used per batch for intermediate activations. The reason we don&#x27;t factor this in is simply because it&#x27;s hard to count as it varies a lot by the software stack, compiler optimisations, etc.&lt;&#x2F;p&gt;
&lt;p&gt;For large batches (say 512), where \(B\) is the batch size;&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{compute} = B \cdot \frac{2 \cdot P  \cdot \text{FLOP}}{N \cdot A_f\text{FLOP}\space\text{s}^{-1}}\\
\text{comms} = B \cdot  \frac{2\cdot n_\text{layers} \cdot 4 \cdot d_\text{model} \cdot \text{b}}{A_c\text{b}\space\text{s}^{-1}}&lt;&#x2F;script&gt;
&lt;p&gt;Where \(A_f\) is the flops of the accelerator and \(A_c\) is the comms bandwidth. We do \(2\cdot P\) flops of operations, which can be intuited by the fact that we matmul through all the parameters, and as mentioned earlier, a matrix-vector multiplication is \(2mn\) given \(A \in \mathbb{R}^{m\times n}, b \in \mathbb{R}^{n}\).&lt;&#x2F;p&gt;
&lt;p&gt;For comms, we see the four (I&#x27;ll round that \(N-1\) factor to \(N\)) communications each of a \(d_{model}\) size vector per layer as explained in the model parallelism section. We swapped out the latency calculation for a throughput one. Then it&#x27;s all divided by the comms bandwidth.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s play with a larger model, a Gopher sized 260B model on 16 GPUs. For a small batch, it&#x27;s 22 ms per token generated. The throughput cost for the comms which we can calculate with the equation for large batch is approximately 35 microseconds, assuring us that it was safe to drop.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{compute} = \frac{2 \cdot P}{N \cdot A_\text{bm}} = \frac{2 \cdot 260\text{e}9}{16\cdot 1.5\text{e}12} \approx 0.0217 \approx 22\text{ms} \\
\text{comms} = 2 \cdot 4 \cdot n_\text{layers} \cdot 8\mu\text{s}= 4 \cdot 80\cdot 8\mu\text{s} = 2560\mu\text{s} \approx 3\text{ms}&lt;&#x2F;script&gt;
&lt;p&gt;For a large batch of 512, for a total of 53 ms per token generated (per batch, so in the 62ms 512 tokens are generated). The latency cost on comms here would&#x27;ve also been 3ms (latency is not multiplied by batch as the message can be prepared together) which is somewhat significant to drop but it&#x27;s fine if we assuming parallel comms and compute.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{compute} = B \cdot \frac{2 \cdot P}{N \cdot A_f} = 512 \cdot \frac{2 \cdot 260\text{e}9}{16 \cdot 312\text{e}12} \approx 0.053 \approx 53\text{ms}\\
\text{comms} = B \cdot \frac{2\cdot 4 \cdot n_\text{layers} \cdot d_\text{model}}{A_c} = 512 \cdot \frac{ 8 \cdot 80 \cdot 16384}{300\text{e}9} \approx 18\text{ms}&lt;&#x2F;script&gt;
&lt;p&gt;The higher value between the comms and compute is taken as we&#x27;re assuming that &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;(http:&#x2F;&#x2F;www.netlib.org&#x2F;lapack&#x2F;lawnspdf&#x2F;lawn96.pdf)&quot;&gt;it&#x27;s parallel&lt;&#x2F;a&gt;. Thus, we would want to avoid having comms being greater than compute (this is the mechanism that prevents us from approaching latency zero as we insert more chips, eventually the comms will start taking more and more time). It&#x27;s not guaranteed that all systems will do this in parallel, and certainly not &lt;em&gt;perfectly&lt;&#x2F;em&gt; in parallel.&lt;&#x2F;p&gt;
&lt;p&gt;These numbers are definitely much lower than what we can get with real sand, as it assumes optimal hardware usage, doesn&#x27;t factor in softmaxes, assumes zero comms latency and ignores many other smaller factors. Nonetheless, all the reasoning behind this math is useful for thinking about where to go optimise performance what deltas incoming optimisations will cause.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;batch-sizes&quot;&gt;batch sizes&lt;&#x2F;h3&gt;
&lt;p&gt;Batch size is an important factor of our performance, especially towards understanding performance for specific usages.&lt;&#x2F;p&gt;
&lt;p&gt;In the previous section, we have two calculations for when something memory bandwidth bound versus flops bound. To figure out which is at play we can compare these numbers;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;\text{mem bandwidth time} = \frac{2 \cdot P}{N \cdot A_\text{bm}}\\
\text{flops time} = B \cdot \frac{2 \cdot P}{N \cdot A_f}&lt;&#x2F;script&gt;
&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;re dealing with the same ratio we found in the &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#kv-cache&quot;&gt;kv cache&lt;&#x2F;a&gt; section. The min batch size for memory bandwidth bound is \(A_\text{bw}&#x2F;A_f = 208\). This is a handy ratio! If we have the load to do it, we prefer flops bound as it&#x27;s more compute efficient. Though it&#x27;s also the case that if we&#x27;re flops bound, making the batch size larger doesn&#x27;t mean anything is getting faster.&lt;&#x2F;p&gt;
&lt;p&gt;To calculate when the capacity goes from mostly kv cache to mostly weights is trivial, and also isn&#x27;t a binary in the same way (nothing special happens when your kv cache starts taking up more memory than your weights). Nothing special really happens with comms either. At some point in increasing the batch size, the throughput starts dwarfing the latency so we dropped that factor. As observed previously, the latency becomes insignificant much later (our 512 batch on 52B communication cost was still 11% latency).&lt;&#x2F;p&gt;
&lt;p&gt;Something oversimplified about comms is that it happens at four different steps, which means we don&#x27;t just want our compute time to be longer than our comms time, we want it to be the case at each step (if we can parallelise the compute and comms). For that, we have a weirder ratio: flops per byte of comms. Here&#x27;s a nice chart of our computations, which will also be useful in the section below.&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;th&gt;\(q, k, v\)&lt;&#x2F;th&gt;&lt;th&gt;\(o\)&lt;&#x2F;th&gt;&lt;th&gt;\(w_1\)&lt;&#x2F;th&gt;&lt;th&gt;\(w_2\)&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;flops&lt;&#x2F;td&gt;&lt;td&gt;\(3B({d_\text{model}}^2)\)&lt;&#x2F;td&gt;&lt;td&gt;\(B({d_\text{model}}^2)\)&lt;&#x2F;td&gt;&lt;td&gt;\(4B({d_\text{model}}^2)\)&lt;&#x2F;td&gt;&lt;td&gt;\(4B({d_\text{model}}^2)\)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;bytes of comms&lt;&#x2F;td&gt;&lt;td&gt;\(B(d_\text{model})\)&lt;&#x2F;td&gt;&lt;td&gt;\(B(d_\text{model})\)&lt;&#x2F;td&gt;&lt;td&gt;\(B(d_\text{model})\)&lt;&#x2F;td&gt;&lt;td&gt;\(B(d_\text{model})\)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;flops&#x2F;byte&lt;&#x2F;td&gt;&lt;td&gt;\(3(d_\text{model})\)&lt;&#x2F;td&gt;&lt;td&gt;\(d_\text{model}\)&lt;&#x2F;td&gt;&lt;td&gt;\(4(d_\text{model})\)&lt;&#x2F;td&gt;&lt;td&gt;\(4(d_\text{model})\)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;\(312\text{e}12 \div 300\text{e}9 = 1040\), which is our flops per byte of comms for our A100s. We want the values in the last row to be larger than our hardware flops per byte so that we stay flops bound (assuming we are not memory bound here). For any model with an embedding dimension over 1024 (per chip), we&#x27;re safe! For 512, it&#x27;s a little awkward.&lt;&#x2F;p&gt;
&lt;p&gt;A low-load API may result in smaller batch sizes, leading to reasonable decisions like dropping the kv cache. If an API had the load for large batches it would probably want to serve the lowest batch size that gets flop bound even if there is capacity left so that it could optimise for per-request-latency. In say mass-inferencing jobs like &lt;a href=&quot;https:&#x2F;&#x2F;deepmind.com&#x2F;blog&#x2F;article&#x2F;Competitive-programming-with-AlphaCode&quot;&gt;AlphaCode&lt;&#x2F;a&gt; we might want to insert as many chips as we can and then do the largest batch we can do with that capacity. I say &amp;quot;may&amp;quot; a lot here but I actually think these are absolute and all three kinds of cases.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;flops-counting&quot;&gt;flops counting&lt;&#x2F;h3&gt;
&lt;p&gt;Previously;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;We do \(2\cdot P\) flops of operations, which can be intuited by the fact that we matmul through all the parameters.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;This is correct reasoning, but we can break it down by walking through all the transformer steps and check that we get \(2P\).&lt;&#x2F;p&gt;
&lt;p&gt;The following calculations are per token, per layer. I describe \(W_q, W_k, W_v \in \mathbb{R}^{d_\text{model}\times d_\text{model}}\) where it&#x27;s more accurate to say we have \(W_q^i, W_k^i, W_v^i \in \mathbb{R}^{d_\text{model}\times d_\text{head}}\), where \(i\) goes up to \(n_\text{heads}\). But for the sake of calculating latency, I simplify \(W_q, W_k, W_v\) to include all the heads.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Computing qkv
&lt;ul&gt;
&lt;li&gt;Multiply \(t_e \in \mathbb{R}^{1\times d_\text{model}}\) by \(W_q, W_k, W_v \in \mathbb{R}^{d_\text{model}\times d_\text{model}}\)&lt;&#x2F;li&gt;
&lt;li&gt;Flop count: \({2 \cdot 3 \cdot d_\text{model}}^2\)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Calculate z
&lt;ul&gt;
&lt;li&gt;This is \(\text{softmax}((q\cdot k)\div\sqrt{d_\text{head}}) \cdot v = z\)&lt;&#x2F;li&gt;
&lt;li&gt;No matrices are multiplied, the number of flops is some factor of \(d_\text{model}\).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Multiply by the output projection matrix
&lt;ul&gt;
&lt;li&gt;Multiply \(W_o \in \mathbb{R}^{d_\text{model}\times d_\text{model}}\), by \(z \in \mathbb{R}^{d_\text{model}\times1}\)&lt;&#x2F;li&gt;
&lt;li&gt;Flop count:  \(2 \cdot {d_\text{model}}^2\)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Feed-forward
&lt;ul&gt;
&lt;li&gt;We have our MLP weights \(W_1 \in \mathbb{R}^{4\times d_\text{model}}, W_2 \in \mathbb{R}^{d_\text{model}\times 4} \) for two linear transformations (there&#x27;s a ReLU in the middle, which small).&lt;&#x2F;li&gt;
&lt;li&gt;Flop count:  \(2\cdot 8 \cdot {d_\text{model}}^2 \)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Some other things
&lt;ul&gt;
&lt;li&gt;There are typically layernorm that happen after each attention, where the weights there are a vector of length \(d_\text{model}\).&lt;&#x2F;li&gt;
&lt;li&gt;There&#x27;s another linear layer and then a softmax that sits on top, which is our output (token) embedding or unembedding or de-embedding or embedding\(^{-1}\).&lt;&#x2F;li&gt;
&lt;li&gt;The original transformer has a cosine absolute positional encoding scheme, which is an addition operation on the token embedding.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Adding up all the flops!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;F = n_\text{layers} \cdot (2 \cdot 3  \cdot {d_\text{model}}^2  + 2\cdot d_\text{model}^2  + 16\cdot d_\text{model}^2 )\\
 = n_\text{layers} \cdot 24 \cdot {d_\text{model}}^2&lt;&#x2F;script&gt;

Subbing in our 8192 model, we should get about 100B flops;&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;F = 64\cdot 24\cdot 8192^2
 = 103079215104 \text{flops}&lt;&#x2F;script&gt;
&lt;p&gt;103079215104 over two is about 51.5B. We&#x27;re a lil under (we get 51.5B instead of 52B) but that&#x27;s because token (un)embeddings are nearly a billion parameters. It would be reasonable to do the latency calculations with \(2\cdot 12\cdot n_\text{layers} \cdot {d_\text{model}}^2\) instead of \(2\cdot P\), but it&#x27;s less than a 2% difference.&lt;&#x2F;p&gt;
&lt;p&gt;What about the the calculation of \(z\) and all the other steps I didn&#x27;t count? Those are all vector-vector (or even vector-scalar) operations, so they are built around a factor of \(d_\text{model}\) rather than \({d_\text{model}}^2\). Even if we had 100 of these operations per layer, it would come out to a hundred million flops, which is 0.1% of the number of flops we counted.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;intermediate-memory-costs&quot;&gt;intermediate memory costs&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2007.00072.pdf&quot;&gt;Data Movement Is All You Need&lt;&#x2F;a&gt; (which is mostly about optimising low level data movement for transformers, and isn&#x27;t a particularly relevant read) has a nice way of classifying operations. We have tensor contractions, which are the big matmuls we&#x27;ve mostly cared about (including the linear layers). Then there are statistical normalisations, the softmax and layernorm. Finally, which this post has completely ignored till now are element-wise operators, which are things like biases, dropouts and activations.&lt;&#x2F;p&gt;
&lt;p&gt;So how do we calculate the latency of those matmuls, layernorms, etc? The reported flops on our hardware is &lt;a href=&quot;https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;performance&#x2F;dl-performance-gpu-background&#x2F;index.html&quot;&gt;specificially for the multiply-add operations&lt;&#x2F;a&gt; so it would not be right to count it in there even if we could count the flops. Surprise! It&#x27;s only to cost memory to do the softmax read&#x2F;writes as that&#x27;s what the bandwidth to flops ratio favours. This is the latency factor that has been alluded to!&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m going to break character on the first-principles aspect of this and discuss Table A.1 from the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2007.00072.pdf&quot;&gt;Data Movement Is All You Need&lt;&#x2F;a&gt; paper. Here we see that the latency for softmax is actually slightly higher than the calculations for qkv (which are a 1&#x2F;3 of the time). This is a little concerning!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;arithmetic_transformers&#x2F;a1.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For the same reason the softmax is memory bound, so is the multiplication of qk, ReLU and dropout are also quite expensive.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;GPU Kernel Fusion&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;GPUs execute operations in units of &amp;quot;kernels&amp;quot;. Kernel fusion means that something that was usually 2 kernels can become one, and the primary use is to reuse loads into memory and reduce redundant loads and stores. For example, a multiply-add is one kernel. If it were two, then one would load+add+store and the second would load+multiply+store. We could save a lot of trips by doing load+add+multiply+store.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;We can also tell the softmax here is not perfectly fused by counting the number of read-writes we should need. In theory it can just be one read and one write (the standard is uh, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1805.02867.pdf&quot;&gt;four&lt;&#x2F;a&gt; so I&#x27;m bullying a bit). For qk, it would be two reads and one write (the two reads can probably be saved). The three to one ratio then, indicates that the softmax is doing more memory passes than is optimal. I say this, because this expresses how much this counting is software dependents and needs experiments to estimate, since in theory the cost could be zero.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s also worth noting that the percentage of time these operations take gets smaller quickly as model size increases as the memory will increase on the order of \(d_\text{model}\) while the flops increase on the order of \({d_\text{model}}^2\) ‚Äî per layer. The paper is a 336M param model, \(d_\text{model} = 1024, n_\text{layers} = 24\).&lt;&#x2F;p&gt;
&lt;p&gt;I added up the latency of all the values in the &amp;quot;Ours&amp;quot; column that were memory bound, including the element-wise operations. The result is that these intermediate steps take 43% of the time. In a model of size 52B (where \(d_\text{model}\) is 8 times larger, we see these operations become less significant.&lt;&#x2F;p&gt;
&lt;p&gt;The duration of these memory bound intermediate operations will take 8 times longer as the operations are vectors of length \(d_\text{model}\). However, the number of flops will increase by 64 times, which means the flop time increases by 64 times.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;0.43\cdot 8 \div(1\cdot64) = 0.05375&lt;&#x2F;script&gt;
&lt;p&gt;So using the optimisations in that paper, a 52B model inference latency would be about 5% of these intermediate calculations we didn&#x27;t factor into latency.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;comparing-against-real-benchmarks&quot;&gt;comparing against real benchmarks&lt;&#x2F;h3&gt;
&lt;p&gt;I work at a language modelling company that has its own infrastructure and existing benchmarks but uh, IP is hard. There is a sadly small number of public benchmarks available for model parallel inferencing? It seems like the only public engines for this are &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;FasterTransformer&quot;&gt;Nvidia FasterTransformer&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;blog&#x2F;deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression&#x2F;&quot;&gt;Microsoft Deepspeed&lt;&#x2F;a&gt; with other benchmarks probably scattered in papers I don&#x27;t know exist. Anywho, we can verify our calculations against some real benchmarks!&lt;&#x2F;p&gt;
&lt;p&gt;Because I only want to use 2 GPUs, I&#x27;ve run a 13B parameter model with FasterTransformer, which does a bunch of good kernel fusing and provides us with tensor parallelism. 13B is 40 layers, 40 heads, each of dim 128 for a dim size of 5120. I have screenshots of the profiles &lt;a href=&quot;https:&#x2F;&#x2F;docs.google.com&#x2F;presentation&#x2F;d&#x2F;17PMhlxB3hZYBLqf2mych9CL8kyyssIEvJHOscpqTo1k&#x2F;edit?usp=sharing&quot;&gt;in here&lt;&#x2F;a&gt; and there are a bunch of interesting things in there that might make another post.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ll start with a 512 context length, batch size 1 and 10 tokens outputted. For a small batch for one token on 2 GPUs we expect 8.4ms, and about 1ms of comms. For 1 GPU, that would be 16.8ms and 0 comms. (2x40x12x5120^2&#x2F;1.5e12)&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Excuse my mangled significant figures, I probably should&#x27;ve kept the mem bandwidth to 1.555 instead of 1.5.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Our empirical result for 1 GPU is 22.0ms, meaning our guess was 76% there. We can actually safely account for all of this, where we know some percentage will go to intermediate activations, and that we don&#x27;t actually get 100% of our theoretical memory bandwidth. For these dimensions, a profile tells us we get up to about 90% of our full memory bandwidth (where I compare the expected cost of a matmul to the duration of a single matmul kernel and rounded up as the bandwidth usage varies quite a bit depending on the tensors being loaded). Counting that in, we expect to take 18.5ms. Adding up the cost of intermediate activations (which we can do from a profile) we get another 2.2ms, getting us to 20.7 ms! To account for the last 1.4 ms there are some other sub-millisecond operations like token embeddings, doing top-(k|p), less net bandwidth than 90% (I couldn&#x27;t be bothered to actually average everything I took the highest bw usage I could find) or even kernal launch times.&lt;&#x2F;p&gt;
&lt;p&gt;Our emprical result for 2 GPUs is 13.5. We&#x27;re farther off this time, for only 62% of the way there. We would check the profile again to see the memory bandwidth (which we expect to be slightly worse, as smaller tensors tend to be able to get less of the bandwidth). This time, it doesn&#x27;t quite get to 90, more like 87, getting us to 9.5ms. The intermediate activations take a similar amount of time (2ms), getting us 11.7ms. With the remaining 1.5 ms then, we&#x27;re searching for comms! This is easily covered by our calculated 1ms of comms not being parallelised. From the profile, our comms take 40-50microseconds per layer, for a total of 1.7ish ms of comms time, which accounts for everything pretty well!&lt;&#x2F;p&gt;
&lt;p&gt;I think for both of those operations, the counting of intermediate activations was a bit higher than it should be, because the profile gave consistently slightly-higher latencies than the raw benchmarking run. The output of the benchmark run was &lt;code&gt;180.86 ms (context time: 45.45 ms)&lt;&#x2F;code&gt; and &lt;code&gt;283.60 ms (context time: 63.17 ms)&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But what about the forwards pass? I expect the forwards pass to take num_tokens&#x2F;flops_to_bw_ratio times as long as a decoding step. This is because we have to send &lt;em&gt;all&lt;&#x2F;em&gt; the tokens to all the GPUs, and each GPU will do their heads of attention on it and store kv. Let&#x27;s use the updated memory bandwidth, 312e12&#x2F;(1.5e12x0.9)=231. Looking at the 1 GPU setup, where 22 is our expected decoding step, we see the 22*(512&#x2F;231) = 48 which is not quite the claimed 63. For 2 GPUs we get 13.5*(512&#x2F;231) = 30ms, even worse!&lt;&#x2F;p&gt;
&lt;p&gt;For the one gpu, some of the missing time should just be kv storing. Looking at the profiles, this is 18 microseconds per layer, 0.7ms. There are some Memsets for 0.2ms. We expect the flop time (this is flops bound!) for one of our MLP multiplies to be 512x4x5120^2x2&#x2F;312e12 = 344 microseconds. In practice, this is 476 at the lowest which means we get 72% of the flops we expect? For the projection in the attention we expect we 512x5120^2x2&#x2F;312e12 = 86 microseconds. In profiles we find this to be 159 at the lowest, which is 54%. Yikes! I panicked for a bit, but uh this is apparently just the flops we expect? See Figure 14 in &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2104.05158.pdf&quot;&gt;this paper&lt;&#x2F;a&gt; where a 512x4000x4000 ends up getting less than 150TFLOPs&#x2F;s.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;exercises&quot;&gt;exercises&lt;&#x2F;h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Given batch size, context length and next_n, how can we calculate the savings of using &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#kv-cache&quot;&gt;kv cache&lt;&#x2F;a&gt;?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;What overheads does the kv cache add in memory time?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Can we be memory bound on our forwards pass but flops bound at each sampling step?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;What tradeoffs and calculations should we consider for using &lt;em&gt;more&lt;&#x2F;em&gt; GPUs than is necessary for capacity? Say for example, a 52B model on 8 or 16 GPUs instead of 4.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;We came up with formulas to calculate time to predict one token. How would we calculate the time to do an entire sample, from doing the forwards pass on the context to predicting all the tokens requested?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#capacity&quot;&gt;capacity&lt;&#x2F;a&gt; section, I say the memory of intermediate calculations are negligble. How small are they exactly?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#batch-sizes&quot;&gt;batch sizes&lt;&#x2F;a&gt; section, we went a bit off topic and talked about the flops per byte of communication. What are the tradeoffs if we had an embedding dimension size of 512?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;We assume GPUs attached to the same host here, but could communicate GPUs between hosts like we do in training. &lt;a href=&quot;https:&#x2F;&#x2F;aws.amazon.com&#x2F;ec2&#x2F;instance-types&#x2F;p4&#x2F;&quot;&gt;AWS has 400gb&#x2F;s&lt;&#x2F;a&gt;. What about it!&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;In &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;transformer-inference-arithmetic&#x2F;#model-parallelism&quot;&gt;model parallelism&lt;&#x2F;a&gt;, we could in practice communicate all the shards and then have each accelerator do all the addition, instead of just a share of their addition. What are the latency implications there?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Try calculating the large batch speed for a 52B on 4xGPUs at batch size 256. The compute should be about 21ms and comms should be about 4ms.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Consider the operation of taking the vector out of the last layer and multiplying it by the unembedding matrix, storing the logits and then doing top-k or top-p sampling (which requires a sort). How long should this take for a 52B model, and what can we parallelise here?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;How can we shard the token embeddings? Would shard the input token embeddings differently from the unembeddings? Layernorms? What extra communication does this incur?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;acknowledgements&quot;&gt;acknowledgements&lt;&#x2F;h3&gt;
&lt;p&gt;Would like to extend credit and thanks to people who make a positive impact on this post in varying capacities. &lt;a href=&quot;https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=GprA5UsAAAAJ&amp;amp;hl=en&quot;&gt;James&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;jekbradbury&quot;&gt;Bradbury&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.ekzhang.com&quot;&gt;Eric Zhang&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;tay.ro&#x2F;&quot;&gt;Taylor Rogalski&lt;&#x2F;a&gt;,  &lt;a href=&quot;https:&#x2F;&#x2F;horace.io&#x2F;&quot;&gt;Horace He&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;www.furidamu.org&#x2F;&quot;&gt;Julian Schrittwieser&lt;&#x2F;a&gt;, Reiner Pope, Jim Wu, &lt;a href=&quot;https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=uMg7CEAAAAAJ&amp;amp;hl=en&quot;&gt;Mohammad&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;bavarian.dev&#x2F;&quot;&gt;Bavarian&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;tbrindus.ca&#x2F;&quot;&gt;Tudor Brindus&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;adrien-morisot-045236173&#x2F;?originalSubdomain=ca&quot;&gt;Adrien Morisot&lt;&#x2F;a&gt; with James leading by a long shot.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;citation&quot;&gt;citation&lt;&#x2F;h3&gt;
&lt;p&gt;Please cite as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;Chen, Carol. &amp;quot;Transformer Inference Arithmetic&amp;quot;, https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;transformer-inference-arithmetic&#x2F;, 2022.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;hr &#x2F;&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;hey kipply you should better understand our big model inferencing latency&lt;br&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;yes that&#x27;s a great idea i&#x27;ll look into it!&lt;br&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;cool i&#x27;d love to see the profile &lt;br&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;if i sit in a dark room by myself long enough i think i can explain all the milliseconds&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üò≥&lt;br&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;&#x2F;blockquote&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;The architectures and latencies expressed in this post are those of publicly known or theoretical models and benchmarks and do not necessarily reflect the architectures or latencies of my employer&#x27;s models.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>LLM Parameter Counting</title>
		<published>2022-03-30T00:00:00+00:00</published>
		<updated>2022-03-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/transformer-param-count/"/>
		<link rel="alternate" href="https://kipp.ly/transformer-param-count/" type="text/html"/>
		<id>https://kipp.ly/transformer-param-count/</id>
		<content type="html">&lt;p&gt;Each weight or parameter is a float that was tuned during training and is usually two bytes as most training is done half-precision now(&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bfloat16_floating-point_format&quot;&gt;bfloat16&lt;&#x2F;a&gt;). Not everything is trained&#x2F;served bfloat16, but it&#x27;s at least half-precision (at least since &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2005.14165.pdf&quot;&gt;the GPT-3 Paper&lt;&#x2F;a&gt; in 2020) which gets us the two bytes.&lt;&#x2F;p&gt;
&lt;p&gt;The weights loosely consist of the following, per each block (where one block a decoder unit that consists of a self-attention layer and a feedforward layer, though I&#x27;ll refer to blocks as layers):&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;\( W_q,W_k,W_v \) matrices, which are each \(d_\text{model} \cdot n_\text{heads}\cdot d_\text{head} \) and project the input into the query, key, and value used in self-attention.&lt;&#x2F;li&gt;
&lt;li&gt;A \( W_o \) matrix, which is also \(d_\text{model}\cdot n_\text{heads}\cdot d_\text{head} \) and used on the output of self-attention, before the MLP layer (the feed-foward neural network that&#x27;s stacked on the self-attention layer).&lt;&#x2F;li&gt;
&lt;li&gt;MLP weights, which are two matrices each of \({d_\text{model}}^2 \cdot 4\). You might also see this referred to by feedforward or linear layers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The four in the MLP weights calculation is based on architecture, but basically every transformer since the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1706.03762.pdf&quot;&gt;original from 2017&lt;&#x2F;a&gt; has gone with that ratio ‚Äî where the MLP is 4 four times the size of the model embedding dimension. In a vast majority of transformer architectures, \(n_\text{heads}\cdot d_\text{head} = d_\text{model}\). You can see this in &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2005.14165.pdf&quot;&gt;all the GPT models&lt;&#x2F;a&gt; at Table 2.1 (the 13B model is off by 20, but might just be a... typo?), in the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.11446.pdf&quot;&gt;Gopher models&lt;&#x2F;a&gt; in Table 1 (where what I called \(d_\text{head}\), they called &amp;quot;Key&#x2F;Value Size&amp;quot;). This is not necessarily the case, but can be assumed.&lt;&#x2F;p&gt;
&lt;p&gt;So then we have a handy equation to calculate the number of parameters!&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;P = 12 \cdot n_\text{layers} \cdot {d_\text{model}}^2&lt;&#x2F;script&gt;
&lt;p&gt;With these, we can practice seeing how the factor of four in the MLP layers and the relationship of \(n_\text{heads}\cdot d_\text{head} = d_\text{model}\) holds true with the dimensions in the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2112.00861.pdf&quot;&gt;inaugural Anthropic paper&lt;&#x2F;a&gt; in Table 1, where only \(n_\text{layers}\), \(d_\text{model}\) and \(P\) are supplied.&lt;&#x2F;p&gt;
&lt;script type=&quot;math&#x2F;tex;mode=display&quot;&gt;P = 12 * n_\text{layers} \cdot {d_\text{model}}^2\\
= 12 \cdot 64 \cdot 8192^2\\
= 51,539,607,552&lt;&#x2F;script&gt;
&lt;p&gt;This is not &lt;em&gt;quite&lt;&#x2F;em&gt; 52B. It&#x27;s probably cheating to round up by half a billion parameters, but we can account for them! The equation above is most of the parameters, but we&#x27;re missing token embeddings. Anthropic uses a 65536 vocab size, so we get \(n_\text{tokens} * d_\text{model} = 536,870,912 \). Adding \(536,870,912 + 51,539,607,552 = 52,076,478,464\). We actually have that half a billion params twice for the unembeddings, which leads us to about 52.5B tokens.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;re also missing biases that are attached to all the weights, as well as layernorm. Biases should be approximately zero, and layernorm are \(d_\text{model}\) (though they exist per block), but otherwise known as zero. Transformers also have positional encoding mechanisms, which for GPT-2 and the original transformer is \(n_\text{ctx}\cdot d_\text{model}\) (aka, zero) but Gopher 280B there&#x27;s 21.5B weights spent on the relative positional encoding method presented in the &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1901.02860&quot;&gt;Transformer XL paper&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Things Read | Feb 2022</title>
		<published>2022-03-01T00:00:00+00:00</published>
		<updated>2022-03-01T00:00:00+00:00</updated>
		<link href="https://kipp.ly/feb-2022/"/>
		<link rel="alternate" href="https://kipp.ly/feb-2022/" type="text/html"/>
		<id>https://kipp.ly/feb-2022/</id>
		<content type="html">&lt;p&gt;The one in which C.S. Lewis &lt;a href=&quot;https:&#x2F;&#x2F;www.lewissociety.org&#x2F;innerring&#x2F;&quot;&gt;tells me I&#x27;m silly&lt;&#x2F;a&gt; for status chasing. &lt;a href=&quot;https:&#x2F;&#x2F;paulbutler.org&#x2F;2022&#x2F;what-does-it-mean-to-listen-on-a-port&#x2F;&quot;&gt;Networking fanfiction&lt;&#x2F;a&gt; as a method of education. Discovery non-fiction for the &lt;a href=&quot;https:&#x2F;&#x2F;go.dev&#x2F;blog&#x2F;ismmkeynote&quot;&gt;modern Golang garbage collector&lt;&#x2F;a&gt; that saved the language. A cool person&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;blog.redvice.org&#x2F;2022&#x2F;lineiform-rust-meta-jit&#x2F;&quot;&gt;pipe dreams for more meta-JIT libraries&lt;&#x2F;a&gt;, now in Rust. Long awaited read for &lt;a href=&quot;https:&#x2F;&#x2F;blog.janestreet.com&#x2F;magic-trace&#x2F;&quot;&gt;Magic Trace&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;bytecodealliance&#x2F;wasmtime&#x2F;tree&#x2F;main&#x2F;cranelift&quot;&gt;Cranelift codegen&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;80000hours.org&#x2F;problem-profiles&#x2F;space-governance&#x2F;&quot;&gt;Space governance&lt;&#x2F;a&gt; probably isn&#x27;t that importractable yet, but we double checked to be sure.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Tensorflow Serving Client with C++ and Bazel</title>
		<published>2022-02-25T00:00:00+00:00</published>
		<updated>2022-02-25T00:00:00+00:00</updated>
		<link href="https://kipp.ly/tf-cpp/"/>
		<link rel="alternate" href="https://kipp.ly/tf-cpp/" type="text/html"/>
		<id>https://kipp.ly/tf-cpp/</id>
		<content type="html">&lt;blockquote&gt;
&lt;p&gt;All code examples can be found in &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-serving-cpp&quot;&gt;this repo&lt;&#x2F;a&gt;. If you know what you&#x27;re looking for and can extract the value you need from that repository, the following post may be pretty useless.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Tensorflow doesn&#x27;t yet have support for TF Serving clients. For Golang, I opted to &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;technical&#x2F;tf-go&#x2F;&quot;&gt;compile the protobufs once and put the generated client in the codebase&lt;&#x2F;a&gt;. For a Bazel C++ project, I had two other reasonable options. One was to build tensorflow&#x2F;serving with my project and use the build target that tensorflow set up for me. I tried that (as another blog post on the internet recommended) and bad things happened. For one, tensorflow&#x2F;serving relies on tensorflow&#x2F;tensorflow which has a whole bunch of shit going on (namely long build times) and dependencies on parts of cuda. And two, they had dependencies that clashed with some of the other items in my &lt;code&gt;WORKSPACE&lt;&#x2F;code&gt; and it seems that they might still rely on bazel 3.7.0 and I would like to use 5.0.0. So I went with the copy the protos in your project then do the build (which someone else did &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;andrew-k-21-12&#x2F;tf-serving-client-cpp&quot;&gt;for CMake&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;Reference Links: &lt;a href=&quot;https:&#x2F;&#x2F;grpc.io&#x2F;&quot;&gt;gRPC&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;developers.google.com&#x2F;protocol-buffers&#x2F;docs&#x2F;cpptutorial&quot;&gt;Protocol Buffers C++&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;www.tensorflow.org&#x2F;tfx&#x2F;serving&#x2F;serving_basic&quot;&gt;Tensorflow Serving&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;docs.bazel.build&#x2F;versions&#x2F;main&#x2F;be&#x2F;protocol-buffer.html&quot;&gt;Bazel Protocol Buffer Rules&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;1the Protos&lt;&#x2F;p&gt;
&lt;p&gt;You don&#x27;t need to copy all of the protos in tensorflow&#x2F;serving and certainly not in tensor&#x2F;tensorflow as you probably only plan on using the &lt;code&gt;PredictionService&lt;&#x2F;code&gt; (as opposed to classify or regress, in which case you&#x27;ll have to do some of your own proto copying).&lt;&#x2F;p&gt;
&lt;p&gt;Otherwise, these protos can be downloaded from the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-serving-cpp&quot;&gt;git repo here&lt;&#x2F;a&gt;, and they&#x27;re up to date as of tensorflow&#x2F;serving version 2.8.0 and are very unlikely to change in breaking ways in the near future.&lt;&#x2F;p&gt;
&lt;p&gt;If you put them in a different folder, you&#x27;ll probably need to rename the imports in the &lt;code&gt;.proto&lt;&#x2F;code&gt; files.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;starlark-star-bright-first-star-i-see-tonight&quot;&gt;Starlark, star bright, first star I see tonight&lt;&#x2F;h3&gt;
&lt;p&gt;The protos don&#x27;t build themselves, and the compilation setup is 200 lines of Starlark (I&#x27;m doing ok here, tensorflow&#x2F;serving uses 450 lines). copy them &lt;a href=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kipply&#x2F;tf-serving-cpp&#x2F;main&#x2F;BUILD&quot;&gt;here&lt;&#x2F;a&gt; and leave out the last ten lines that builds a main file.&lt;&#x2F;p&gt;
&lt;p&gt;In your &lt;code&gt;WORKSPACE&lt;&#x2F;code&gt; file you&#x27;ll want the following;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;load&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;@bazel_tools&#x2F;&#x2F;tools&#x2F;build_defs&#x2F;repo:http.bzl&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;http_archive&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;#
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# GRPC Dependencies
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;#
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;http_archive&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;com_github_grpc_grpc&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;strip_prefix &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;grpc-dc78581af30da834b7b95572f109bf6c708686e0&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;urls &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;https:&#x2F;&#x2F;github.com&#x2F;grpc&#x2F;grpc&#x2F;archive&#x2F;dc78581af30da834b7b95572f109bf6c708686e0.tar.gz&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;load&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;@com_github_grpc_grpc&#x2F;&#x2F;bazel:grpc_deps.bzl&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;grpc_deps&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;grpc_deps&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;load&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;@com_github_grpc_grpc&#x2F;&#x2F;bazel:grpc_extra_deps.bzl&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;grpc_extra_deps&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;grpc_extra_deps&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;#
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# Protocol buffer rules
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;#
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;http_archive&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;rules_proto&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;sha256 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;66bfdf8782796239d3875d37e7de19b1d94301e8972b3cbd2446b332429b4df1&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;strip_prefix &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;rules_proto-4.0.0&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;urls &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;https:&#x2F;&#x2F;mirror.bazel.build&#x2F;github.com&#x2F;bazelbuild&#x2F;rules_proto&#x2F;archive&#x2F;refs&#x2F;tags&#x2F;4.0.0.tar.gz&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;https:&#x2F;&#x2F;github.com&#x2F;bazelbuild&#x2F;rules_proto&#x2F;archive&#x2F;refs&#x2F;tags&#x2F;4.0.0.tar.gz&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;load&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;@rules_proto&#x2F;&#x2F;proto:repositories.bzl&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;rules_proto_dependencies&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;rules_proto_toolchains&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;rules_proto_dependencies&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;rules_proto_toolchains&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;tf-serving-client-over-grpc&quot;&gt;TF Serving Client over GRPC&lt;&#x2F;h3&gt;
&lt;p&gt;I&#x27;ll leave an example here, but be prepared to reference the C++ GRPC documentation a lot. I personally found it easier to read the header files, Google is quite diligent in leaving lots of comments in there though is not good at turning up the right reference documentation when you search for things.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c++&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-c++ &quot;&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;#include &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;grpcpp&#x2F;grpcpp.h&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;#include &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;tensorflow_serving&#x2F;apis&#x2F;prediction_service.grpc.pb.h&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;main&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;argc&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;char&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;** &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;argv&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;const &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;auto&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt; prediction_service_stub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=
&lt;&#x2F;span&gt;&lt;span&gt;      tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;serving&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;PredictionService&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;NewStub&lt;&#x2F;span&gt;&lt;span&gt;(grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;CreateChannel&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;          &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;localhost:9000&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;InsecureChannelCredentials&lt;&#x2F;span&gt;&lt;span&gt;())); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; make sure your server is running here!
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;ClientContext client_context;
&lt;&#x2F;span&gt;&lt;span&gt;  tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;serving&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;PredictRequest predict_request;
&lt;&#x2F;span&gt;&lt;span&gt;  tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;serving&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;PredictResponse predict_response;
&lt;&#x2F;span&gt;&lt;span&gt;  grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;ClientContext cli_context;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  predict_request&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mutable_model_spec&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;set_name&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;model_name&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; specify your model name here
&lt;&#x2F;span&gt;&lt;span&gt;  predict_request&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mutable_model_spec&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;set_signature_name&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;some_signature&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; specify the signature here
&lt;&#x2F;span&gt;&lt;span&gt;  google&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;protobuf&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;Map&amp;lt;std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;string, tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;TensorProto&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt; inputs &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=
&lt;&#x2F;span&gt;&lt;span&gt;      &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;predict_request&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mutable_inputs&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;TensorProto input_tensor;
&lt;&#x2F;span&gt;&lt;span&gt;  input_tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;set_dtype&lt;&#x2F;span&gt;&lt;span&gt;(tensorflow&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;DataType&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;DT_INT32);
&lt;&#x2F;span&gt;&lt;span&gt;  input_tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mutable_tensor_shape&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;add_dim&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;set_size&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;  input_tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;add_int_val&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;  input_tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;add_int_val&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;  inputs&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;insert&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;input_key&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, input_tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;const&lt;&#x2F;span&gt;&lt;span&gt; grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;Status&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt; predict_status &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; prediction_service_stub&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Predict&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;      &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;cli_context, predict_request, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;predict_response);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!&lt;&#x2F;span&gt;&lt;span&gt;predict_status&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;ok&lt;&#x2F;span&gt;&lt;span&gt;()) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;cerr &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; predict_status&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;error_message&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;endl;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;const &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;auto&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt; output_pair &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span&gt; predict_response&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;outputs&lt;&#x2F;span&gt;&lt;span&gt;()) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;cout &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;Output &amp;quot; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; output_pair&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;first &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;endl;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;auto&lt;&#x2F;span&gt;&lt;span&gt; tensor &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; output_pair&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;second&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;const &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;auto&lt;&#x2F;span&gt;&lt;span&gt; val &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span&gt; tensor&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int_val&lt;&#x2F;span&gt;&lt;span&gt;()) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;      std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;cout &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;\t&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; val;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;    std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;cout &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; std&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;::&lt;&#x2F;span&gt;&lt;span&gt;endl;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A thing about tensorflow&#x2F;serving is that you specify dimensions, and you don&#x27;t model your data as any kind of multi-dimensional tensor. Instead you just &lt;code&gt;add_dtype_val&lt;&#x2F;code&gt; until you&#x27;ve filled your specified dimensions. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-serving-cpp&#x2F;blob&#x2F;main&#x2F;main.cc&quot;&gt;Here is the link to the full script&lt;&#x2F;a&gt; which also contains an example to get metadata from tensorflow&#x2F;serving and is executable in bazel with &lt;code&gt;bazel run :main_lib&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Reading Log | March 2021</title>
		<published>2021-04-05T00:00:00+00:00</published>
		<updated>2021-04-05T00:00:00+00:00</updated>
		<link href="https://kipp.ly/march-reading-2021/"/>
		<link rel="alternate" href="https://kipp.ly/march-reading-2021/" type="text/html"/>
		<id>https://kipp.ly/march-reading-2021/</id>
		<content type="html">&lt;h3 id=&quot;the-real-world&quot;&gt;The Real World&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;80000hours.org&#x2F;problem-profiles&#x2F;#overall-list&quot;&gt;Our current list of the most important world problems - 80,000 Hours&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Boysenberry&quot;&gt;Boysenberry - Wikipedia&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dreadlocks&quot;&gt;Dreadlocks - Wikipedia&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.acropt.com&#x2F;blog&#x2F;2019&#x2F;10&#x2F;25&#x2F;why-does-stretching-help-you-get-more-flexible&quot;&gt;How does stretching actually make you more flexible? ‚Äî ACRO Physical Therapy &amp;amp; Fitness&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;markxu.com&#x2F;strong-evidence&quot;&gt;Strong Evidence is Common&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bloom%27s_2_sigma_problem&quot;&gt;Bloom&#x27;s 2 sigma problem - Wikipedia&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.thesquirrelcensus.com&#x2F;&quot;&gt;Squirrel Census&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;technical&quot;&gt;Technical&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;1111-warp-better-vpn&#x2F;&quot;&gt;Introducing WARP: Fixing Mobile Internet Performance and Security&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;nelhage&#x2F;archive&#x2F;e709cb1d-3e6a-48e9-953a-0831d14345fe&quot;&gt;Determinism in software engineering&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.chromium.org&#x2F;developers&#x2F;design-documents&#x2F;process-models&quot;&gt;Process Models - The Chromium Projects&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.chromium.org&#x2F;Home&#x2F;chromium-security&#x2F;site-isolation&quot;&gt;Site Isolation - The Chromium Projects&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;lukesmurray.com&#x2F;blog&#x2F;replicating-a-clothing-pattern&quot;&gt;Replicating a Clothing Pattern | Luke Murray&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;lilianweng.github.io&#x2F;lil-log&#x2F;2021&#x2F;03&#x2F;21&#x2F;reducing-toxicity-in-language-models.html&quot;&gt;Reducing Toxicity in Language Models&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;tratt.net&#x2F;laurie&#x2F;blog&#x2F;entries&#x2F;which_parsing_approach.html&quot;&gt;Laurence Tratt: Which Parsing Approach?&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;superuser.com&#x2F;questions&#x2F;294681&#x2F;how-does-a-computer-restart-itself&#x2F;294736#294736&quot;&gt;reboot - How does a computer restart itself? - Super User&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;nelhage&#x2F;archive&#x2F;http-pipelining-s3-and-gg&#x2F;&quot;&gt;HTTP Pipelining, S3, and gg&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;distill.pub&#x2F;2021&#x2F;multimodal-neurons&#x2F;&quot;&gt;Multimodal Neurons in Artificial Neural Networks&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;esbuild.github.io&#x2F;faq&#x2F;#benchmark-details&quot;&gt;esbuild - FAQ&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;nee.lv&#x2F;2021&#x2F;02&#x2F;28&#x2F;How-I-cut-GTA-Online-loading-times-by-70&#x2F;&quot;&gt;How I cut GTA Online loading times by 70%&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;tech&quot;&gt;Tech&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qqt6YxAZoOc&quot;&gt;Computer, build me an app - Rich Harris - JSConf EU 2018 - YouTube&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;codeascraft.com&#x2F;2012&#x2F;09&#x2F;10&#x2F;the-engineer-exchange-program&#x2F;&quot;&gt;403 Forbidden&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.torchnyu.com&#x2F;2021&#x2F;01&#x2F;20&#x2F;learn-imperfectly.html&quot;&gt;Learn Imperfectly&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.torchnyu.com&#x2F;2020&#x2F;12&#x2F;05&#x2F;look-up.html&quot;&gt;Look Up&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;tinyprojects.dev&#x2F;projects&#x2F;mailoji&quot;&gt;Mailoji: I bought 300 emoji domain names from Kazakhstan and built an email service | Tiny Projects&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>shortest path, faster</title>
		<published>2021-04-01T00:00:00+00:00</published>
		<updated>2021-04-01T00:00:00+00:00</updated>
		<link href="https://kipp.ly/spfa/"/>
		<link rel="alternate" href="https://kipp.ly/spfa/" type="text/html"/>
		<id>https://kipp.ly/spfa/</id>
		<content type="html">&lt;p&gt;when i was young, i had no care for software engineering. data structures and algorithms were much more alluring.&lt;&#x2F;p&gt;
&lt;p&gt;i learned about the time and its complexity, and the fastest ways to solve my perplexities.&lt;&#x2F;p&gt;
&lt;p&gt;the challenges i faced were of that a multitude, but none changed me like &lt;a href=&quot;https:&#x2F;&#x2F;dmoj.ca&#x2F;problem&#x2F;vmss7wc15c4p3&quot;&gt;&amp;quot;Gold-Chain Rule&amp;quot;&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;see i knew to find the shortest path, dijkstra&#x27;s algorithm was the fastes.&lt;&#x2F;p&gt;
&lt;p&gt;it runs in oh of [V plus (E times log V)] where V and E are the number of verticies and edges on a ~tree~ directed weighted graph.&lt;&#x2F;p&gt;
&lt;p&gt;when people talk about complexity they always assume the worst case. considering the average may give you a taste.&lt;&#x2F;p&gt;
&lt;p&gt;see to pass gold-chain rule, dijkstra was not faster. shortest path faster algorithm was... faster.&lt;&#x2F;p&gt;
&lt;p&gt;though no average case has been proved, an O(E) average case complexity seems to be the truth&lt;&#x2F;p&gt;
&lt;p&gt;but how better to explain shortest path faster algorithm, than to describe it in poem?&lt;&#x2F;p&gt;
&lt;p&gt;surely an implementation is called for, i won&#x27;t make you wait anymore.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# a deque is a double ended queue
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;from &lt;&#x2F;span&gt;&lt;span&gt;collections &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;deque
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# V and E are vertices and edges, which you knew
&lt;&#x2F;span&gt;&lt;span&gt;v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4
&lt;&#x2F;span&gt;&lt;span&gt;e &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# adj[x].append((y, d)) says there&amp;#39;s a path from x to y with distance d
&lt;&#x2F;span&gt;&lt;span&gt;adj &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[[] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)]
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# distances holds the of the shortest path for each node from node one, stay with me
&lt;&#x2F;span&gt;&lt;span&gt;distances &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# a queue is needed to store nodes as they&amp;#39;re nagivated
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# it started with node one with a distance of zero, this is fated
&lt;&#x2F;span&gt;&lt;span&gt;q &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;deque&lt;&#x2F;span&gt;&lt;span&gt;([(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)])
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# tree traversal starts!
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while &lt;&#x2F;span&gt;&lt;span&gt;q:
&lt;&#x2F;span&gt;&lt;span&gt;    distance, node &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;q&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;popleft&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    distances[node] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;distance
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;dest, add &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;adj[node]:
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# we only want to continue traversal down this branch if it feels good in our hearts
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;distance &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;add &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span&gt;distances[node] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;or &lt;&#x2F;span&gt;&lt;span&gt;distances[node] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;            q&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((distance &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;add, dest))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;l &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(distances[l])
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;so now you know how shortest path fastest algorithm works, perhaps it would help to see that it is no quirk.&lt;&#x2F;p&gt;
&lt;p&gt;compare this to dijkstra&#x27;s in your head, or just let me show you instead&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# import for priority queue, which again i suppose you knew
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;from &lt;&#x2F;span&gt;&lt;span&gt;heapq &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;heappush, heappop
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;e &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;adj &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[[] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span&gt;)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;adj[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;distances &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# saying the same words many times, does count as a rhyme
&lt;&#x2F;span&gt;&lt;span&gt;q &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# this is still the same, except it&amp;#39;s a list instead of a deque, which in python is just a name
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while &lt;&#x2F;span&gt;&lt;span&gt;q: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;    distance, node &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;heappop&lt;&#x2F;span&gt;&lt;span&gt;(q) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# the essence of the pop is maintained
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# this is something a little different, logic that was in the loop is now in the parent
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;distances[node] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;continue
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    distances[node] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;distance &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;dest, add &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;adj[node]: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;heappush&lt;&#x2F;span&gt;&lt;span&gt;(q, (distance &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;add, dest)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# the essence of the push is maintained
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;l &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, v &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;): &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(distances[l]) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;a pop quiz! get ready!&lt;&#x2F;p&gt;
&lt;p&gt;intuitive this algorithm may be, but how would you prove its correctness with ease?&lt;&#x2F;p&gt;
&lt;p&gt;this is a challenging question i pose, as code examples are always mostly a show. not a bug in the implementation of shortest path faster algorithm per say, but perhaps a limitation of inputs are at play. a hint i shall provide, for addressing negative weights in a graph often slides.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Donation Log | 2020</title>
		<published>2021-03-07T00:00:00+00:00</published>
		<updated>2021-03-07T00:00:00+00:00</updated>
		<link href="https://kipp.ly/donation-log-2020/"/>
		<link rel="alternate" href="https://kipp.ly/donation-log-2020/" type="text/html"/>
		<id>https://kipp.ly/donation-log-2020/</id>
		<content type="html">&lt;p&gt;The path to earn-to-give effective altruism is mostly one of normalizing donating, not one of character development. Donations converted to CAD, if I donated through an organization that distributes to other charities, the charities that will be spending the money are listed.&lt;&#x2F;p&gt;
&lt;p&gt;2021 edit: I would&#x27;ve liked to put more money into less anthrocentric causes as well as put some money into meta-research&lt;&#x2F;p&gt;
&lt;h3 id=&quot;breakdown&quot;&gt;Breakdown&lt;&#x2F;h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Charity&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;Amount&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: right&quot;&gt;Charity&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: right&quot;&gt;Amount&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Future of Humanity Institute&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;10000&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Humane League&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;500&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Deworm the World&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;4000&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Good Food Institute&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;500&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Wild Animal Initiative&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;500&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Albert Schweitzer Foundation&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;500&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Against Malaria Foundation&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;4000&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Coalition for Rainforest Nations&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;4000&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Law for Black Lives&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;650&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;We the Protestors&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;350&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Black Legal Action Center&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;285&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Federation of Black Canadians&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;100&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Equal Justice Initiative&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;180&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Kentucky Reproductive Freedom Fund&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;60&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Cambodia Town Relief Fund&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;35&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;Black Girls Code&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;200&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Harriet Tubman Community Organization&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;100&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: right&quot;&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Reading Log | February 2021</title>
		<published>2021-03-06T00:00:00+00:00</published>
		<updated>2021-03-06T00:00:00+00:00</updated>
		<link href="https://kipp.ly/feb-2021/"/>
		<link rel="alternate" href="https://kipp.ly/feb-2021/" type="text/html"/>
		<id>https://kipp.ly/feb-2021/</id>
		<content type="html">&lt;p&gt;Can you tell I&#x27;m doing a read-along of a distributed systems course?&lt;&#x2F;p&gt;
&lt;h3 id=&quot;technical&quot;&gt;Technical&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.blog&#x2F;2012-12-26-downtime-last-saturday&#x2F;&quot;&gt;Downtime last Saturday - The GitHub Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;pdos.csail.mit.edu&#x2F;6.824&#x2F;papers&#x2F;vm-ft.pdf&lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;pdos.csail.mit.edu&#x2F;6.824&#x2F;papers&#x2F;gfs.pdf&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;queue.acm.org&#x2F;detail.cfm?id=1594206&quot;&gt;Access denied | queue.acm.org used Cloudflare to restrict access&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.red-lang.org&#x2F;p&#x2F;about.html&quot;&gt;Red Programming Language: About&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;mlir.llvm.org&#x2F;&quot;&gt;MLIR&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.tensorflow.org&#x2F;2019&#x2F;04&#x2F;mlir-new-intermediate-representation.html&quot;&gt;MLIR: A new intermediate representation and compiler framework ‚Äî The TensorFlow Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;pdos.csail.mit.edu&#x2F;6.824&#x2F;papers&#x2F;mapreduce.pdf&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;discourse.julialang.org&#x2F;t&#x2F;julias-broadcast-vs-jaxs-vmap&#x2F;38990&quot;&gt;Julia&#x27;s Broadcast vs Jax&#x27;s vmap - Internals &amp;amp; Design - JuliaLang&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jax.readthedocs.io&#x2F;en&#x2F;latest&#x2F;jaxpr.html&quot;&gt;Understanding Jaxprs ‚Äî JAX  documentation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;tailscale.com&#x2F;blog&#x2F;an-unlikely-database-migration&#x2F;&quot;&gt;An unlikely database migration ¬∑ Tailscale Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;nelhage&#x2F;archive&#x2F;tracing-jits-and-coverage-guided-fuzzers&#x2F;&quot;&gt;Tracing JITs and coverage-guided fuzzers&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;nelhage&#x2F;archive&#x2F;40eabac8-448a-477c-9b63-ed98fcdf6190&quot;&gt;Alive2 and missed-optimization bug reports&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;www.bnikolic.co.uk&#x2F;blog&#x2F;python&#x2F;jax&#x2F;2020&#x2F;10&#x2F;20&#x2F;jax-outputgraph.html&quot;&gt;Jax: Visualising the computational graph of a jax program | B. Nikolic Software and Computing Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.geeksforgeeks.org&#x2F;maximum-bipartite-matching&#x2F;&quot;&gt;Maximum Bipartite Matching - GeeksforGeeks&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;signalsandthreads.com&#x2F;clock-synchronization&#x2F;&quot;&gt;Clock Synchronization&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;64.github.io&#x2F;cmake-raytracer&#x2F;&quot;&gt;Ray Tracing in pure CMake | Delta&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;dall-e&#x2F;&quot;&gt;DALL¬∑E: Creating Images from Text&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;image-gpt&#x2F;&quot;&gt;Image GPT&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;misc&quot;&gt;Misc&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;culinaryabortions.wordpress.com&#x2F;2008&#x2F;04&#x2F;06&#x2F;5-tempura-lettuce&#x2F;&quot;&gt;5. Tempura Lettuce | Culinary Abortions&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;expandingawareness.substack.com&#x2F;p&#x2F;expanding-awareness-2&quot;&gt;Expanding Awareness #2 - Expanding Awareness&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;alexandertechnique.com&#x2F;&quot;&gt;The Complete Guide to the Alexander Technique&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jaan.io&#x2F;my-friend-radicalized-this-made-me-rethink-how-i-build-AI&#x2F;&quot;&gt;My friend radicalized. This made me rethink how I build AI ‚Äì Jaan Altosaar&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Every day of Money Stuff&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;tech-adjacent&quot;&gt;Tech Adjacent&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;buttondown.email&#x2F;nelhage&#x2F;archive&#x2F;45c2f95f-e21c-48d4-8422-2435b7f16aa8&quot;&gt;Some notes on code review&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;medium.com&#x2F;figma-design&#x2F;desperately-seeking-squircles-8eb8db9b654b&quot;&gt;Desperately seeking squircles. Figma‚Äôs search for the mysterious math‚Ä¶ | by Daniel Furse | Figma Design | Medium&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.drakethomas.net&#x2F;blog&#x2F;good-non-math-problems&quot;&gt;Good non-math problems ‚Äî Drake&#x27;s Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Tensorflow with Go Code Examples: TFRecord Examples, TF Serving Clients</title>
		<published>2021-03-06T00:00:00+00:00</published>
		<updated>2021-03-06T00:00:00+00:00</updated>
		<link href="https://kipp.ly/tf-go/"/>
		<link rel="alternate" href="https://kipp.ly/tf-go/" type="text/html"/>
		<id>https://kipp.ly/tf-go/</id>
		<content type="html">&lt;blockquote&gt;
&lt;p&gt;All code examples can be found in &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&quot;&gt;this repo&lt;&#x2F;a&gt;. If you know what you&#x27;re looking for, and the code works out of the box for you, the following post will be pretty useless.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Tensorflow doesn&#x27;t yet have support for TFRecords or TF Serving clients. This is not a package because TFRecord read&#x2F;write and gRPC TFServing client are no more than a hundred lines each, and I don&#x27;t want to maintain it.&lt;&#x2F;p&gt;
&lt;p&gt;Reference Links: &lt;a href=&quot;https:&#x2F;&#x2F;grpc.io&#x2F;&quot;&gt;gRPC&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;developers.google.com&#x2F;protocol-buffers&#x2F;docs&#x2F;gotutorial&quot;&gt;Proto Buffers Go&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;www.tensorflow.org&#x2F;tfx&#x2F;serving&#x2F;serving_basic&quot;&gt;Tensorflow Serving&lt;&#x2F;a&gt; || &lt;a href=&quot;https:&#x2F;&#x2F;www.tensorflow.org&#x2F;tutorials&#x2F;load_data&#x2F;tfrecord&quot;&gt;TFRecords and tf.Train.Example&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;compiling-protos&quot;&gt;Compiling Protos&lt;&#x2F;h3&gt;
&lt;p&gt;To generate the Go files:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Clone the TF Serving and Tensorflow repositories&lt;&#x2F;li&gt;
&lt;li&gt;Checkout to the version you need&lt;&#x2F;li&gt;
&lt;li&gt;Run &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;blob&#x2F;master&#x2F;compile.sh&quot;&gt;this script&lt;&#x2F;a&gt; after replacing the &lt;code&gt;PATH_TO_TF&lt;&#x2F;code&gt; and &lt;code&gt;PATH_TO_TF_SERVING&lt;&#x2F;code&gt; variables with your path.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;Users&#x2F;kipply&#x2F;code&#x2F;tensorflow&#x2F;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;Users&#x2F;kipply&#x2F;code&#x2F;tfserving&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow_serving&#x2F;apis&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow_serving&#x2F;config&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow_serving&#x2F;util&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow_serving&#x2F;core&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow_serving&#x2F;sources&#x2F;storage_path&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow&#x2F;core&#x2F;framework&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow&#x2F;core&#x2F;example&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow&#x2F;core&#x2F;lib&#x2F;core&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow&#x2F;core&#x2F;protobuf&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;eval &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;protoc -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF_SERVING&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; -I $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt; --go_out=plugins=grpc:src&#x2F; $&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;PATH_TO_TF&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&#x2F;tensorflow&#x2F;stream_executor&#x2F;*.proto&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;rm&lt;&#x2F;span&gt;&lt;span&gt; src&#x2F;tensorflow_serving&#x2F;apis&#x2F;prediction_log.pb.go &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# causes an import loop
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I also commited the compilation &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;tree&#x2F;master&#x2F;src&quot;&gt;here&lt;&#x2F;a&gt;, though I can&#x27;t guarantee the version. I recommend that the compiled files be placed in the gopath, or the package name can be find+replaced and you can commit the &lt;code&gt;pb.go&lt;&#x2F;code&gt; files to your repository.&lt;&#x2F;p&gt;
&lt;p&gt;The script compiles more packages than is absolutely necessary for TFServing+TFRecord writing. The import loop is that &lt;code&gt;tensorflow_serving&#x2F;prediction_log&lt;&#x2F;code&gt; imports &lt;code&gt;tensorflow_serving&#x2F;core&lt;&#x2F;code&gt; which imports &lt;code&gt;tensorflow_serving&#x2F;apis&lt;&#x2F;code&gt;. It&#x27;s a logically valid import cycle of the structs and functions, but Golang won&#x27;t allow package import cycles. If you need &lt;code&gt;prediction_log&lt;&#x2F;code&gt; protos, you can manually move &lt;code&gt;&#x2F;core&lt;&#x2F;code&gt; into &lt;code&gt;&#x2F;apis&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;tf-serving-client-over-grpc&quot;&gt;TF Serving Client over GRPC&lt;&#x2F;h3&gt;
&lt;p&gt;A link to a executable script &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;blob&#x2F;master&#x2F;client.go&quot;&gt;here&lt;&#x2F;a&gt;. &lt;code&gt;cd&lt;&#x2F;code&gt; into the repository directory and execute with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;export GOPATH=$GOPATH:$PWD &amp;amp;&amp;amp; go run client.go
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If no TF Serving Server is running at &lt;code&gt;localhost:9000&lt;&#x2F;code&gt;, then you&#x27;ll get the following error;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;rpc error: code = Unavailable desc = connection error: desc = &amp;quot;transport: Error while dialing dial tcp [::1]:9000: connect: connection refused&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here&#x27;s a snippet of the script that fetches the model metadata, given the name of the model. In production, you should use a connection pool.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span&gt;modelURL &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;localhost:9000&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;modelMetadataRequest &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;tfServing&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;GetModelMetadataRequest&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;ModelSpec&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;tfServing&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;ModelSpec&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;Name&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;model&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;  },
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;MetadataField&lt;&#x2F;span&gt;&lt;span&gt;: []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;string&lt;&#x2F;span&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;signature_def&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;},
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;conn, err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Dial&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;modelURL&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;grpc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;WithInsecure&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;log&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Fatalf&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Error&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;client &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;tfServing&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;NewPredictionServiceClient&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;conn&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;metadata, err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;client&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;GetModelMetadata&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;context&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Background&lt;&#x2F;span&gt;&lt;span&gt;(), &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;modelMetadataRequest&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;log&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Fatalf&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Error&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;fmt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Println&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;metadata&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A thing about gRPC over Go is that you always send slices. If you want to send a 2D slice of integers, you need to flatten the slice and specify the dimensions in the request, and gRPC will validate that a slice of the correct length was sent. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;blob&#x2F;master&#x2F;client.go#L48&quot;&gt;A link to the script again&lt;&#x2F;a&gt;, and two functions to copypasta:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int64Flatten&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;slisli &lt;&#x2F;span&gt;&lt;span&gt;[][]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int64&lt;&#x2F;span&gt;&lt;span&gt;) []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int64 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;	flattened &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int64&lt;&#x2F;span&gt;&lt;span&gt;{}
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, sli &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= range &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;slisli &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;sli&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int32Flatten&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;slisli &lt;&#x2F;span&gt;&lt;span&gt;[][]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int32&lt;&#x2F;span&gt;&lt;span&gt;) []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int32 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;	flattened &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int32&lt;&#x2F;span&gt;&lt;span&gt;{}
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, sli &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= range &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;slisli &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;append&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;sli&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flattened
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;tfrecord-example-read-write&quot;&gt;TFRecord Example Read+Write&lt;&#x2F;h3&gt;
&lt;p&gt;Link to executable script &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;blob&#x2F;master&#x2F;tfrecords.go&quot;&gt;here&lt;&#x2F;a&gt;. &lt;code&gt;cd&lt;&#x2F;code&gt; into the directory and execute with:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;go&lt;&#x2F;span&gt;&lt;span&gt; run tfrecords.go
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The output should be;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;[1 2 3 4 5] hello [0.1 0.2 0.3 0.4 0.5]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here is the part of the script that&#x27;s needed for read+write!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensorflow&#x2F;blob&#x2F;051a96f3ec4fc38b248e8ae8ad2f8ad124eda59b&#x2F;tensorflow&#x2F;core&#x2F;lib&#x2F;hash&#x2F;crc32c.h
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;const &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;maskDelta &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0xa282ead8
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensorflow&#x2F;blob&#x2F;051a96f3ec4fc38b248e8ae8ad2f8ad124eda59b&#x2F;tensorflow&#x2F;core&#x2F;lib&#x2F;hash&#x2F;crc32c.h#L53-L56
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mask&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;crc &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;((&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;| &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;17&lt;&#x2F;span&gt;&lt;span&gt;)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;maskDelta
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;var &lt;&#x2F;span&gt;&lt;span&gt;crc32Table &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;MakeTable&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;Castagnoli&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;crc32Hash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;data &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Checksum&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;crc32Table&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;uint64ToBytes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint64&lt;&#x2F;span&gt;&lt;span&gt;) []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;	b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;8&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;PutUint64&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Write&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;w &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;io&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;Writer&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;data &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;) (&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;error&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; Write based on format specified in https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensorflow&#x2F;blob&#x2F;051a96f3ec4fc38b248e8ae8ad2f8ad124eda59b&#x2F;tensorflow&#x2F;core&#x2F;lib&#x2F;io&#x2F;record_writer.cc#L124-L128
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F;  uint64    length
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F;  uint32    masked crc of length
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F;  byte      data[length]
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F;  uint32    masked crc of data
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	length &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint64&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;	lengthCRC &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mask&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;crc32Hash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;uint64ToBytes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint64&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;)))))
&lt;&#x2F;span&gt;&lt;span&gt;	dataCRC &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mask&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;crc32Hash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Write&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;length&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Write&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;lengthCRC&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Write&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Write&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;dataCRC&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Size&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;dataCRC&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Size&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;length&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Size&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;lengthCRC&lt;&#x2F;span&gt;&lt;span&gt;), &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;io&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;Reader&lt;&#x2F;span&gt;&lt;span&gt;) (&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;data &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;error&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;var &lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;		length         &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint64
&lt;&#x2F;span&gt;&lt;span&gt;		lengthChecksum &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32
&lt;&#x2F;span&gt;&lt;span&gt;		dataChecksum   &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint32
&lt;&#x2F;span&gt;&lt;span&gt;	)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; get data length
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;r&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;length&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; get length checksum
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;r&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;lengthChecksum&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; get data
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;length&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;r&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; get data checksum
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;r&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;binary&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;LittleEndian&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;dataChecksum&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;err
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; check checksum length
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;actual &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mask&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;crc32Hash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;uint64ToBytes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;length&lt;&#x2F;span&gt;&lt;span&gt;))); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;actual &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;lengthChecksum &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;errors&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;New&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;corrupted record, length checksum doesn&amp;#39;t match&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; check data checksum
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;actual &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;mask&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;crc32Hash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;)); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;actual &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;dataChecksum &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;		&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;errors&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;New&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;corrupted record, data checksum doesn&amp;#39;t match&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;	}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;	&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;data&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;nil
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The code that writes tf.Train.Examples is &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kipply&#x2F;tf-go-examples&#x2F;blob&#x2F;master&#x2F;tfrecords.go&quot;&gt;here&lt;&#x2F;a&gt;, and uses the Example proto compiled in the previous step.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I&#x27;d like this to be good for Sea Eel Orbit, so in this post you have learned how to read and write Tensorflow Records in Golang and how to communicate with a Tensorflow Serving gRPC server with Golang. It also includes compiling Tensorflow and Tensorflow Serving protobufs.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Reading Log | January 2021</title>
		<published>2021-02-02T00:00:00+00:00</published>
		<updated>2021-02-02T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jan-2021/"/>
		<link rel="alternate" href="https://kipp.ly/jan-2021/" type="text/html"/>
		<id>https://kipp.ly/jan-2021/</id>
		<content type="html">&lt;p&gt;This is my first reading log! I put down links to most of the things I read every month. All of these are &amp;quot;recommended&amp;quot; to some extent, since that&#x27;s the reason I chose to finish reading them. This month is slightly incomplete since I only came up with this recently. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;misc&quot;&gt;Misc&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;http:&#x2F;&#x2F;web.mit.edu&#x2F;6.055&#x2F;old&#x2F;S2009&#x2F;notes&#x2F;jump-heights.pdf&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;evanjconrad.com&#x2F;posts&#x2F;moral-competence&quot;&gt;Moral Competence | Evan Conrad&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;alexdanco.com&#x2F;2021&#x2F;01&#x2F;22&#x2F;the-michael-scott-theory-of-social-class&#x2F;&quot;&gt;The Michael Scott Theory of Social Class ‚Äì alexdanco.com&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;astralcodexten.substack.com&#x2F;p&#x2F;still-alive&quot;&gt;Still Alive - Astral Codex Ten&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;evanjconrad.com&#x2F;posts&#x2F;how-to-feel-good&quot;&gt;How to feel good | Evan Conrad&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Every day of &lt;a href=&quot;https:&#x2F;&#x2F;www.bloomberg.com&#x2F;opinion&#x2F;authors&#x2F;ARbTQlRLRjE&#x2F;matthew-s-levine&quot;&gt;Money Stuff&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;80000hours.org&#x2F;2015&#x2F;07&#x2F;80000-hours-thinks-that-only-a-small-proportion-of-people-should-earn-to-give-long-term&#x2F;&quot;&gt;80,000 Hours thinks that only a small proportion of people should earn to give long term - 80,000 Hours&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;programming&quot;&gt;Programming&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;jit_language_reference.html#language-reference&quot;&gt;TorchScript Language Reference ‚Äî PyTorch 1.7.0 documentation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;fasterthanli.me&#x2F;articles&#x2F;a-half-hour-to-learn-rust&quot;&gt;A half-hour to learn Rust - fasterthanli.me&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;surma.dev&#x2F;things&#x2F;ditherpunk&#x2F;&quot;&gt;Ditherpunk ‚Äî The article I wish I had about monochrome image dithering ‚Äî surma.dev&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.blog&#x2F;2020-12-21-how-we-built-the-github-globe&#x2F;&quot;&gt;How we built the GitHub globe - The GitHub Blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.jamesgolick.com&#x2F;2013&#x2F;5&#x2F;19&#x2F;how-tcmalloc-works.html&quot;&gt;How tcmalloc Works | James Golick&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jalammar.github.io&#x2F;explaining-transformers&#x2F;&quot;&gt;Interfaces for Explaining Transformer Language Models ‚Äì Jay Alammar ‚Äì Visualizing machine learning one concept at a time.&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.ioccc.org&#x2F;2020&#x2F;carlini&#x2F;index.html&quot;&gt;Best of show - abuse of libc&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;medium.com&#x2F;tensorflow&#x2F;pushing-the-limits-of-gpu-performance-with-xla-53559db8e473&quot;&gt;Pushing the limits of GPU performance with XLA | by TensorFlow | TensorFlow | Medium&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kAOanJczHA0&quot;&gt;XLA: TensorFlow, Compiled! (TensorFlow Dev Summit 2017) - YouTube&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;dex-lang&quot;&gt;GitHub - google-research&#x2F;dex-lang: Research language for array processing in the Haskell&#x2F;ML family&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;deepmind&#x2F;dm-haiku&quot;&gt;GitHub - deepmind&#x2F;dm-haiku: JAX-based neural network library&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;www.furidamu.org&#x2F;blog&#x2F;2020&#x2F;12&#x2F;22&#x2F;muzero-intuition&#x2F;&quot;&gt;MuZero Intuition&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;djharper.dev&#x2F;post&#x2F;2020&#x2F;12&#x2F;26&#x2F;executable-pngs&#x2F;&quot;&gt;Executable PNGs - djhworld&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;llvm.org&#x2F;docs&#x2F;Vectorizers.html&quot;&gt;Auto-Vectorization in LLVM ‚Äî LLVM 12 documentation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jax.readthedocs.io&#x2F;en&#x2F;latest&#x2F;notebooks&#x2F;Common_Gotchas_in_JAX.html&quot;&gt;√∞¬ü¬î¬™ JAX - The Sharp Bits √∞¬ü¬î¬™ ‚Äî JAX  documentation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;www.plymouth.ac.uk&#x2F;uploads&#x2F;production&#x2F;document&#x2F;path&#x2F;3&#x2F;3742&#x2F;PlymouthUniversity_MathsandStats_gradients_and_directional_deriavatives.pdf&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;colinraffel.com&#x2F;blog&#x2F;you-don-t-know-jax.html&quot;&gt;You don&#x27;t know JAX&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;tech-but-not-programming&quot;&gt;Tech, but not Programming&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;apenwarr.ca&#x2F;log&#x2F;20201227&quot;&gt;Systems design explains the world: volume 1 - apenwarr&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;apenwarr.ca&#x2F;log&#x2F;20140701&quot;&gt;The Curse of Smart People - apenwarr&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;lemire.me&#x2F;blog&#x2F;2021&#x2F;01&#x2F;01&#x2F;peer-reviewed-papers-are-getting-increasingly-boring&#x2F;&quot;&gt;Peer-reviewed papers are getting increasingly boring ‚Äì Daniel Lemire&#x27;s blog&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;blog.nelhage.com&#x2F;post&#x2F;computers-can-be-understood&#x2F;&quot;&gt;Computers can be understood - Made of Bugs&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>You can&#x27;t be &quot;not good enough&quot; to skip (or drop out of) college</title>
		<published>2020-12-19T00:00:00+00:00</published>
		<updated>2020-12-19T00:00:00+00:00</updated>
		<link href="https://kipp.ly/no-not-good-enough/"/>
		<link rel="alternate" href="https://kipp.ly/no-not-good-enough/" type="text/html"/>
		<id>https://kipp.ly/no-not-good-enough/</id>
		<content type="html">&lt;blockquote&gt;
&lt;p&gt;Some personal context context to this! The narrative people often read off me is that I started working as a programmer in high school, and could make a good living doing that and school would only slow me down. This is surface level true, but it certainly wasn&#x27;t because I was too achieved for school but strictly because school was never going to work out for me. I was a below average high school student and the only college that accepted me (the first time I applied) was a small school in Ottawa. I think a version of me who is some combination of more passionate of pursuit of knowledge, less ADHD or just smarter could&#x27;ve been better off in school.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;This is a pro-not-going-to-college post in the context of people around the tech industry. It is mostly for people who are entertaining no-college as something that might be good for them. It is not about why or if dropping out is a good idea, and more to air out the idea that not going to school requires some level of skill -- a notion probably brought forth by prolific dropouts and some reasonable sense that school is useful and so to not go you&#x27;d have to overcome it and then some.&lt;&#x2F;p&gt;
&lt;p&gt;Most messaging with not going to school along the lines of &amp;quot;there are more important things to work on&amp;quot;, &amp;quot;you can learn faster outside of school&amp;quot;, &amp;quot;why wait for a degree when you can start working now&amp;quot;, or &amp;quot;you could be running a kickass startup instead&amp;quot;. All of these are great reasons to not go to school, but they have an implication that you have to be skilled to a certain degree (haha, &amp;quot;degree&amp;quot;). Good enough to have the opportunities to work on more important things. Good enough that school isn&#x27;t already challenging your learning. Good enough to get a job. Good enough to run a startup.&lt;&#x2F;p&gt;
&lt;p&gt;Most of my conversations with people who are interested in the concept of not going to school have implied that not being good enough is a blocker. Of course, there are other overlapping blockers related to fear, money, privilege, or it simply not being a good choice for your priorities, but I think &amp;quot;not being good enough&amp;quot; is wholy surmountable (provided you&#x27;re accurately evaluating your own abilities).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;doing-the-things-no-one-else-has-had-the-chance-to-do&quot;&gt;Doing the things no one else has had the chance to do&lt;&#x2F;h3&gt;
&lt;p&gt;I model ambition&#x2F;excellence as a spectrum. One end is &amp;quot;getting ahead&amp;quot; and the other end is &amp;quot;getting a bonus&amp;quot;. Canonical &amp;quot;getting ahead&amp;quot; would be graduating early, getting promoted quickly and rising to the top of your org in record time. It&#x27;s hard to describe what &amp;quot;getting a bonus&amp;quot; might be like since it&#x27;s by nature dependent on things one might not expect to have done. It can be summarized as &amp;quot;doing the things no one else has had the chance to do&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;This is a wavy spectrum, and the range shrinks and ambiguities increase when you apply it to any individual. Regardless, I contend that &amp;quot;getting a bonus mentality&amp;quot; helps make it such that one can&#x27;t be &amp;quot;not good enough&amp;quot; to skip college.&lt;&#x2F;p&gt;
&lt;p&gt;While they&#x27;re two ends of a spectrum, I think few would argue that both approaches can lead to excellence, success, ambition, or whatever it is you want for yourself. However, with &amp;quot;getting a bonus&amp;quot;, there is much less &amp;quot;not good enough&amp;quot; barrier. Instead of getting a job at Google after dropping out, you can work on a side project, take the time to pursue another career path, work at a non-profit or train to climb Mount Everest.&lt;&#x2F;p&gt;
&lt;p&gt;In my first year not going to school, I learned to juggle, taught programming bootcamp and suprised myself by moving to a &amp;quot;city&amp;quot; with less than a million people for my first experience living away from home. The time I saved allowed me to further pursue an interests in the arts I found too late because I was obsessed with getting internships in high school and gave me flexibility to travel. With the money I saved (and employment) I was able to donate over 25% of my pretax income.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Becoming an adult means access to many more measures of success.&lt;&#x2F;strong&gt; It&#x27;s often the sense for students that not that many things can measure success. Leaving school gave me so many more successes to seek than academic performance, number of skills and resume lines.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;falling-behind&quot;&gt;Falling behind&lt;&#x2F;h3&gt;
&lt;p&gt;If &amp;quot;getting a bonus&amp;quot; is the opposite of &amp;quot;getting ahead&amp;quot;, then certainly that means you fall behind right? Perhaps! But you will have earned four years of doing things that no one else will have had. Given tech, you won&#x27;t be a full-four years behind in your career, though it&#x27;s possible you won&#x27;t be as well off as you would be if you had gone to school. Additionally, I think that not being in school often helps accelerate your &amp;quot;goodness&amp;quot;, though that&#x27;s a separate &amp;quot;why get out of school&amp;quot; post.&lt;&#x2F;p&gt;
&lt;p&gt;Not going to college definitely put me behind in a lot of things. When working on TruffleRuby at Shopify I got burned by not having taking an Operating Systems or Concurrency course. Not having a degree put me in a very difficult spot in immigrating anywhere (I&#x27;m Canadian though got a US visa, but hadn&#x27;t at the time this was published). It takes out the character I would have built struggling through courseloads (I was not good at school, and it&#x27;s unfortunate I may never be able to correct that). It certainly cuts down some my job opportunities.&lt;&#x2F;p&gt;
&lt;p&gt;So yeah, falling behind is a thing. One path is to just accept it with the other less-measurable experiences you have achieved, another is to convince yourself that it&#x27;s not quite as real as one might think.&lt;&#x2F;p&gt;
&lt;p&gt;Once you get out of school, the number of different axes on which you can succeed grows quickly. Some may end up caring only about their salary, others on their social lives, others on their ability to start a family. It gets drastically harder to compare who is more successful, if you were even worried about that in the first place. The farther I get away from the school-scene the more apparent it is that I am not behind on valuable experiences. Without counting the years of school and exams rolling around every semester, the concept of being &amp;quot;behind&amp;quot; becomes much less real.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;joy-affects-your-success&quot;&gt;Joy affects your success&lt;&#x2F;h3&gt;
&lt;p&gt;I wish I could point to some source here, but hopefully you already believe me a bit? If you enjoy your work, you can be better at it. That means that if you think you&#x27;re good at school and not that great at having a job, but also you hate school - you might have a better chance than you think.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;If you are interested in not going to school, then the much harder question is what on earth to do. I don&#x27;t have many coherent thoughts about this that is suitable as general advice, but if you want to email me at email@kipp.ly we can chat~&lt;&#x2F;p&gt;
&lt;p&gt;&amp;lt;3,
Kipply&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Iconic Images Programmers Happen to Know</title>
		<published>2020-11-30T00:00:00+00:00</published>
		<updated>2020-11-30T00:00:00+00:00</updated>
		<link href="https://kipp.ly/iconic-computer-science-images/"/>
		<link rel="alternate" href="https://kipp.ly/iconic-computer-science-images/" type="text/html"/>
		<id>https://kipp.ly/iconic-computer-science-images/</id>
		<content type="html">&lt;p&gt;Over the years I&#x27;ve noticed some images (not diagrams or graphs) that are recognizable to programmers. These images also often have backstories that contain educational information, so here they are!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;lena&quot;&gt;Lena&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;lena.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Lena is a Swedish model and this photo of her is from a Playboy cover. Her name is sometimes spelled &amp;quot;Lenna&amp;quot; to encourage her name to be pronounced as &amp;quot;leh-nah&amp;quot; instead of &amp;quot;lee-nah&amp;quot;, which is a mildly amusing parallel to classification tasks. The full image has her mostly nude.&lt;&#x2F;p&gt;
&lt;p&gt;The photo was first used six months after release in 1972 because of the mixture of textures and colours for testing an image compression algorithm. This eventually led to JPEGs (first released 1992). It&#x27;s was standard to use the image to showcase differences between image compression algorithms .&lt;&#x2F;p&gt;
&lt;p&gt;For obvious reasons, having a nude model be the face of all image processing has raised concerns. Still there are blog posts, papers and websites that still use Lena for image processing, though recently it&#x27;s been about computer vision, style transfer, etc.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-cornell-box&quot;&gt;The Cornell Box&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;cornellbox.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Anyone who has taken a graphics course has seen this box as it was first presented at a SIGGRAPH in 1984. It consists of five planes, an overhead light, a rectangular prism and cube. Variations are often seen with spheres of different materials such as dielectrics (glass), and metals instead of lambertians (the matte texture).&lt;&#x2F;p&gt;
&lt;p&gt;For a raytracer (or pathtracer) this tests a lot of important features. The shadowing of the rectangle onto the wall, contrasting wall colours that should emit some colour onto the white (this is called diffuse reflection).&lt;&#x2F;p&gt;
&lt;p&gt;As shown below, it can also showcase (or rather, suffer from) tone mapping, which is a technique used to map a set of colours to another to make the range look &amp;quot;dynamic&amp;quot; or at least correct. The image below has a bug where the lack of tonemapping causes the image to bug out where it tries to make the colour brighter than a pure white pixel.&lt;&#x2F;p&gt;
&lt;p&gt;Another issue with the image below is the noise, which can be fixed by more sampling in this specific case as it&#x27;s a monte carlo ray tracer, so it uses some brute force and randomization as computers can&#x27;t actually simulate light going in infinite directions.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;badtracer.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Other classic rendering images include the Stanford bunny and the Utah teapot. It&#x27;s been a meme to hide the Utah teapot into random scenes, and the teapot is the graphics version of &amp;quot;Hello World&amp;quot;. It appears in Toy Story, the Simpsons, a Windows screensaver, and the Sims. Here&#x27;s a &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=TIxt9guMbXo&quot;&gt;2.5 minute video about the teapot from Tom Scott&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;bunny.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;utahteapost.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-big-red-mobile&quot;&gt;The Big Red Mobile&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;bigred.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;CLRS! The iconic graphic on the textbook is obviously representative of a tree, but it&#x27;s actually based on a piece of art. It was made by Alexander Calder in 1959. If you don&#x27;t already know about mobiles, they&#x27;re really cool, carefully engineered to work with equilibrium and air currents. Big Red, made from sheet metal and steel weird, can be found at the Whitney Museum of American Art!&lt;&#x2F;p&gt;
&lt;p&gt;Fun fact, Cormen (the C in CLRS) and co wanted to recolour the depiction to use red and black, but the Calder estate would not allow it. You can also purchase &lt;a href=&quot;https:&#x2F;&#x2F;www.hangingmobilegallery.com&#x2F;big-red-mobile&#x2F;&quot;&gt;similar versions of the mobile&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-dragon-book-cover&quot;&gt;The Dragon Book Cover&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;dragon.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This popular compilers textbook is often referred to as the &amp;quot;Dragon Book&amp;quot; because of the üêâ.The Dragon&#x27;s shirt says &amp;quot;Complexity of Compiler Design&amp;quot;, the shield says &amp;quot;Syntax Directed Translation&amp;quot; and the sword says &amp;quot;LALR Parser Generator&amp;quot;. The older edition also has the knight riding a horse labeled &amp;quot;Data Flow Analysis&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;greendragon.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;syntax-directed-translation&quot;&gt;Syntax Directed Translation&lt;&#x2F;h4&gt;
&lt;p&gt;The shield describes a method where the compilation is guided by the parser, and describes a more simpler subset of compilers. Syntax directed translation is a method of implementation used on context-free grammars (there&#x27;s a whole linguistics thing behind this, but it&#x27;s mostly what it sounds like) as a Type 3 language (on the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chomsky_hierarchy#Type-2_grammars&quot;&gt;Chomsky Heirarchy&lt;&#x2F;a&gt;) could not be driven by the parser. There aren&#x27;t too many commonly used languages that would be described as completely context free though there are languages that only have small caveats to become CFGs (not to be confused with control flow graphs, another compilers concept). If you want to read more, this &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;14589346&#x2F;is-c-context-free-or-context-sensitive&quot;&gt;Stack Overflow question&lt;&#x2F;a&gt; is a good start.&lt;&#x2F;p&gt;
&lt;p&gt;Anywho, this is likely the shield because it prevents any blurring of &amp;quot;execution&amp;quot; and &amp;quot;compilation&amp;quot; by not having any ambiguities embedded in the grammar.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;lalr-parser-generator&quot;&gt;LALR Parser generator&lt;&#x2F;h4&gt;
&lt;p&gt;LALR is a type of parser (look ahead left to right) that is simpler than an LR parser (left to right, rightmost derivation) but more powerful than LL parsers (left to right, leftmost derivation). Parser generators greatly improve the pains of writing a parser. GCC started off with a parser generated (it&#x27;s handwritten as of 2004), CPython makes their own LL* parser generator (*it&#x27;s a bit variant, CPython devs may correct me), Haskell+OCaml+Ruby are on LALR generators.&lt;&#x2F;p&gt;
&lt;p&gt;Writing a nice parser that works, is fast &lt;em&gt;and&lt;&#x2F;em&gt; surfaces nice syntax errors is a difficult design task, and a bit tedious after designed! Hence the dragon will be slayed by a LALR parser generator (YACC is taught in the book).&lt;&#x2F;p&gt;
&lt;h4 id=&quot;data-flow-analysis&quot;&gt;Data Flow Analysis&lt;&#x2F;h4&gt;
&lt;p&gt;Data flow analysis is what it sounds like, tracking the movement of variables or other stored memory through a program. It is represented as the horse the knight is riding probably because it powers most things. I tried to think of why it might be removed from the cover, but there&#x27;s no obvious answer and everything I came up with just sounded like a conspiracy theory.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;o-reilly-animals&quot;&gt;O&#x27;Reilly Animals&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;animals.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Iconic meme-able book covers! But who draws them? Who picks the animals when the book is not just called Python? Why are they pictures of animals?&lt;&#x2F;p&gt;
&lt;p&gt;O&#x27;Reilly claims that this originated in the weirdness of Unix terms like awk, sed and yacc, and really the rest of it was &amp;quot;it just clicked&amp;quot;. Many of them were drawn by one Lorrie LeJeune, and were done with pen and paper! There are also amusing stories of complaints from the arachnephobic who had to deal with spiders on covers. You can find a list of all the books and animals &lt;a href=&quot;https:&#x2F;&#x2F;www.oreilly.com&#x2F;animals.csp&quot;&gt;here&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Edie Freedman, the creative director who saw over this claimed that there&#x27;s meaning to how all the animals that were selected though they aren&#x27;t revealed. But here are some of the answers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;the-obvious-ones&quot;&gt;The Obvious Ones&lt;&#x2F;h4&gt;
&lt;p&gt;Many (but not all) of the Python books have snakes, Rust has a crab, OCaml has a Camel, GNU has a gnu.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;oracle-bugs&quot;&gt;Oracle Bugs&lt;&#x2F;h4&gt;
&lt;p&gt;&amp;quot;Oracle Essentials&amp;quot; has a cicada, &amp;quot;Oracle Regular Expressions&amp;quot; have spiders, &amp;quot;Oracle 8i Internal Services&amp;quot; has a bumblebee, dragonfly, dung beetle, lady bug, lantern fly, leaf insect, ants, praying mantis, etc. &lt;em&gt;Very&lt;&#x2F;em&gt; consistently bugs. The speculation is often &amp;quot;oracle software bad&amp;quot; but its likely just a meaningless theme (with each animal having a deep meaning) and not meant to piss off Oracle. It is special as even Python is not consistently snakes, and other groups of books like Google, Regular Expressions, Javascript, etc, do not have any themes.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;perl-camel&quot;&gt;Perl Camel&lt;&#x2F;h4&gt;
&lt;p&gt;Here&#x27;s a weird one, as the obvious choice would be an oyster for the pearl. &lt;a href=&quot;https:&#x2F;&#x2F;www.wsj.com&#x2F;articles&#x2F;SB870061922836237000&quot;&gt;Wall Street Journal claims&lt;&#x2F;a&gt; that Larry Wall, creator of the language, wanted a camel because like Perl it&#x27;s ugly but can go a long way without water. Some also claim it&#x27;s a reference to the proverb &amp;quot;a camel is a horse designed by a committee&amp;quot; and how Perl is easily identifiable as a mixture of other languages. It&#x27;s cool as the camel as adopted as Perl&#x27;s mascot after the O&#x27;Reilly book.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;python-entirely-my-conspiracy&quot;&gt;Python (entirely my conspiracy)&lt;&#x2F;h4&gt;
&lt;p&gt;Not all of the Python books have snakes! &amp;quot;Data Wrangling with Python&amp;quot; has a lizard, which seems to be a reference to giving Python &amp;quot;legs&amp;quot; to work with data. &amp;quot;Python Programming On Win32&amp;quot; is a crocdile, which to me just screams &amp;quot;PYTHON BUT MAKE IT SCARY&amp;quot;. &amp;quot;Learning Python&amp;quot; is a rat and &amp;quot;Python Coobook&amp;quot; is a rabbit, which may be a reference to them being more introductory Python books as they&#x27;re snake food.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;macos-powder-explosion-wallpaper&quot;&gt;MacOS Powder Explosion Wallpaper&lt;&#x2F;h3&gt;
&lt;p&gt;MacOS has always had some iconic wallpapers, especially of California views so this one stood out to me as &amp;quot;this should be generated&amp;quot;. This isn&#x27;t related to programming but I thought I&#x27;d investigate it since I&#x27;ve always wanted to know.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;explosion.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Apple explicitly scrubs EXIF data, which is all that microchip tracking metadata that are automatically attached to your images for location, time, device, shutter speeds, etc. The one time the EXIF was leaked on one image it had a bunch of nitpicking notes like &amp;quot;fill in this area close to the edge with more tree so it doesn‚Äôt create awkward negative shapes&amp;quot; and &amp;quot;darken some of the stars that are a bit smaller and darker, so there is a little more difference in the starfield&amp;quot; which I guess could be expected for the quality of the Apple wallpapers and the anxiety that comes with being the photographer for a MacOS wallpaper.&lt;&#x2F;p&gt;
&lt;p&gt;Spoiler alert, I didn&#x27;t actually figure out if these were generated or photographed, but I did figure out &lt;em&gt;how&lt;&#x2F;em&gt; one would generate&#x2F;photograph them, and that they are &lt;em&gt;very&lt;&#x2F;em&gt; probably photographed. Here is the precedence: photographed ethereal Apple productions.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;cs_images&#x2F;applefancy.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-to-photograph&quot;&gt;How to Photograph&lt;&#x2F;h4&gt;
&lt;p&gt;As expected, making these powder explosions would be a pain. One must first have the space, the high speed camera (powder flying through the air like that lasts less than a second) and cover all of the equipment. The powder is typically flour, and mixed with &amp;quot;holi&amp;quot; powder which is just high pigment powder for photoshoots&#x2F;parties&#x2F;crafts. It seems that many photographers actually have people in suits to throw the powder and those shots tend to look more like powder clouds than explosions. I found someone who did something a bit more clever, which involves a simple canon mechanism (silicon tubing and a pump) and sound triggered.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-to-render&quot;&gt;How to Render&lt;&#x2F;h4&gt;
&lt;p&gt;3D animation software of course would also enable you to do this, and in my opinion produces better results.&lt;&#x2F;p&gt;
&lt;p&gt;The general approach is to start with a sphere, create some noise outwards like a spiky ball. Turn those vectors into dots going out, then configure those dots to create more particles in the direction of the velocity. Wind and air drag simulations are built into most animation software.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;end&quot;&gt;End&lt;&#x2F;h3&gt;
&lt;p&gt;Have a nice day &amp;lt;3&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Escape! From the Allocations: Escape Analysis in Pypy, LuaJIT, V8, C++, Go and More</title>
		<published>2020-10-12T00:00:00+00:00</published>
		<updated>2020-10-12T00:00:00+00:00</updated>
		<link href="https://kipp.ly/escape-analysis/"/>
		<link rel="alternate" href="https://kipp.ly/escape-analysis/" type="text/html"/>
		<id>https://kipp.ly/escape-analysis/</id>
		<content type="html">&lt;p&gt;With software engineering, speed and memory are the basic measurement-benchmarks. For programming language implementations, the two are heavily involved with each other. In JIT compilers, that means storing more things in memory to speed up the program drastically. It also means putting time into garbage collection to keep memory down, spending time to try to eliminate allocations and deciding where to put some piece of data.&lt;&#x2F;p&gt;
&lt;p&gt;Escape Analysis is a technique that determines the behaviour of how a variable (more specifically, a pointer) is used in a certain scope, and whether it not it escapes that scope (the scope is usually a function). Escape analysis allows the program to stack allocate (here is an article on &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;79923&#x2F;what-and-where-are-the-stack-and-heap&#x2F;80113#80113&quot;&gt;Stack vs Heap &lt;&#x2F;a&gt;allocations) when it&#x27;s determined the variable will not be used outside of the scope or in other cases, try to eliminate the allocation completely.
&amp;gt;
For a little background on how programming languages work, skim through my post &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;jits-intro&quot;&gt;A Deep Introduction to JIT Compilers: JITs are not very Just-in-time&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;pypy-escapes-boxing&quot;&gt;Pypy Escapes Boxing&lt;&#x2F;h3&gt;
&lt;p&gt;Pypy puts a lot of work into minimizing &lt;em&gt;boxing&lt;&#x2F;em&gt;, which is done through escape analysis. Boxing is when a primitive is boxed into an object wrapper type, such as an &lt;code&gt;int&lt;&#x2F;code&gt; to &lt;code&gt;Integer&lt;&#x2F;code&gt; in Java. Object oriented language implementations often utilize boxing (sometimes called auto-boxing), including JavaScript, C#, Haskell and others! Computers natively understands types like booleans and integers, but not objects, and unfortunately many languages need to store most of their data as an object and not the primitive. For example, &lt;code&gt;314&lt;&#x2F;code&gt; as a constant can be stored as a primitive on the stack, but when &lt;code&gt;314.toString()&lt;&#x2F;code&gt; is executed, &lt;code&gt;314&lt;&#x2F;code&gt; has to be boxed so that the method can be run on the object. Unboxing is performed to extract the value.&lt;&#x2F;p&gt;
&lt;p&gt;Boxing and unboxing is an expensive operation, with .NET citing 20x the time for boxed assignment and 4x the time for unboxing assignment (when you explicitly cast back). Pypy also has expensive boxing operations, as it&#x27;s not just assigning&#x2F;computing more values but organizing them into a heap structure.&lt;&#x2F;p&gt;
&lt;p&gt;Pypy considers this to be its second most important problem, and uses &amp;quot;virtual objects&amp;quot;, also called virtualisation. It&#x27;s a fancy term that means they avoid creating the entire heap structure, store the primitive value (not on the heap) and mock any object-operations that need to happen. While the virtual object is used in some applicable scope, read and writes are done to the virtual object without the expense of boxing&#x2F;unboxing. Even more computation is saved as since the virtual object exists and no guards need to exist to verify information about the value in the object, whereas guards are usually in place to check the class after loading a value.&lt;&#x2F;p&gt;
&lt;p&gt;Pypy will virtualise onto the stack optimistically and then allocate later should it become necssary. Escape analysis is really powerful in JITs mostly because jitted langauges tend to be more dynamic, but also because they can very aggressively stack allocate. Languages that compile once have to be completely confident that the escape analysis is valid (or also compile code in case of failure) &lt;em&gt;and&lt;&#x2F;em&gt; make decisions about how far it should look to determine a scope. JITs can kind of just hope it&#x27;ll work and then actually do the allocation if it doesn&#x27;t -- and remember what happened for next time (though that makes it sound a lot easier than it actually is).&lt;&#x2F;p&gt;
&lt;p&gt;For example;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;10000&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# Integer.random() is not an actual stdlib operation in Python, I used it to indicate a non-primitive object is created
&lt;&#x2F;span&gt;&lt;span&gt;  y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;Integer&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;random&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;x
&lt;&#x2F;span&gt;&lt;span&gt;  x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+= &lt;&#x2F;span&gt;&lt;span&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# this would also involves boxing without escape analysis, since operators are implemented as methods
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(x)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There are two cases of virtualisation here. The first is &lt;code&gt;y&lt;&#x2F;code&gt;, which will be virtualised as it does not escape. Thus in the second line of the loop, Pypy would no longer need a guard for the value of &lt;code&gt;y&lt;&#x2F;code&gt;. This saves us a lot more than just constructing and traversing the heap structure. When boxed, Pypy has to check the class types of &lt;code&gt;y&lt;&#x2F;code&gt; and &lt;code&gt;x&lt;&#x2F;code&gt; due to the dynamic-ness of Python -- can these values be added? If they can, where is the method to describe how they are added (Python allows operator overloading)? It also has to recreate a boxed object to reassign to &lt;code&gt;y&lt;&#x2F;code&gt; and in more complex cases could leave behind additional garbage for the GC.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;x&lt;&#x2F;code&gt; on the other hand, does escape, but it&#x27;s still valuable to virtualise it, for that allocation is in a loop and the escape is outside the loop. When a jump instruction comes in (loop ends), it‚Äôll come with code that actually allocates &lt;code&gt;x&lt;&#x2F;code&gt; for the garbage collector and future use. Another case of escape analysis can be found in methods;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;font-style:italic;color:#ff79c6;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;():
&lt;&#x2F;span&gt;&lt;span&gt;  x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;A&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;B&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;x[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;A&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this case, &lt;code&gt;x&lt;&#x2F;code&gt; will likely never escape and the allocation isn&#x27;t even needed to execute the rest of the function. This particular case may actually be constant-folded away (the constant is replicated at usage sites), but abstractions of this pattern will use escape analysis. Escape analysis also often takes place for language-internal operations, and I&#x27;ll describe how Javascript features and internals makes escape analysis very important.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-javascript-uses-escape-analysis-in-language-internals&quot;&gt;How Javascript Uses Escape Analysis in Language Internals&lt;&#x2F;h3&gt;
&lt;p&gt;The most complex question about escape analysis (other than maybe &amp;quot;how do I implement it&amp;quot;) is probably &amp;quot;is this only beneficial to very shortlived variables, and if so how does it help much?&amp;quot;. As mentioned in the Pypy example, it is sometimes to protect your program from allocations that are made by the language implementation rather than the programmer. Here&#x27;s a quick example in Javascript (example taken from &lt;a href=&quot;https:&#x2F;&#x2F;www.jfokus.se&#x2F;jfokus18&#x2F;preso&#x2F;Escape-Analysis-in-V8.pdf&quot;&gt;this PDF&lt;&#x2F;a&gt;, which has a &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KiWEWLwQ3oI&quot;&gt;corresponding talk&lt;&#x2F;a&gt; that might be elementary at this point in the blog post).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;javascript&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-javascript &quot;&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;bar&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;o&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6be5fd;&quot;&gt;Math&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;sqrt&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;o&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;o&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;o&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;o&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;y);
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;bar&lt;&#x2F;span&gt;&lt;span&gt;({ x: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span&gt;, y: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span&gt;});
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;One might not expect anything to allocate even without escape analysis, but when you create the object to pass into &lt;code&gt;bar&lt;&#x2F;code&gt; it is created and allocated by default since it now exists for &lt;code&gt;bar&lt;&#x2F;code&gt; and can escape &lt;code&gt;bar&lt;&#x2F;code&gt;. This is a good example of a full allocation elimination, the allocation isn&#x27;t just moved into the stack, rarther &lt;code&gt;bar&lt;&#x2F;code&gt; is inlined and then the usage of any object at all can be optimized away.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;luajit-allocation-sinking&quot;&gt;LuaJIT Allocation Sinking&lt;&#x2F;h3&gt;
&lt;p&gt;In most languages that box, essentially everything gets a box (except &lt;code&gt;null&lt;&#x2F;code&gt; and &lt;code&gt;undefined&lt;&#x2F;code&gt; types, though &lt;code&gt;NaN&lt;&#x2F;code&gt; in Javascript is boxed into a &lt;code&gt;Number&lt;&#x2F;code&gt; so terms and conditions may apply). LuaJIT is smarter off the bat and manages to not box floats and is good at not allocating (when I say &amp;quot;allocate&amp;quot;, I mean to the heap) constants.&lt;&#x2F;p&gt;
&lt;p&gt;LuaJIT&#x27;s does something called &lt;a href=&quot;http:&#x2F;&#x2F;wiki.luajit.org&#x2F;Allocation-Sinking-Optimization&quot;&gt;&lt;em&gt;Allocation Sinking&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;, which is based on escape analysis and the result is very powerful allocation removals, doing things that even the age-old Hotspot can&#x27;t do. Pypy implemented a vast majority of the things that LuaJIT did (see this &lt;a href=&quot;http:&#x2F;&#x2F;www1.maths.lth.se&#x2F;matematiklth&#x2F;vision&#x2F;publdb&#x2F;reports&#x2F;pdf&#x2F;ardo-bolz-etal-dls-12.pdf&quot;&gt;2012 paper&lt;&#x2F;a&gt;) though I&#x27;d want to describe some of these optimizations in the context of LuaJIT rather than Pypy because LuaJIT gave me free examples.&lt;&#x2F;p&gt;
&lt;p&gt;When data is allocated, there&#x27;s typically a &amp;quot;store&amp;quot; and then a &amp;quot;load&amp;quot; later on. Store-to-load forwarding is what it sounds like, getting the subsequent &amp;quot;load&amp;quot; function to receive data directly from the location of storing. This is used to have powerful allocation sinking, more commonly called &amp;quot;code motion&amp;quot; (or specifically, loop-invariant code motion as JITs tend to be concerned with loop optimizations). These examples do not use executable Lua code.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;lua&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-lua &quot;&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;z &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;-- i don&amp;#39;t think this actually allocates in lua, but let‚Äôs pretend it does
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What we want is for &lt;code&gt;x&lt;&#x2F;code&gt; to be declared outside of the loop, as it saves us that allocation every time we iterate. This could be done through code motion.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;lua&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-lua &quot;&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;z
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In the example below, the allocation of &lt;code&gt;i&lt;&#x2F;code&gt; to &lt;code&gt;y&lt;&#x2F;code&gt; should be moved to be inside the conditional. Note that this optimization is not quite covered by the base strategy described for Pypy.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;lua&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-lua &quot;&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;random&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0.5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;-- but does not escape this if statement
&lt;&#x2F;span&gt;&lt;span&gt;    x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;z
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;-- should become
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;random&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0.5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#ff79c6;color:#f8f8f0;&quot;&gt;local&lt;&#x2F;span&gt;&lt;span&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;z
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here, LuaJIT defers the write and &lt;em&gt;forwards&lt;&#x2F;em&gt; the data to the read. As a result, the allocation and read are very much removed. The forwarding destination is the point of escape, which is where the escape analysis comes in.&lt;&#x2F;p&gt;
&lt;p&gt;LuaJIT has an explicit mark-and-sweep pass to do sinks. For an example that highlights the allocation sinking, LuaJIT performed on par with C++ and 700x faster than Lua. Specifically (taken from the &lt;a href=&quot;http:&#x2F;&#x2F;wiki.luajit.org&#x2F;Allocation-Sinking-Optimization#implementation%5B&quot;&gt;LuaJIT Blog&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;lua&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-lua &quot;&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;ffi &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;require&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;ffi&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;point
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;point &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;ffi&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;metatype&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;struct { double x, y; }&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;__add &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;function&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;point&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;x, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;y)
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;local &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;point&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1.5&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2.5&lt;&#x2F;span&gt;&lt;span&gt;), &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;point&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3.25&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4.75&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;100000000 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;x, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;y)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This example does some things that are familiar from the Pypy example -- it creates temporary objects while performing the arithmetic (&lt;code&gt;point(a.x + b.x, a.y + b.y)&lt;&#x2F;code&gt;). These two under-the-hood allocations are expensive, but LuaJIT optimizes them away! Even Hotspot fails to make this optimization.&lt;&#x2F;p&gt;
&lt;p&gt;Important note that LuaJIT does not describe this as escape analysis, and particularly specifies that escape analysis is not ideal for dynamic languages (because there are too many points of escape in dynamic languages), but the intention of finding points of escape and saving allocation times is the same even though the traditional &amp;quot;if escape then heap_allocate else stack_allocate&amp;quot; is not an accurate description of allocation sinking.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;where-have-all-the-interpreted-languages-gone&quot;&gt;Where have all the interpreted languages gone&lt;&#x2F;h3&gt;
&lt;p&gt;This blog post doesn&#x27;t cover interpreted languages! The obvious answer is that because they&#x27;re interpreted, there&#x27;s no room for them to do escape analysis, and unlike JITs they can&#x27;t recompile or move from interpretation to compilation. However, most interpreted languages (Python, Ruby, PHP) do have a compile step where bytecode is emitted, so there&#x27;s no technical reason why escape analysis couldn&#x27;t be performed at that step. These languages need to maintain fast compile times, which is the broad reason why it isn&#x27;t done. Additionally, as mentioned by Mike Pall of LuaJIT, dynamic languages have too many points of escape, which is handle-able by JITs but would be harder to implement as a part of static compilation.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;some-security-escaped-v8&quot;&gt;Some Security Escaped V8&lt;&#x2F;h3&gt;
&lt;p&gt;Javascript&#x27;s V8 engine does escape analysis similarly to the way described in Pypy and LuaJIT. In 2017 though, a bug with overly aggressive escape analysis became a significant vulnerability for Chrome browsers and escape analysis was disabled for about a week before they reimplemented it. This is an Extremely Cool exploit and I&#x27;m surprised there wasn&#x27;t a write-up on it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;allocs&#x2F;js.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Chrome team marked this as &amp;quot;high&amp;quot; with a $7500 reward, and the bug is fairly intuitive -- something isn&#x27;t allocated when it should be and errors will occur due to something not existing when it should be. The reason it&#x27;s a security vulnerability is unrelated to escape analysis and requires too much background to fully explore in this post.&lt;&#x2F;p&gt;
&lt;p&gt;But for an entire Chrome Version, this key optimization was just... gone? I assume compiler speed in the scope of web-browsing speed is but a minor factor due to all the caching and network times, but other than that I don&#x27;t actually know what to expect with escape analysis gone. It probably would&#x27;ve been very impactful for NodeJS, but the vulnerability had to do with the browser API so Node was not at risk.&lt;&#x2F;p&gt;
&lt;p&gt;So... benchmark time! I&#x27;ll be running Octane, which is not a recommended benchmark suite (retired in 2017) but is pretty big and came with my build of V8. I didn&#x27;t bother too much with scientific process, and ran it on my laptop for three runs (V8 recommends 10). I ran without CPU frequency scaling or limiting the number of cores though I could make an argument that I should&#x27;ve.&lt;&#x2F;p&gt;
&lt;p&gt;I rebuilt V8 (I could&#x27;ve also tested with Chrome builds, but those seemed harder to find&#x2F;built and maybe there were other performance affecting charges), based on commit history &lt;a href=&quot;https:&#x2F;&#x2F;chromium.googlesource.com&#x2F;v8&#x2F;v8&#x2F;+log&#x2F;f29d55e61904333f3ccc792021885dfa8dc980e2&quot;&gt;here&lt;&#x2F;a&gt;. This compares the impact of this security patch, and not the impact we would get by disabling EA now (it got a big overhaul!).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;                               benchmark:    score |  master_ |      % |
&lt;&#x2F;span&gt;&lt;span&gt;===================================================+==========+========+
&lt;&#x2F;span&gt;&lt;span&gt;                                Richards:  28998.3 |  29093.8 |   -0.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                               DeltaBlue:  51902.6 S  51187.0 S    1.4 |
&lt;&#x2F;span&gt;&lt;span&gt;                                  Crypto:  32698.2 |  33198.3 |   -1.5 |
&lt;&#x2F;span&gt;&lt;span&gt;                                RayTrace:  54845.4 S  80116.3 |  -31.5 |
&lt;&#x2F;span&gt;&lt;span&gt;                             EarleyBoyer:  41575.6 |  42536.7 |   -2.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                                  RegExp:   8115.0 S   8302.8 |   -2.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                                   Splay:  22830.1 S  23609.1 S   -3.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                            SplayLatency:  39286.6 S  40214.6 S   -2.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                            NavierStokes:  37347.0 |  37557.0 |   -0.6 |
&lt;&#x2F;span&gt;&lt;span&gt;                                   PdfJS:  31527.6 |  32036.1 |   -1.6 |
&lt;&#x2F;span&gt;&lt;span&gt;                                Mandreel:  39278.4 |  39593.9 |   -0.8 |
&lt;&#x2F;span&gt;&lt;span&gt;                         MandreelLatency: 117204.4 S 119061.7 S   -1.6 |
&lt;&#x2F;span&gt;&lt;span&gt;                                 Gameboy:  75636.3 S  76792.6 S   -1.5 |
&lt;&#x2F;span&gt;&lt;span&gt;                                CodeLoad:  22562.2 S  23094.8 |   -2.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                                   Box2D:  75097.7 S  79478.3 |   -5.5 |
&lt;&#x2F;span&gt;&lt;span&gt;                                    zlib:  65881.2 |  65934.8 |        |
&lt;&#x2F;span&gt;&lt;span&gt;                              Typescript:  23753.4 |  23682.8 |    0.3 |
&lt;&#x2F;span&gt;&lt;span&gt;                                  Octane:  38420.0 S  39782.1 |   -3.4 |
&lt;&#x2F;span&gt;&lt;span&gt;---------------------------------------------------+----------+--------+
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From this we can observe that disabling escape analysis could not have been that bad for Chrome, with a 3.4% reported slowdown (though it is a significant optimization for a compiler). &lt;code&gt;RayTrace&lt;&#x2F;code&gt; is quite an outlier there, and I find it amusing since the Raytracer probably deals with a lot of objects to represent points and shapes in space, which is exactly what the example in the previous Javascript and Lua sections were doing.&lt;&#x2F;p&gt;
&lt;p&gt;With the new escape analysis, disabling it cost 6.3% instead of 3.4%, which indicates that the new escape analysis is better. These benchmarks are good enough to make note of the importance of escape analysis, what kind of operations it works well on but not good enough to say that &amp;quot;escape analysis makes Javascript 6.3% faster&amp;quot;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;escape-analysis-with-llvm-backed-languages&quot;&gt;Escape Analysis with LLVM-backed languages&lt;&#x2F;h3&gt;
&lt;p&gt;Escape analysis happens for statically compiled languages too! I&#x27;ll go through an example with clang, Julia (which is jitted, but statically compiled with type information), and then touch on what happens with Rust. LLVM is a toolchain which handles code generation for many languages, and will optimize them in mostly the same way.&lt;&#x2F;p&gt;
&lt;p&gt;Here is the C++ code I&#x27;ll work with for this example. I started by running it through clang, which is a C++ (and friends) compiler with an LLVM backend.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;c&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;t &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= new &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;]; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; the new operator in cpp is conventionally an allocation, though it is implementation defined
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; a;
&lt;&#x2F;span&gt;&lt;span&gt;    t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span&gt;    t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; c;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt;t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt;t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;]; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; because this is the only usage of `t`, we should be able to optimize away the allocation of `t`
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;delete[]&lt;&#x2F;span&gt;&lt;span&gt; t; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; the compiler has to understand that this `delete` operation doesn&amp;#39;t require an allocation of `t` to exist
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; r;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s easy to tell that escape analysis happens here with the emmitted assembly - we get only three instructions; &lt;code&gt;lea&lt;&#x2F;code&gt;, &lt;code&gt;add&lt;&#x2F;code&gt; and &lt;code&gt;ret&lt;&#x2F;code&gt;. &lt;code&gt;lea&lt;&#x2F;code&gt; computes an address of X and stores it in Y, &lt;code&gt;add&lt;&#x2F;code&gt; is the arithmetic (the &lt;code&gt;lea&lt;&#x2F;code&gt; does a part of the addition) and then &lt;code&gt;ret&lt;&#x2F;code&gt; is a return. The instructions for &lt;code&gt;foo&lt;&#x2F;code&gt; begin when &lt;code&gt;r&lt;&#x2F;code&gt; is intialized and assigned. &lt;code&gt;gcc&lt;&#x2F;code&gt; will not make this optimization, though this is not at all an indication that &lt;code&gt;gcc&lt;&#x2F;code&gt; is less powerful than &lt;code&gt;clang&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;I would not call this escape analysis outside of a blog post though it describes a similar process of allocation elimination. This is better described as constant propogation, as the escape analysis is not really checking escape out of a loop or funciton, but that the only escape (which is reading for this case) of the values. LLVM does explicitly run escape analysis for more conventional examples shown previously though this is easier to work with as an example.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; this is C and not C++ code but it&amp;#39;s all `clang` anyway
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;#include &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;lt;stdlib.h&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;void &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;indirect&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;x&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    x[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;14&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;malloc&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;sizeof&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;)); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; malloc usually means allocations
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;indirect&lt;&#x2F;span&gt;&lt;span&gt;(x);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; x[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;];
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;free&lt;&#x2F;span&gt;&lt;span&gt;(x);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; y;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;LLVM does it quite well, with this example getting the allocations optimized away. Both &lt;code&gt;indirect&lt;&#x2F;code&gt; and &lt;code&gt;foo&lt;&#x2F;code&gt; only has a &lt;code&gt;mov&lt;&#x2F;code&gt; instruction (copies between registers). So there are actually two cases, the first being &lt;code&gt;x&lt;&#x2F;code&gt; not being allocated and the second is &lt;code&gt;y&lt;&#x2F;code&gt; not being allocated. Nothing is allocated, though it makes sense that a simple additional function call with a pointer does not make it that much harder for LLVM (though it would make it much harder for more dynamic languages).&lt;&#x2F;p&gt;
&lt;p&gt;To see where these optimizations happen, we can look at the LLVM code (an intermediate representation for LLVM, higher level than assembly). I looked for a &lt;code&gt;znam&lt;&#x2F;code&gt; instruction which clang uses to make allocations. For the first example, there is only one allocation for the array &lt;code&gt;t&lt;&#x2F;code&gt;. Then with the options &lt;code&gt;-mllvm -print-after-all&lt;&#x2F;code&gt; I get some output with the LLVM code at various steps, specified such as &amp;quot;value propogation&amp;quot; or &amp;quot;dead argument elimination&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;After a run of &amp;quot;Combine redundant instructions&amp;quot;, &lt;code&gt;znam&lt;&#x2F;code&gt; disappears, and the instructions are about halved (this is not proportionate to speed). &lt;code&gt;store&lt;&#x2F;code&gt; operations are also gone after this step, (they belong to the &lt;code&gt;t[n]= {a|b|c}&lt;&#x2F;code&gt; lines). Exploring &lt;a href=&quot;https:&#x2F;&#x2F;llvm.org&#x2F;doxygen&#x2F;InstructionCombining_8cpp_source.html&quot;&gt;the implementation&lt;&#x2F;a&gt; you can also see how they explicitly look for escapes.&lt;&#x2F;p&gt;
&lt;p&gt;Below is the same program in Julia. Working with this optimization in Julia is more difficult because it is mostly JIT compiled, with functions compiled (statically) as they are called. Julia also has the challenge of being garbage collected. For the below, I rigged a compilation to LLVM code with &lt;code&gt;@code_llvm&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;julia&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-julia &quot;&gt;&lt;code class=&quot;language-julia&quot; data-lang=&quot;julia&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(a, b, c)
&lt;&#x2F;span&gt;&lt;span&gt;  t &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; Int&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;64&lt;&#x2F;span&gt;&lt;span&gt;[a, b, c]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt;t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt;t[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  clear&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;:t&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# Free! The Memory
&lt;&#x2F;span&gt;&lt;span&gt;  r
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This time I&#x27;m looking for &lt;code&gt;store&lt;&#x2F;code&gt; instruction which is used to write to memory. Julia does not optimize away the creation of the array &lt;code&gt;t&lt;&#x2F;code&gt;, probably partially due a specific Julia feature or the increased complexity of LLVM code due to Julia&#x27;s dynamic-ness relative to C++ (it is generally unclear to me what blocks this). Julia would probably do a better job at less convoluted constant propagation and it does do fine on escape analysis, as seen on the below example.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;julia&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-julia &quot;&gt;&lt;code class=&quot;language-julia&quot; data-lang=&quot;julia&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# same example from earlier with Pypy!
&lt;&#x2F;span&gt;&lt;span&gt;    x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for&lt;&#x2F;span&gt;&lt;span&gt; i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;123
&lt;&#x2F;span&gt;&lt;span&gt;    	y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; rand(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# if rand is not used, the entire function gets turned into a constant value return!
&lt;&#x2F;span&gt;&lt;span&gt;    	x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+=&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;span&gt;    x
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For this, I didn&#x27;t even have to look for &lt;code&gt;store&lt;&#x2F;code&gt; or anything GC related, the code is the same if I replace &lt;code&gt;y * 4&lt;&#x2F;code&gt; with &lt;code&gt;rand(1, 5) * 4&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Other LLVM-backed languages include Swift, Crystal and Rust. If you&#x27;ve heard anything about Rust, it&#x27;s probably something along the lines of &amp;quot;yeah manual memory management is hard but Rust makes it easier&amp;quot;. If I worded it as &amp;quot;Rust makes it very easy&#x2F;automatic to statically check memory&amp;quot; then I&#x27;d be closer to saying &amp;quot;Rust&#x27;s memory is automatically managed, just not at runtime&amp;quot;. If you&#x27;ve heard another thing about Rust it&#x27;s probably &amp;quot;borroooowww cheeeeckkkeeeerrr&amp;quot;. Look into &lt;a href=&quot;https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;1.8.0&#x2F;book&#x2F;references-and-borrowing.html&quot;&gt;Rust&#x27;s Ownership Structure&lt;&#x2F;a&gt; and you might find that the borrow checker basically prevents you from accidentally letting something get stuck in the heap when it escapes. I certainly would not call the borrow checker &amp;quot;escape analysis&amp;quot; but it&#x27;s a relevant concept in Rust that is rather parallel to escape analysis.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;go&quot;&gt;Go&lt;&#x2F;h3&gt;
&lt;p&gt;Golang Escape Analysis is the most documented between all the language implementations I described. Go doesn&#x27;t use LLVM for code generation and is garbage collected. With Go, I can build with &lt;code&gt;-gcflags -m&lt;&#x2F;code&gt; (with &lt;code&gt;-m&lt;&#x2F;code&gt; multiple times for more verbosity) to see all the escape analysis decisions (I could do this for V8 as well). Go&#x27;s escape analysis is very focused on &amp;quot;does it escape the function&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;I found a cool example to showcase Go Escape Analysis, pulled from &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;36125927&#x2F;golang-slice-allocation-performance&quot;&gt;this Stack Overflow question&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;main&lt;&#x2F;span&gt;&lt;span&gt;() {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;const &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;65536
&lt;&#x2F;span&gt;&lt;span&gt;  now &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;time&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Now&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;  loop &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;50000
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;loop&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++ &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    allocation &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;allocation&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;  }
&lt;&#x2F;span&gt;&lt;span&gt;  elapsed &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;time&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Since&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;now&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;fmt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Println&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;elapsed&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The number &lt;code&gt;65536&lt;&#x2F;code&gt; probably looks familiar to you -- it&#x27;s exactly 64K. The Stack Overflow question asks why setting &lt;code&gt;alloc&lt;&#x2F;code&gt; to &lt;code&gt;65535&lt;&#x2F;code&gt; instead of &lt;code&gt;65536&lt;&#x2F;code&gt; causes this code to speed up by 10000x (by my unscientific measurements on my local machine). Turns out with the slightly larger size, Go decides that the alloc must escape to the heap. The SO answer is more or less &amp;quot;this is just the GC running because escape analysis&amp;quot; but we have time to get into it. Here is the debugging output with &lt;code&gt;65535&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;17&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;14&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;inlining call to fmt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;Println &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; inlining
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;does not escape &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; decides that `alloc does not escape scope`, correct
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;17&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;14&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;elapsed escapes to heap &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; decides `elapsed` escapes? weird.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;17&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;14&lt;&#x2F;span&gt;&lt;span&gt;: []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;interface &lt;&#x2F;span&gt;&lt;span&gt;{} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;literal does not escape &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; irrelevant, related to println
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Before I move onto why the alloc escapes, why does &lt;code&gt;elapsed&lt;&#x2F;code&gt; escape when it seems fairly obviously only used in &lt;code&gt;main&lt;&#x2F;code&gt;? Go will count a function call as escape, and thus printing &lt;code&gt;elapsed&lt;&#x2F;code&gt; causes it to be allocated. This is not usually too much of a problem, since inlining will occur first, but &lt;code&gt;fmt.Println&lt;&#x2F;code&gt; is complex enough that the inlined function contains another function call (this is shown when I add more &lt;code&gt;-m&lt;&#x2F;code&gt;s). My non-professional opinion is that I expected more aggressive escape analysis and inlining, but I still see no evidence that Go escape analysis has a lot of room for improvement since I don&#x27;t understand Go language internals or core philosophies that might prevent more aggressive escape analysis.&lt;&#x2F;p&gt;
&lt;p&gt;Anyway, when I set it to &lt;code&gt;65536&lt;&#x2F;code&gt; here is the expanded output to explain why Go thinks &lt;code&gt;alloc&lt;&#x2F;code&gt; needs to go to the heap.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;escapes to heap&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15&lt;&#x2F;span&gt;&lt;span&gt;:   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;flow&lt;&#x2F;span&gt;&lt;span&gt;: {&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;heap&lt;&#x2F;span&gt;&lt;span&gt;} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;storage &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;)}:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15&lt;&#x2F;span&gt;&lt;span&gt;:     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;from &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;make&lt;&#x2F;span&gt;&lt;span&gt;([]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;) (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;non&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;constant size&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.go&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;15
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What&#x27;s up with this &amp;quot;non-constant size&amp;quot; business? I even used the keyword &lt;code&gt;const&lt;&#x2F;code&gt;! If I manually constant propogate and don&#x27;t use the &lt;code&gt;alloc&lt;&#x2F;code&gt; const, it still escapes to heap. The answer is a &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;issues&#x2F;41635&quot;&gt;bug that I reported&lt;&#x2F;a&gt; and was shockingly fixed with two reviewers in less than 24 hours and I am so impressed with the Go devs. Anyway, the correct reason is &amp;quot;too large for stack&amp;quot;. I did a quick search for why that number is 64K, and it seems mostly OS related and maybe hardware? Open to emails explaining max sizes for stack allocated values.&lt;&#x2F;p&gt;
&lt;p&gt;A key to stack allocation for Golang is that you have to know the lifetime of the object at compile time - which is why escape analysis is hand in hand with &amp;quot;can I stack allocate this?&amp;quot;. There are a bunch more general rules that can be found with a quick &lt;a href=&quot;https:&#x2F;&#x2F;segment.com&#x2F;blog&#x2F;allocation-efficiency-in-high-performance-go-services&#x2F;&quot;&gt;Google search&lt;&#x2F;a&gt;, though they&#x27;re not specification guaranteed.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;other-compilers-that-do-escape-analysis&quot;&gt;Other Compilers that do Escape Analysis&lt;&#x2F;h3&gt;
&lt;p&gt;Lisp (and dialects) do escape analysis, and a lot of the papers about escape analysis will be about Lisp and Scheme (earliest paper I could find on the subject is 1990). This means almost nothing because there are so many lisp dialects and implementations of each of them, but here is an article about &lt;a href=&quot;https:&#x2F;&#x2F;bike.github.io&#x2F;posts&#x2F;kildall.html&quot;&gt;Kildall&#x27;s Algorithm for Escape Analysis on a Lisp Compiler&lt;&#x2F;a&gt;. &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stalin_(Scheme_implementation)&quot;&gt;Stalin&lt;&#x2F;a&gt;, a Scheme compiler used a lot of data-flow analysis and advertises very powerful escape analysis.&lt;&#x2F;p&gt;
&lt;p&gt;GraalVM will of course run Escape Analysis for any Truffle language. They call it &amp;quot;partial escape analysis&amp;quot;, which is what was described in Pypy where the allocation is delayed, or only run at the point of escape. See &lt;a href=&quot;http:&#x2F;&#x2F;www.ssw.uni-linz.ac.at&#x2F;Research&#x2F;Papers&#x2F;Stadler14&#x2F;Stadler2014-CGO-PEA.pdf&quot;&gt;the paper on this&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Hotspot (Java compiler) of course also does escape analysis, though I get the impression that it&#x27;s not as &amp;quot;partial&amp;quot; as newer JITs (this may be biased since I can find papers about newer JITs going &amp;quot;haha i am better than hotspot&amp;quot; but not Hotspot going &amp;quot;excuse me my escape analysis is actually great&amp;quot;). One could probably run some tests with JVM backed languages like Java or Scala.&lt;&#x2F;p&gt;
&lt;p&gt;OCaml does not do escape analysis, but will do things that are more like the constant propagation I talked about with LLVM. OCaml is garbage collected, but it is very well garbage collected (omg goals) and Escape Analysis did not help much (&lt;a href=&quot;https:&#x2F;&#x2F;inbox.ocaml.org&#x2F;caml-list&#x2F;1254277202.4888153.1523892717467.JavaMail.zimbra@inria.fr&#x2F;&quot;&gt;see thread&lt;&#x2F;a&gt;)&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;ocaml&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-ocaml &quot;&gt;&lt;code class=&quot;language-ocaml&quot; data-lang=&quot;ocaml&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;let &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;p x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;let &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= ref&lt;&#x2F;span&gt;&lt;span&gt; x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;(* `r` will not be allocated *)
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while&lt;&#x2F;span&gt;&lt;span&gt; is_not_finished &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!&lt;&#x2F;span&gt;&lt;span&gt;r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;    r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:=&lt;&#x2F;span&gt;&lt;span&gt; do_something &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;!&lt;&#x2F;span&gt;&lt;span&gt;r
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;done
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>I can dance, but I can&#x27;t learn choreography</title>
		<published>2020-09-28T00:00:00+00:00</published>
		<updated>2020-09-28T00:00:00+00:00</updated>
		<link href="https://kipp.ly/dance-not-choreo/"/>
		<link rel="alternate" href="https://kipp.ly/dance-not-choreo/" type="text/html"/>
		<id>https://kipp.ly/dance-not-choreo/</id>
		<content type="html">&lt;p&gt;like many human beings out there, i‚Äôve wanted to dance. i want to be able to walk on pointe, swing dance with strangers and leap into splits. i am currently a very untrained dancer who only managed to reach her toes a year ago.&lt;&#x2F;p&gt;
&lt;p&gt;like many human beings out there, i started with a simple dance class, got an intro offer, showed up to a slightly crammed studio and spent one hour learning a thirty second routine.&lt;&#x2F;p&gt;
&lt;p&gt;like many of the humans there in that room with me, i did not feel like i was dancing. to those of you who have felt this way, my first thought is to say something like ‚Äúaww don‚Äôt worry, we all start that way. our bodies are unique and we will all walk our own journey‚Äù. of course, people said this to me. i said this to me. it‚Äôs a good thing to say.&lt;&#x2F;p&gt;
&lt;p&gt;but come a year or two later, i still didn‚Äôt feel like i could dance. i kept going with the physical activity but i didn‚Äôt dance, i did tricks and made shapes. am i just untalented? probably.&lt;&#x2F;p&gt;
&lt;p&gt;so then came march and i was stuck inside. my training for tricks (pole dance) became much harder since it was dangerous to learn tricks on my own, plus it‚Äôs hard to come up with the willpower to train since it‚Äôs tiring and painful. here are some pole bruises.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;movement&#x2F;polebruise.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;so i started easing into dancing. not learning a routine or picking a song, but putting on a playlist and moving in whatever way felt good. i suffered in my technical skills from lack of learning choreography and new moves, but without guidance i was able to achieve these things which i now consider to be the guiding requirements of ‚Äúcan you dance?‚Äù&lt;&#x2F;p&gt;
&lt;p&gt;expressing feelings. this doesn‚Äôt have to be a soulful ‚Äúi must dance to express my heartache‚Äù, but should at least mean that movement is distinct and different in different moods.&lt;&#x2F;p&gt;
&lt;p&gt;exploration&#x2F;creativity. some feeling that you‚Äôve done something new while dancing, something that you didn‚Äôt know you could do or that would look&#x2F;feel good.&lt;&#x2F;p&gt;
&lt;p&gt;accepting guidance. you don‚Äôt have to be able to step into a rave and start shaking your ass, but if you‚Äôre in a freestyle class and you‚Äôre given a prompt to work with your head, that should affect your movement.&lt;&#x2F;p&gt;
&lt;p&gt;underlying to these points is being comfortable with moving.&lt;&#x2F;p&gt;
&lt;p&gt;when i watch other people dance i ask, ‚Äúdo i want to be them right now?‚Äù&lt;&#x2F;p&gt;
&lt;p&gt;if i see them looking confident, expressive, being powerful in their movement the answer is always ‚Äúyes‚Äù whether they‚Äôre shaking their ass or just twirling their hands. (by the way, i highly recommend trying to dance with just your hands).&lt;&#x2F;p&gt;
&lt;p&gt;disciplined dancers can come after me but i recommend dancing without ever learning choreography. you will still get the exercise, self-expression and be able to expand your movement repertoire. i do still like classes once in a while for inspiration (but also following people i love) as well as guided freestyle or routine development classes, but i don‚Äôt think it‚Äôs necessary.&lt;&#x2F;p&gt;
&lt;p&gt;my comfort zone is ever expanding. my go-to style is a very modern pole dance ‚Äî a lot of tension, kicks, body rolls, long lines to sensual music. here is an eleven second video of me moving in ways i never have before to really fast music, prompted by the music being released by a work fren of mine. &amp;lt;3&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Incantations of Movement</title>
		<published>2020-09-24T00:00:00+00:00</published>
		<updated>2020-09-24T00:00:00+00:00</updated>
		<link href="https://kipp.ly/incantations-of-movement/"/>
		<link rel="alternate" href="https://kipp.ly/incantations-of-movement/" type="text/html"/>
		<id>https://kipp.ly/incantations-of-movement/</id>
		<content type="html">&lt;p&gt;there are phrases we exchange in every day life that have very little sense but we agree on what they mean. like when we ‚Äúcall it a day‚Äù, when something is ‚Äúon the ball‚Äù or to ‚Äúwrap your head around‚Äù something.&lt;&#x2F;p&gt;
&lt;p&gt;these things are shared through us by language and associated experience, but we also have incantations to describe how we move ‚Äî and these incantations are special because we experience them first hand.&lt;&#x2F;p&gt;
&lt;p&gt;it takes time to learn these incantations. the first time i showed up to a yoga class and was told to open my heart i just laughed at the ambiguity of the request.&lt;&#x2F;p&gt;
&lt;p&gt;opening your heart is a series of movements that are hard to separate, but you could break it down and describe the opening in the chest, neck tilting back, shoulders down and the arch in your upper back. i know when i‚Äôm opening my heart, but if i gave myself those instructions one by one, it would not feel like my heart is open. there‚Äôs some magic in the cue that makes it better.&lt;&#x2F;p&gt;
&lt;p&gt;but i think ‚Äúlengthening your spine‚Äù is also an incantation, even though it‚Äôs completely physiological whereas ‚Äúopen your heart‚Äù is packaged into a metaphor of sorts.&lt;&#x2F;p&gt;
&lt;p&gt;it is still a fucking incantation because it‚Äôs not the same as ‚Äúwiggle your right thumb‚Äù. it‚Äôs something that you will do incorrectly the first time you try because you have no idea what it means. i googled instructions for a basic spine elongation exercise and it‚Äôs one hundred and fifty words, and uses incantations like ‚Äúcontracting your abdominals and then releasing your body‚Äù.&lt;&#x2F;p&gt;
&lt;p&gt;so how do you know when you‚Äôre successfully executing the incantation? do you feel it? does someone have to tell you? can you see it? i have experienced all these options.&lt;&#x2F;p&gt;
&lt;p&gt;sometimes i just feel it, the movement feels good, different, productive. with my spine lengthening, i actually could see it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;movement&#x2F;upsidedown.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;the photo on the right was taken before i took a second to lengthen my spine. a lot of this is in my shoulders, but the differences in the way my back looks is also noticeable. when i invert my abs and shoulders are tensed, my lower abs especially are working to hollow out my back. when i relax into this and let my spine be pulled, i am more symmetrical&lt;&#x2F;p&gt;
&lt;p&gt;oh these incantations&lt;&#x2F;p&gt;
&lt;p&gt;i‚Äôve recently levelled up my incantation interpretation, as a couple weeks ago, when hanging like this, i was told to ‚Äúpull my head towards the ground‚Äù. at this point i have an intuition for interpreting incantations (i am an incantation jit compiler!) and i pull my fucking head towards the ground and i feel my spine lengthen with ease.&lt;&#x2F;p&gt;
&lt;p&gt;why did that work? why does my brain, which i consider very left-brain-y (and knows a bit about spines) work so well with ‚Äúpull my head towards the ground‚Äù when it has already been working on lengthening for so long.&lt;&#x2F;p&gt;
&lt;p&gt;am i just trying harder because someone told me to? (but then why was it easy?) is a new incantation always better than an old one?&lt;&#x2F;p&gt;
&lt;p&gt;certainly not all incantations are made the same. ‚Äúpull your shoulders towards the ground‚Äù would‚Äôve done incorrect things. i‚Äôve also been told to ‚Äútwist into [my] stomach‚Äù which just thoroughly confused me but helped other students.&lt;&#x2F;p&gt;
&lt;p&gt;you can break down what i call incantations to be ‚Äúthe meaning of words‚Äù and their ‚Äúconnotations‚Äù and just ‚Äúlearning by association‚Äù. yet every time someone tells me to open my heart, i feel like there‚Äôs some code hidden in there that somehow tells me exactly what to do, without me knowing exactly what i‚Äôm doing.&lt;&#x2F;p&gt;
&lt;p&gt;incantations.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Smarter Because You Move</title>
		<published>2020-09-23T00:00:00+00:00</published>
		<updated>2020-09-23T00:00:00+00:00</updated>
		<link href="https://kipp.ly/smarter-because-you-move/"/>
		<link rel="alternate" href="https://kipp.ly/smarter-because-you-move/" type="text/html"/>
		<id>https://kipp.ly/smarter-because-you-move/</id>
		<content type="html">&lt;p&gt;this is not something i would claim to people like ‚Äúhey maybe if you could raise one eyebrow you would be smarter‚Äù, but control of your body is a nervous system process, which is reasonably considered relevant to intelligence. i happen to think that your nervous system is incredibly dumb. the amount of control i have over my body tells me that my brain is very bad at communicating with my body ‚Äî it‚Äôs stupid.&lt;&#x2F;p&gt;
&lt;p&gt;octopi are considered very smart, but they don‚Äôt use their nine brains to build computers, rather they can control each of their suction cups individually. that‚Äôs very impressive to me because here i am, a human controlling a metal machine that stores data and uses the internet and i can‚Äôt raise an eyebrow.&lt;&#x2F;p&gt;
&lt;p&gt;‚Äúwell that‚Äôs fine‚Äù you say, ‚Äúwhy would you need to raise your eyebrow? it‚Äôs hard for you to isolate your other fingers, but you can move your thumbs with great control. your body is fine!‚Äù&lt;&#x2F;p&gt;
&lt;p&gt;to that, i shall share the tale of the trap muscle that won‚Äôt activate. if you don‚Äôt go to the gym, you might look at the muscle and think ‚Äúhow the fuck am I supposed to move that‚Äù and that would be a correct response.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;movement&#x2F;traps.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;if you do weight lifting, then you might be thinking of specific exercises and how they target your low&#x2F;mid&#x2F;upper traps differently. you might still be unable to flex it without doing one of the exercises or without also tensing another muscle.&lt;&#x2F;p&gt;
&lt;p&gt;if you‚Äôre me, you do a lot of hanging from your arms and inversions. you also do a lot of hunching over your computer and sticking your neck out. you have very strong shoulders and pec muscles (it‚Äôs side boob muscle) and a fairly weak neck. your traps are by no means weak because you need back muscles for many things.&lt;&#x2F;p&gt;
&lt;p&gt;but then if you did one of those trap exercises, it‚Äôs so fucking hard!&lt;&#x2F;p&gt;
&lt;p&gt;a fun thing with muscles, is that they do actually move and pull to exert force. that means if you press on it it, they can‚Äôt exert force.&lt;&#x2F;p&gt;
&lt;p&gt;one day i was given a trap exercise and i said ‚Äúnoooo this is so hard‚Äù. then my pec muscle was pinched, and the trap exercise became easy, though for the first time ever i actually felt my trap working.&lt;&#x2F;p&gt;
&lt;p&gt;what happened to my body was that my pecs were so used to doing all the work, that they would activate and kick in even when my traps should be doing the work ‚Äî and would be better at the job.&lt;&#x2F;p&gt;
&lt;p&gt;i went home with new exercises to really focus on learning to activate my traps ‚Äî this is different from the intention of strengthening. i need to teach my traps to activate when they‚Äôre supposed to, and learn how to identify when my traps are activated vs when another part of my body is trying to take over. there are some exercises associated with this but the hard part really is teaching my body parts, nervous system and brain some new skills.&lt;&#x2F;p&gt;
&lt;p&gt;as a software developer, i often assume that the default behaviour is ok when actually the default behaviour is dumb. in engineering this happens often because there are so many different use cases, but this is my BRAIN and my PEC they are literally right next to each other, grew up together, evolved to complement each other and they really should not be able to fuck up default behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;the extended narrative is that maybe the default behaviour was fine but i, as the engineer, fucked it up because i toggled it to custom behaviour by making my pecs work more, but a good (nervous) system should really emit some kind of warning to tell me i‚Äôm choosing to do something a stupid way.&lt;&#x2F;p&gt;
&lt;p&gt;at the gut level, i feel dumb when my body doesn‚Äôt do what i want because it‚Äôs limited by the same mechanism that prevents me from calculating logarithms in my head (you can argue that this is wrong, but it feels that way). i would like to explore if these skills are transferable or if i will ‚Äúfeel smart‚Äù when i learn to activate my traps or isolate different parts of my abs.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>I Don&#x27;t Want to be a Founder and I Don&#x27;t Think You Do Either</title>
		<published>2020-07-19T00:00:00+00:00</published>
		<updated>2020-07-19T00:00:00+00:00</updated>
		<link href="https://kipp.ly/founding-bad/"/>
		<link rel="alternate" href="https://kipp.ly/founding-bad/" type="text/html"/>
		<id>https://kipp.ly/founding-bad/</id>
		<content type="html">&lt;p&gt;I had a brief run with a startup and was faced with the decision of going into a YC Cohort (W20). In that fiasco, I also spent at least twelve hours actively in conversations trying to convince other another to take my spot. It&#x27;s been half a year, and I&#x27;ve had a lot more time to reflect on reasons as to why one might want to run a startup. As you might&#x27;ve guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders, which seems to be a shocking number of people.&lt;&#x2F;p&gt;
&lt;p&gt;This post definitely will not apply to everyone, but I&#x27;d hope there&#x27;s some valuable thinking in here. Also, note that this is fairly oriented towards technical founders in a very Silicon Valley startup world (VCs give you money, you grow faste, etc). &lt;&#x2F;p&gt;
&lt;h1 id=&quot;ways-being-a-founder-is-unexpectedly-bad&quot;&gt;Ways Being a Founder is Unexpectedly Bad&lt;&#x2F;h1&gt;
&lt;h3 id=&quot;commitment&quot;&gt;Commitment&lt;&#x2F;h3&gt;
&lt;p&gt;I&#x27;m not talking about commitment to your company. I&#x27;m talking about commitment to your cofounder (if you have one, which is likely).&lt;&#x2F;p&gt;
&lt;p&gt;Maybe I&#x27;m too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that&#x27;s scary. It should be scary or should at least take a few years for it not to become scary.&lt;&#x2F;p&gt;
&lt;p&gt;Your cofounder is...kind of the same? In a seed-stage it&#x27;s likely you &lt;em&gt;actually&lt;&#x2F;em&gt; live together, and if you don&#x27;t, you&#x27;re likely functionally living together with the amount of work involved. They&#x27;re responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They&#x27;re tied to your life goals, your dreams, and your passions.&lt;&#x2F;p&gt;
&lt;p&gt;My impression was that my relationship with my cofounder would be more intense than marriage, and &lt;em&gt;extra&lt;&#x2F;em&gt; bad in the event of failure since there&#x27;s additional loss (and it&#x27;s statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren&#x27;t ready but were fine anyway, but I stand by the statement that it&#x27;s more intense than marriage and not enough people put care into this.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;your-vc-is-not-the-one-at-risk-here&quot;&gt;Your VC is Not the One at Risk Here&lt;&#x2F;h3&gt;
&lt;p&gt;I often hear sentiments that resemble &amp;quot;wow these VCs are taking a chance on me I better commit to this!&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;VCs are not evil people trying to take advantage of you (actually they might be, but let&#x27;s assume they&#x27;re not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you&#x27;re SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them.&lt;&#x2F;p&gt;
&lt;p&gt;They&#x27;re not shy about it either, the entire reason they&#x27;re investing in you is because they think you&#x27;re more valuable than you cost.
&lt;img src=&quot;..&#x2F;img&#x2F;founding&#x2F;paul.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your &amp;quot;bosses&amp;quot; as you answer to them (though &lt;em&gt;much&lt;&#x2F;em&gt; less than a regular &amp;quot;boss&amp;quot;) and to the ones you hope to raise capital from in the future.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into &amp;quot;I&#x27;m going to work on this startup partially in service to these people who believed in me and gave me lots of money&amp;quot;. These additional stresses that come from meeting VC expectations and the complications of the dynamics of that relationship get pretty stressful.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;sense-of-self&quot;&gt;Sense of Self&lt;&#x2F;h3&gt;
&lt;p&gt;This one is the one that got to me most but I can see it being irrelevant to a lot of other people.&lt;&#x2F;p&gt;
&lt;p&gt;Many founders have big egos -- I don&#x27;t mean they&#x27;re assholes or overly self-important but they do have very powerful confidence, because that&#x27;s a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years &lt;em&gt;cough cough&lt;&#x2F;em&gt; Neumann).&lt;&#x2F;p&gt;
&lt;p&gt;My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are &lt;em&gt;good&lt;&#x2F;em&gt; and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could&#x27;ve occurred in my social life (they had already some what started but were revertable).&lt;&#x2F;p&gt;
&lt;p&gt;The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There&#x27;s nothing wrong with that, but I also think it&#x27;s exceptionally tragic to come down from that. It&#x27;s not just dealing with failure and getting back up on your feet, it&#x27;s losing a part of your identity.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;school-is-generally-a-good-idea-for-prospective-dropouts&quot;&gt;School is Generally a Good Idea (for prospective dropouts)&lt;&#x2F;h3&gt;
&lt;p&gt;Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can&#x27;t be worked around with &amp;quot;I am very smart and can learn fast&amp;quot; and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because there will just be much less technical work. It&#x27;s true that founders will learn more than they will in school or industry, but the technical development may not be as strong. My model is that the best schooling experience is better technical education than the best founding experience.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;common-reasons-why-people-want-to-be-founders-and-how-to-get-those-features-elsewhere&quot;&gt;Common reasons why people want to be founders and how to get those features elsewhere&lt;&#x2F;h1&gt;
&lt;h3 id=&quot;something-to-own&quot;&gt;Something to Own&lt;&#x2F;h3&gt;
&lt;p&gt;Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client &lt;code&gt;hey.com&lt;&#x2F;code&gt;, Chromebooks, and countless amazing dev tools.&lt;&#x2F;p&gt;
&lt;p&gt;Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time.&lt;&#x2F;p&gt;
&lt;p&gt;The alternative is starting a project on the side. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ziglang&#x2F;zig&quot;&gt;Ziglang&lt;&#x2F;a&gt; was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to &amp;quot;own&amp;quot; something significant without even having to leave your job. Examples includes Julia Evan&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;jvns.ca&#x2F;&quot;&gt;blog&lt;&#x2F;a&gt; (not actually a work-side-project) and line of zines, Cassidy William&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;drop.com&#x2F;buy&#x2F;drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo&quot;&gt;keycap line&lt;&#x2F;a&gt;, Nick Frosst&#x27;s successful and awesome &lt;a href=&quot;https:&#x2F;&#x2F;goodkidofficial.com&#x2F;&quot;&gt;band&lt;&#x2F;a&gt; and many more. I understand that it&#x27;s not the extent of &amp;quot;oh yeah Google? I built that&amp;quot;, but I think the expected value is much higher in creating and owning something that isn&#x27;t a startup.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;getting-rich&quot;&gt;Getting Rich&lt;&#x2F;h3&gt;
&lt;p&gt;A lot of people claim that startups are less money, but I find for signicant number of founders, that&#x27;s not true -- not because they&#x27;ll definitely have a good exit, but because they&#x27;re skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-funded early-stage startup) is usually higher.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;not-being-at-school-for-prospective-dropouts&quot;&gt;Not Being at School (for prospective dropouts)&lt;&#x2F;h3&gt;
&lt;p&gt;This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don&#x27;t always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself.&lt;&#x2F;p&gt;
&lt;p&gt;A better program can improve many things, such as &lt;a href=&quot;http:&#x2F;&#x2F;www.olin.edu&#x2F;&quot;&gt;Olin College of Engineering&lt;&#x2F;a&gt; that has a project-based curriculum, &lt;a href=&quot;https:&#x2F;&#x2F;www.makeschool.com&#x2F;&quot;&gt;Make School&lt;&#x2F;a&gt; that is a two year applied-engineering degree program or &lt;a href=&quot;https:&#x2F;&#x2F;devdegree.ca&#x2F;&quot;&gt;Dev Degree&lt;&#x2F;a&gt;, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. Olin is actually expensive so a better program may actually be financially unviable for potential startup founders.&lt;&#x2F;p&gt;
&lt;p&gt;Another alternative is to just be worse at school and learn on the side and&#x2F;or to morph your silly school assignments into productive skills and useful outputs. The &lt;a href=&quot;http:&#x2F;&#x2F;coconut-lang.org&#x2F;&quot;&gt;Coconut Programming Language&lt;&#x2F;a&gt; was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have &lt;a href=&quot;https:&#x2F;&#x2F;thume.ca&#x2F;2017&#x2F;06&#x2F;17&#x2F;tree-diffing&#x2F;&quot;&gt;industry applications&lt;&#x2F;a&gt;. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with &lt;a href=&quot;https:&#x2F;&#x2F;thume.ca&#x2F;2019&#x2F;04&#x2F;29&#x2F;comparing-compilers-in-rust-haskell-c-and-python&#x2F;&quot;&gt;educational findings for engineers in general&lt;&#x2F;a&gt; (also see &lt;a href=&quot;https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20192645&quot;&gt;HackerNews thread&lt;&#x2F;a&gt;). In five weeks, my friend Maas was able to launch &lt;a href=&quot;https:&#x2F;&#x2F;medium.com&#x2F;@maaslalani&#x2F;launch-5d02cc5e05f5&quot;&gt;five relatively successful products&lt;&#x2F;a&gt; while enrolled in Dev Degree.&lt;&#x2F;p&gt;
&lt;p&gt;School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive enviromnment than the startup world. It is fully possible to build useful software and learn &amp;quot;useful&amp;quot; skills while at school. There are also a bunch of other reasons why not to drop out of school and why school is fun, though those have been argued by those more qualified than me.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;freedom-to-work-on-what-you-want&quot;&gt;Freedom to work on what you want&lt;&#x2F;h3&gt;
&lt;p&gt;I covered this a bit in previous sections, but prospective founders (and people and general) tend not to like industry jobs because they don&#x27;t always get the pick the most interesting things to do and have a limited selection to begin with.&lt;&#x2F;p&gt;
&lt;p&gt;Finding a perfect job that lets you do everything you want is pretty hard, but I also think that the free-est industry job is &lt;em&gt;much&lt;&#x2F;em&gt; more free than running a startup, unless answering to shareholders, dealing with recruiting, management and paperwork are things you find interesting. I couldn&#x27;t find many accounts of people with jobs like this, but I know a few personally so I&#x27;ll describe.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Shopify has a team that is dedicated to shorter projects that are created and selected by the team and not demands that are sent from executives.&lt;&#x2F;li&gt;
&lt;li&gt;My own team at Shopify (we worked on &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;oracle&#x2F;truffleruby&quot;&gt;TruffleRuby&lt;&#x2F;a&gt;) was experimental by nature and thus there was a lot of free reign to try things that are the most interesting. Furthermore, Shopify gave me a lot of room to work on + publish blog posts and go to conferences.&lt;&#x2F;li&gt;
&lt;li&gt;Freelance engineers who get to pick their projects and then do them on their own accord. There are also a lot of full-time open source maintainers.&lt;&#x2F;li&gt;
&lt;li&gt;Research jobs or doing a graduate degree where almost anything can go!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;fame-and-recognition&quot;&gt;Fame and Recognition&lt;&#x2F;h3&gt;
&lt;p&gt;I really debated this section since I haven&#x27;t met a founder who was like &amp;quot;oh I&#x27;m doing this so I can be famous and recognized for my talents&amp;quot;. However, I think it&#x27;s a strong desire that rightfully manifests healthily in a lot of founders. I don&#x27;t think I need to give examples for profilic individual contributors, but I also understand that there are &lt;em&gt;less&lt;&#x2F;em&gt; of them than prolific founders. This one is hard to replicate elsewhere though you can certainly get very close.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ambition&quot;&gt;Ambition&lt;&#x2F;h3&gt;
&lt;p&gt;I think this is the one that confuses me the most when people want to become founders. Phrases like &amp;quot;I want to do better than just being another engineer&amp;quot; don&#x27;t really seem to be about ambition.&lt;&#x2F;p&gt;
&lt;p&gt;To be ambitious often means things like wanting to do a Ph.D, become a medical doctor or an astronaut. On that scale, it&#x27;s not &lt;em&gt;really&lt;&#x2F;em&gt; about being better at something you&#x27;re doing (though it partially is), but joining a new game where it&#x27;s supposedly harder. I believe that running a successful startup is indeed harder than being a good engineer and is more ambitious on that axis. However, I think the games are close enough that ambition can easily be matched without changing the game. Setting goals like working at a certain company, promotions (up to positions like CTO) and leading a successful product at a company aren&#x27;t strictly less ambitious than building a successful startup.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;enjoying-risk-passion-about-a-very-specific-product-service-that-can-only-be-done-at-a-startup&quot;&gt;Enjoying risk, Passion about a very specific product&#x2F;service that can only be done at a startup&lt;&#x2F;h3&gt;
&lt;p&gt;Anyway to summarize here&#x27;s a list of reasons I think are particularly convincing for people who want to start a company:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;They want to build something that can&#x27;t be built in any other place. This should be more like &amp;quot;this thing has been bothering me forever and I need to fix it&amp;quot; and less &amp;quot;let&#x27;s go find something to fix&amp;quot;.&lt;&#x2F;li&gt;
&lt;li&gt;Money, fame+recognition&lt;&#x2F;li&gt;
&lt;li&gt;Enjoyment of risk (note that this is somewhat distinct from being adventurous)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;These reasons don&#x27;t really manifest on their own so it&#x27;s hard to evaluate, as I&#x27;m pretty certain all people feel the first point to some extent.&lt;&#x2F;p&gt;
&lt;p&gt;All this to say, I&#x27;m scared that people are too eager to run a startup because it&#x27;s glorified and seems virtuous (brave, hardworking, ambitious, smart, unique) when it&#x27;s secretly not-that-great.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Ideas for Programmers Looking Beyond Web Development</title>
		<published>2020-07-10T00:00:00+00:00</published>
		<updated>2020-07-10T00:00:00+00:00</updated>
		<link href="https://kipp.ly/past-webdev/"/>
		<link rel="alternate" href="https://kipp.ly/past-webdev/" type="text/html"/>
		<id>https://kipp.ly/past-webdev/</id>
		<content type="html">&lt;p&gt;A majority of programmers work in the massive field of web development, because there are so many jobs, resources and problems to solve! This is especially true for self-taught developers like myself or bootcamp grads. With that, there are also many people looking to try something other than web-development, whether it be out of boredom, curiousity or passion for another area of computer science.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m particularly a fan of this, as while web-development got me hooked into programming (and is partially what I do now), exploring other types of work made me a much &lt;em&gt;much&lt;&#x2F;em&gt; better engineer. I think that two months of working on backend development at Shopify helped me grow less than a three-month side project for which I built a very simple raytracer. My experience has also been that it&#x27;s very hard to break out of web development since there&#x27;s activation energy, and it&#x27;s harder to be as impactful, so I&#x27;m hoping this will help.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;projects&quot;&gt;Projects&lt;&#x2F;h2&gt;
&lt;p&gt;Projects listed in vague order of increasing difficulty &#x2F; time committment. I have not done all these of course, but I at least know someone who did &#x2F; have some special respect for the creator.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ray-tracing-in-one-weekend&quot;&gt;Ray Tracing In One Weekend&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;raytracing.github.io&#x2F;books&#x2F;RayTracingInOneWeekend.html&quot;&gt;Link to Book&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is one of the single most impactful projects I&#x27;ve done! With a raytracer you can model objects in 3D space and generate images for what they&#x27;d look like by applying your own colours, angles and lightning. It uses a little bit of math and teaches introductory graphics. The most fun part about raytracing is the development cycle, since you can instantly test software (limited by how fast your computer is) and see the result, without having to worry about hidden bugs.&lt;&#x2F;p&gt;
&lt;p&gt;I estimate for it to take less than a week if you work on it full time and a month if doing it in free time. There is also &amp;quot;Ray Tracing the Next Week&amp;quot; and &amp;quot;Ray Tracing the Rest of Your Life&amp;quot; if you want more!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;llvm-tutorial&quot;&gt;LLVM Tutorial&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;llvm.org&#x2F;docs&#x2F;tutorial&#x2F;&quot;&gt;Link to Tutorial&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The LLVM tutorial helps you to build an entire programming language with LLVM which is insanely fun and relevant to software we use everyday. It also includes teachings about JITs! I recommend &lt;em&gt;not&lt;&#x2F;em&gt; following the OCaml tutorials as the tutorials are old and you&#x27;ll have trouble installing dependencies (like I did). I really like compilers as an area of focus because unlike graphics or GPU programming, your work is relevant to anyone who is a programmer.&lt;&#x2F;p&gt;
&lt;p&gt;I estimate this to take a week full time and 2+ weeks doing it in free time and no more than two months.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;crafting-interpreters&quot;&gt;Crafting Interpreters&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;craftinginterpreters.com&#x2F;contents.html&quot;&gt;Link to Book&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I put this one after the LLVM tutorial just because it is longer, but Crafting Interpreters is an &lt;em&gt;excellent&lt;&#x2F;em&gt; resource. It actually teaches you how to build two interpreters, one with Java and another with C and also covers VMs and garbage collection. I think the type of interpreters you&#x27;ll build through Crafting Interpreters will help you understand CRuby and CPython source code more than the LLVM Tutorial will help you understand Rust source code.&lt;&#x2F;p&gt;
&lt;p&gt;I recommend starting on the second interpreter iff you have a solid impression of how interpreters tend to work and you&#x27;re familiar with programming in C as well as data structures. I estimate the entirety of Crafting Interpreters to take 3 - 6 weeks full time or a few months part time (more variable since it&#x27;s longer and there are more opportunities to challenge yourself).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;spinning-up-in-deep-reinforcement-learning&quot;&gt;Spinning Up in Deep Reinforcement Learning&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;spinningup.openai.com&#x2F;en&#x2F;latest&#x2F;&quot;&gt;Link to Resource&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This collection of resources &#x2F; docs is created by Open AI and generally impressed me in quality of documentation (I generally have very little faith in big companies being able to document things well). It&#x27;s not a tutorial, but is good at giving the full picture (how to get into the career, lingo, example implementations, etc). It also provides two exercises that are fairly long as well as fun information such as PyTorch vs Tensorflow comparisons.&lt;&#x2F;p&gt;
&lt;p&gt;I think of all the resources I listed, this one gets you the closest to a career change (partially just the nature of the ML field). I only list one Machine Learning related resource because other good intro-to-ML guides have good page rank (though I think Spinning Up in Deep RL has underrated pagerank).&lt;&#x2F;p&gt;
&lt;p&gt;Some resources for people who already have some background in AI (read the Wikipedia definitions and did Tensorflow&#x2F;Pytorch tutorials):&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;d2l.ai&#x2F;&quot;&gt;Deep Dive into Machine Learning&lt;&#x2F;a&gt; (a book)&lt;&#x2F;li&gt;
&lt;li&gt;For people vaguely familiar with Machine Learning: (language model focused, sorry)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1706.03762&quot;&gt;All You Need is Attention&lt;&#x2F;a&gt; (a paper)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1810.04805.pdf&quot;&gt;BERT&lt;&#x2F;a&gt; (a paper, though BERT is not the entire name of the paper)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;d4mucfpksywv.cloudfront.net&#x2F;better-language-models&#x2F;language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;GPT2&lt;&#x2F;a&gt; (also a paper, and GPT2 is not the name of the paper)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.alignmentforum.org&#x2F;library&quot;&gt;Collection of Resources about AI Safety&lt;&#x2F;a&gt; (doesn&#x27;t actually need much of a ML background)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;implementing-the-raft-distributed-consensus-system&quot;&gt;Implementing the Raft Distributed Consensus System&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;raft.github.io&#x2F;&quot;&gt;Link to Raft Info Page&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Raft is a consensus algorithm. I&#x27;m not going to describe further, but it&#x27;s an algorithm to solve problems with distributed systems -- something you may be familiar with! Unlike many of the projects I&#x27;ve listed, Raft will require a lot of reading &#x2F; research to build background knowledge. Implementing Raft requires knowledge about operating systems, systems programming in general, networks and concurrency. I feel that it&#x27;ll also test more software engineering skills since the process will include lots of logging, tests and error handling.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m not going to give time estimates about Raft since I&#x27;ve read a lot but haven&#x27;t implemented it. More importantly, it depends on your background. If I had to say, it would be at least a week full time.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;building-an-operating-system&quot;&gt;Building an Operating System&lt;&#x2F;h3&gt;
&lt;p&gt;This one seems fun but I&#x27;ve only briefly attempted it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jvns.ca&#x2F;blog&#x2F;2014&#x2F;03&#x2F;12&#x2F;the-rust-os-story&#x2F;&quot;&gt;Julia Evans on an OS in Rust&lt;&#x2F;a&gt; | &lt;a href=&quot;https:&#x2F;&#x2F;tc.gts3.org&#x2F;cs3210&#x2F;2020&#x2F;spring&#x2F;lab.html&quot;&gt;Georgia Tech Course Materials&lt;&#x2F;a&gt; | &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;cfenollosa&#x2F;os-tutorial###&quot;&gt;OS Tutorial&lt;&#x2F;a&gt; (unmaintained in 2+ years) | &lt;a href=&quot;https:&#x2F;&#x2F;wiki.osdev.org&#x2F;Main_Page&quot;&gt;OS Dev Wiki&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Though challenging and a long project, I recommend OS dev because it&#x27;s a surprisingly common project (you can probably find more resources for this than say, Raft). The difficult parts with this project is that it&#x27;s more open-ended, longer even to get to a minimal project and the development cycle is a bit more painful.&lt;&#x2F;p&gt;
&lt;p&gt;Estimate 4+ weeks full time for a minimal-ish OS.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;miscellaneous&quot;&gt;Miscellaneous&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;Computer Vision&lt;&#x2F;strong&gt;. I didn&#x27;t list any tutorials for this since none are particularly special, but &lt;a href=&quot;https:&#x2F;&#x2F;opencv.org&#x2F;&quot;&gt;OpenCV&lt;&#x2F;a&gt; is powerful and there are a whole bunch of projects that can come out of it! The documentation is not as polished as most web-dev documentation which I think makes it extra fun.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Blockchain&lt;&#x2F;strong&gt;. I&#x27;m generally pretty clueless about blockchain, so not listing any resources but I&#x27;m leaving it here in case anyone has ideas.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Regex&lt;&#x2F;strong&gt;. This is not a career, nor is it distinct from webdev, but it certainly exercises your brain in a different way and is a unique skill! Being able to write regexes off the top of my head has been a great help to my software engineering. I learned&#x2F;practiced through &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;past-webdev&#x2F;regexcrossword.com&#x2F;&quot;&gt;Regex Crosswords&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;activities-and-references&quot;&gt;Activities and References&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;competitive-programming&quot;&gt;Competitive Programming&lt;&#x2F;h3&gt;
&lt;p&gt;Hesistant about including this since it&#x27;s sometimes just &amp;quot;leetcoding&amp;quot; but I think competitive programming was formative to my programming skills. &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;past-webdev&#x2F;codeforces.com&#x2F;&quot;&gt;Codeforces&lt;&#x2F;a&gt; has weekly contests (also see TopCoder, DMOJ). Some of the problems are more traditional data science and algorithms, but sites like Codeforces over Leetcode will have some more adhoc and math focused puzzles. Speaking of math, &lt;a href=&quot;https:&#x2F;&#x2F;projecteuler.net&#x2F;&quot;&gt;Project Euler&lt;&#x2F;a&gt; is also a great source of problems. I also like throwing away writing good code sometimes and just writing code for me!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;kaggle-for-data-science-and-machine-learning&quot;&gt;Kaggle for Data Science and Machine Learning&lt;&#x2F;h3&gt;
&lt;p&gt;Kaggle is a platform where users receive datasets and try to predict &#x2F; compute some values in a contest format. They also have some open datasets with various tutorials on how to work with them, such as the &lt;a href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;c&#x2F;titanic&quot;&gt;Titanic Dataset&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;general-things&quot;&gt;General Things&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;begone-stack-overflow-hello-papers&quot;&gt;Begone Stack Overflow, Hello Papers&lt;&#x2F;h3&gt;
&lt;p&gt;As a web developer, a lot of my learning was throug Stack Overflow, videos and Medium articles. I think my learning of compilers was high-friction because of my unwillingness to read papers (which I&#x27;m still working on). This is not applicable to &lt;em&gt;everything&lt;&#x2F;em&gt;, for example machine learning has a lot of strong Stack Overflow resources through uses of libraries (though you&#x27;ll definitely need to read papers for ML), and for learning to do reverse engineering, individual blog posts with write-ups are probably your best resource. In general, you may have to relearn how you filter &#x2F; search through content.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;open-source&quot;&gt;Open Source&lt;&#x2F;h3&gt;
&lt;p&gt;Something missing from this article is &amp;quot;after I learn these skills, how do I get a job?&amp;quot;, and the reason it&#x27;s missing is because I&#x27;d be talking out of my ass if I tried to answer that. However, I do some know reliable ways through which that has been done and Open Source is definitely one of them!&lt;&#x2F;p&gt;
&lt;p&gt;Spend some time looking into different projects and start working up towards contributions. I recommend larger projects for exposure and also because they&#x27;ll have better support systems for new contributors. I know numerous people who somewhat bypassed education through side projects and gained skills entirely through working on OSS!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>How JIT Compilers are Implemented and Fast: Pypy, LuaJIT, Graal and More</title>
		<published>2020-07-04T00:00:00+00:00</published>
		<updated>2020-07-04T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jits-impls/"/>
		<link rel="alternate" href="https://kipp.ly/jits-impls/" type="text/html"/>
		<id>https://kipp.ly/jits-impls/</id>
		<content type="html">&lt;p&gt;This post goes into details of 5+ JITs and various optimization strategies and discuss how they work with different JITs. Information in this blog post is more &lt;em&gt;depth-first&lt;&#x2F;em&gt;, thus there are many important concepts that may be skipped. That also means that this blogpost is &lt;em&gt;not enough information&lt;&#x2F;em&gt; to draw meaningful conclusions on any comparisons of implementations&#x2F;languages.&lt;&#x2F;p&gt;
&lt;p&gt;For background on JIT compilers see &lt;a href=&quot;https:&#x2F;&#x2F;carolchen.me&#x2F;blog&#x2F;jits-intro&quot;&gt;A Deep Introduction to JIT Compilers: JITs are not very Just-in-time&lt;&#x2F;a&gt;. If the title does not make sense to you then it may be worth a skim.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Mild Disclaimers, can be skipped&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;I will often describe an optimization behaviour and claim that it probably exists in some other compiler. Though I don&#x27;t always check if an optimization exists in another JIT (it&#x27;s sometimes ambiguous), I&#x27;ll always state explicitly if I know it‚Äôs there.
I will also provide code examples to show where an optimization might occur, however the optimization may not necessarily occur for that code because another optimization will take precedence. There may also be some general oversimplifications, but not more than I think exists in most posts like these.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h1 id=&quot;meta-tracing&quot;&gt;(Meta)Tracing&lt;&#x2F;h1&gt;
&lt;p&gt;LuaJIT employs a method called tracing. Pypy does meta-tracing, which involves using a system to generate tracing interpreters and JITs. Pypy and LuaJIT are not the reference implementations of Python or Lua, but projects on their own. I would describe LuaJIT as shockingly fast, and it describes itself as one of the fastest dynamic language implementations -- which I buy fully.&lt;&#x2F;p&gt;
&lt;p&gt;To determine when to start tracing, the interpreting loop will look for &amp;quot;hot&amp;quot; loops to trace (the concept of &amp;quot;hot&amp;quot; code is universal to JITs). Then, the compiler will &amp;quot;trace&amp;quot; the loop, recording executed operations to compile well optimized machine code. In LuaJIT, the compilation is performed on the traces with an instruction-like IR that is unique to LuaJIT.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-pypy-implements-tracing&quot;&gt;&lt;strong&gt;How Pypy Implements Tracing&lt;&#x2F;strong&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Pypy will start tracing a function (which is not always a user defined function) after constant number of 1619 executions, and will compile it after another 1039 executions, meaning a function has to execute around 3000 times for it to start gaining speed. These constants were carefully tuned by the Pypy team (lots of constants are tuned for compilers in general!).&lt;&#x2F;p&gt;
&lt;p&gt;Dynamic languages make it hard to optimize things away. The following code could be statically eliminated by a stricter language, as &lt;code&gt;False&lt;&#x2F;code&gt; will always be falsy. However, in Python 2, that could not have been guaranteed before runtime.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;False&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;FALSE&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For any sane program, the conditional will always be false. Unfortunately, the value of &lt;code&gt;False&lt;&#x2F;code&gt; could be reassigned and thus if the statement were in a loop, it could be redefined somewhere else. For this case, Pypy would build a &amp;quot;guard&amp;quot;. When a guard fails, the JIT will fall back to the interpreting loop. Pypy then uses another constant (200), called &lt;em&gt;trace eagerness&lt;&#x2F;em&gt; to decide whether to compile the rest of the new path till the end of the loop. That sub-path is called a &lt;em&gt;bridge&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Pypy also exposes all those constants as arguments that can be tweaked at execution, along with configuration for unrolling (expanding loops) and inlining! It also exposes some hooks so we can see when things are compiled.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;font-style:italic;color:#ff79c6;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;print_compiler_info&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;type)
&lt;&#x2F;span&gt;&lt;span&gt;pypyjit&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;set_compile_hook&lt;&#x2F;span&gt;&lt;span&gt;(print_compiler_info)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;10000&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;False&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;pass
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(pypyjit&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;get_stats_snapshot&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;counters)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Above, I set up a plain python program with a compile hook to print the type of compilation made. It also prints some data at the end, where I can see the number of guards. For the above I get one compilation of a loop and 66 guards. When I replaced the if statement with just a pass under the for-loop, I was left with 59 guards.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;10000&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;pass &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# removing the `if False` saved 7 guards!
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With these two lines added to the for loop, I will get two compilations, with the new one being of type &#x27;bridge&#x27;!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;randint&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;20&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;False &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;True
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;wait-but-you-said-meta-tracing&quot;&gt;Wait, but you said Meta-tracing!&lt;&#x2F;h3&gt;
&lt;p&gt;The concept behind meta-tracing is ‚Äúwrite an interpreter, get a compiler for free!‚Äù or more magically, ‚Äúturn your interpreter into a JIT-compiler!‚Äù. This is just obviously a great thing, since writing compilers is hard so if we can get a great compiler for free that‚Äôs a good deal. Pypy &amp;quot;has&amp;quot; an interpreter and a compiler, but there‚Äôs no explicit implementation of a traditional compiler.&lt;&#x2F;p&gt;
&lt;p&gt;Pypy has a toolchain called RPython (which was built for Pypy). It is a framework program for implementing interpreters. It is a language in that it specifies a subset of the Python language, namely to force things like static typing. It is a language to write an interpreter in. It is not a language to code in typed-Python, since it doesn‚Äôt care or have things like standard libraries or packages. Any RPython program is a valid Python program. RPython programs are transpiled to C and then compiled. Thus, the RPython meta-compiler exists as a compiled C program.&lt;&#x2F;p&gt;
&lt;p&gt;The ‚Äúmeta‚Äù in meta-tracing comes from the fact that the trace is on the execution of the interpreter rather than the execution of the program. The interpreter more or less behaves as any interpreter, with the added capability of tracing its own operations, and being engineered to optimize those traces by updating the path of the interpreter (itself). With further tracing, the path that the interpreter takes becomes more optimized. With a very optimized interpreter taking a specific, optimized path, the compiled machine code being used in that path from the compiled RPython can be used as the compilation.&lt;&#x2F;p&gt;
&lt;p&gt;In short, the ‚Äúcompiler‚Äù in Pypy is compiling your interpreter, which is why Pypy is sometimes referred to as a meta-compiler. The compiler is less for the program you&#x27;re trying to execute, but rather for compiling the trace of the optimizing interpreter!&lt;&#x2F;p&gt;
&lt;p&gt;Metatracing might be confusing, so I wrote a very bad metatracing program that can only understand &lt;code&gt;a = 0&lt;&#x2F;code&gt; and &lt;code&gt;a++&lt;&#x2F;code&gt;to illustrate.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# interpreter written with RPython
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;line &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;code:
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;line &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a = 0&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;elif &lt;&#x2F;span&gt;&lt;span&gt;line &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a++&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;guard&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;is_int&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# notice how in Python, the type is unknown, but after being interpreted by RPython, the type is known
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;guard&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;&amp;gt; 0&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int_add&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If I ran the following in a hot loop;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++
&lt;&#x2F;span&gt;&lt;span&gt;a&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then the traces may look something like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# Trace from numerous logs of the hot loop
&lt;&#x2F;span&gt;&lt;span&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# guards can go away
&lt;&#x2F;span&gt;&lt;span&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int_add&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;int_add&lt;&#x2F;span&gt;&lt;span&gt;(a, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# optimize trace to be compiled
&lt;&#x2F;span&gt;&lt;span&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;alloc&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# the section of code that executes this trace _is_ the compiled code
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;But the compiler isn&#x27;t some special standalone unit, it&#x27;s built into the interpreter! So the interpreter loop would actually look something like this&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;line &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;code:
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;traces&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;is_compiled&lt;&#x2F;span&gt;&lt;span&gt;(line):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;run_compiled&lt;&#x2F;span&gt;&lt;span&gt;(traces&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;compiled&lt;&#x2F;span&gt;&lt;span&gt;(line))
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;continue
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;elif &lt;&#x2F;span&gt;&lt;span&gt;traces&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;is_optimized&lt;&#x2F;span&gt;&lt;span&gt;(line):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;compile&lt;&#x2F;span&gt;&lt;span&gt;(traces&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;optimized&lt;&#x2F;span&gt;&lt;span&gt;(line))
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;continue
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;elif &lt;&#x2F;span&gt;&lt;span&gt;line &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a = 0&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# ....
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;an-introduction-to-jvms&quot;&gt;An Introduction to JVMs&lt;&#x2F;h2&gt;
&lt;p&gt;Disclaimer: I worked on&#x2F;with a Graal-based language, &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;oracle&#x2F;truffleruby&quot;&gt;TruffleRuby&lt;&#x2F;a&gt; for four months and loved it.&lt;&#x2F;p&gt;
&lt;p&gt;Hotspot (named after looking for &lt;em&gt;hot&lt;&#x2F;em&gt; spots) is the VM that ships with standard installations of Java, and there are multiple compilers in it for a tiered strategy. Hotspot is open source, with 250,000 lines of code which contains the compilers, and three garbage collectors. Though Hotspot is not a tracing JIT, it employs a similar approach of having an interpreter, profiling and then compiling. There is not a specific name for what Hotspot does, though the closest categorization would probably be a method-based JIT (they optimized by method) or a Tiering JIT.&lt;&#x2F;p&gt;
&lt;p&gt;Strategies used in Hotspot inspired many of the subsequent JITs, the structure of language VMs and especially the development of JavaScript engines. It also created a wave of JVM languages such as Scala, Kotlin, JRuby or Jython. JRuby and Jython are fun implementations of Ruby and Python that compile the source code down to the JVM bytecode and then have Hotspot execute it. These projects have been relatively successful at speeding up languages like Python and Ruby (Ruby more so than Python) without having to implement an entire toolchain like Pypy did. Hotspot is also unique in that it&#x27;s a JIT for a less dynamic language (though it&#x27;s technically it&#x27;s a JIT for JVM bytecode and not Java).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;vms.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;GraalVM is a JavaVM and then some, written in Java. It can run any JVM language (Java, Scala, Kotlin, etc). It also supports a Native Image, to allow AOT compiled code through something called Substrate VM. Twitter runs a significant portion of their Scala services with Graal, so it must be pretty good, and better than the JVM in some ways despite being written in Java.&lt;&#x2F;p&gt;
&lt;p&gt;But wait, there&#x27;s more! GraalVM also provides Truffle, a framework for implementing languages through building Abstract Syntax Tree (AST) interpreters. With Truffle, there‚Äôs no explicit step where JVM bytecode is created as with a conventional JVM language, rather Truffle will just use the interpreter and communicate with Graal to create machine code directly with profiling and a technique called partial evaluation. Partial evaluation is out of scope for this blog post, tl;dr it follows metatracing‚Äôs ‚Äúwrite an interpreter, get a compiler for free‚Äù philosophy but is approached differently.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;TruffleJS, the Truffle implementation of JavasScript outperforms the JavaScript V8 engine on select benchmarks which is nifty since V8 has had numerous more years of development, Google money+resources poured in and some crazy skilled people working on it. TruffleJS is still by no means ‚Äúbetter‚Äù than V8 (or other mainstream JS engines) on most measures but it is a sign of promise for Graal.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h1 id=&quot;the-unexpectedly-great-jit-compiler-strategies&quot;&gt;The Unexpectedly Great JIT Compiler Strategies&lt;&#x2F;h1&gt;
&lt;h3 id=&quot;interpreting-c&quot;&gt;Interpreting C&lt;&#x2F;h3&gt;
&lt;p&gt;A common problem with JIT implementations is support for C Extensions. Standard interpreters such as Lua, Python, Ruby, and PHP have a C API, which allows users to build packages in C, thus making the execution significantly faster. Common packages such as &lt;code&gt;numpy&lt;&#x2F;code&gt; or standard library functions such as &lt;code&gt;rand&lt;&#x2F;code&gt; are written in C. These C extensions are vital to having these interpreted languages run quickly in practice.&lt;&#x2F;p&gt;
&lt;p&gt;C extension support is hard to support for a variety of reasons, the most obvious being that the API is modelled on internal implementation details. It&#x27;s easier to have C extensions when the interpreter is written in C! JRuby couldn&#x27;t support C extensions but has a Java extension API. Pypy recently came out with beta support for C extensions, though I&#x27;m not sure how usable it is yet largely due to &lt;a href=&quot;https:&#x2F;&#x2F;www.hyrumslaw.com&#x2F;&quot;&gt;Hyrum&#x27;s Law&lt;&#x2F;a&gt;. LuaJIT does support C extensions, along with additional features in their C extensions (LuaJIT is pretty darn great!)&lt;&#x2F;p&gt;
&lt;p&gt;Graal solves the problem with Sulong, an engine that runs LLVM Bitcode on GraalVM by making LLVM Bitcode a Truffle language. LLVM is a toolchain, though all we need to know about it is that C can be compiled into LLVM Bitcode (Julia also has an LLVM backend!). It&#x27;s a bit weird, but basically the solution is to take a perfectly good 40+ year old compiled language and interpret it! Of course, it&#x27;s not nearly as fast as properly compiling C, but there are a few wins tucked away in here.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;cextensions.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;LLVM Bitcode is already fairly low-level, which means that jitting that IR is not as inefficient as jitting C. Some of that cost is earned back in that the Bitcode can be optimized along with the rest of the Ruby program, whereas a compiled C program could not be. All that allocation removal, inlining, dead code elimination, etc can be run on the C and Ruby code together instead of Ruby code just calling a C binary. Select benchmarks even have TruffleRuby C extensions running faster than CRuby C extensions.&lt;&#x2F;p&gt;
&lt;p&gt;For this system to work, it should be known that the Truffle ASTs are completely language-agnostic and the overhead to switching between C, Java or whatever language in Graal is minimal.&lt;&#x2F;p&gt;
&lt;p&gt;The ability for Graal to work with Sulong is a part of their polyglot features, which provides high interoperability between languages. Not only is it great for the compiler, but it is also a proof of concept for multiple languages easily used in one &amp;quot;application&amp;quot;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;go-back-to-the-interpreted-code-it-ll-be-faster&quot;&gt;Go back to the interpreted code, it&#x27;ll be faster&lt;&#x2F;h3&gt;
&lt;p&gt;We know that JITs come with an interpreter and a compiler, and that they move from the interpreter to the compiler to get faster. Pypy set bridges to take the inverse path, though for Graal and Hotspot, they &lt;em&gt;deoptimize&lt;&#x2F;em&gt;. The terms do not refer to strictly different concepts, but deoptimization refers more to transferring back to the interpreter as a deliberate optimization rather than as a solution to the inevitabilities of dynamic languages. Hotspot and Graal both leverage deoptimization aggressively -- Graal especially as engineers have heavy control over the compilation and need more control over the compilation for optimizations (compared to, say, Pypy). Deoptimization is also used in JS Engines such as V8 which I&#x27;ll discuss a lot as it powers JavaScript in Chrome as well as Node.js.&lt;&#x2F;p&gt;
&lt;p&gt;An important component to making deoptimization fast, is to make sure that switch from the compiler to interpreter is as fast as possible. The most naive implementation would result in the interpreter having to ‚Äúcatch up‚Äù with the compiler in order to be able to make the deopt. Additional complexity exists in dealing with deoptimizing asynchronous threads. To deoptimize, Graal will recreate the stack frames and use a mapping from generated code to return to the interpreter. For threads, safepoints in Java threads are used which are in place for threads to constantly pause and go ‚Äúhi garbage collector, do I stop now?‚Äù so not much overhead is added to handle threads. It‚Äôs a bit rocky, but fast enough to make deoptimization a good strategy.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;deopts.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Similarly to the Pypy bridging example, monkey patching of functions can be deoptimized. The deoptimization there is actually more elegant, as it&#x27;s not a deoptimization that occurs when a guard fails, rather the deoptimizing-code is added where monkey patching occurs.&lt;&#x2F;p&gt;
&lt;p&gt;A great example of a JIT deoptimization is conversion overflow, which refers to when a particular type (say &lt;code&gt;int32&lt;&#x2F;code&gt;) is represented&#x2F;allocated internally but needs to become a &lt;code&gt;int64&lt;&#x2F;code&gt;. This is something that TruffleRuby does through deoptimizations, as well as V8.&lt;&#x2F;p&gt;
&lt;p&gt;Say when you set &lt;code&gt;var = 0&lt;&#x2F;code&gt; in Ruby, you get an &lt;code&gt;int32&lt;&#x2F;code&gt; (Ruby actually calls it Fixnum and Bignum, but I‚Äôll continue saying &lt;code&gt;int32&lt;&#x2F;code&gt; and &lt;code&gt;int64&lt;&#x2F;code&gt;). Whenever you perform an operation on &lt;code&gt;var&lt;&#x2F;code&gt;, you would then have to check if the resulting value overflows. The check is fine mostly, but compiling the code that handles the overflow is expensive, especially given how common numeric operations are.&lt;&#x2F;p&gt;
&lt;p&gt;Even without looking at compiled instructions, we can see how this deoptimization eases the amount of code it takes to handle.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; compiling the check
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; a, b;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; sum &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(overflowed) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; this would also involve some allocation handling for the cpu
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;long&lt;&#x2F;span&gt;&lt;span&gt; bigSum &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; bigSum;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;else &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; sum;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; doing the deoptimisation
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; a, b;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; sum &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(overflowed) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  deoptimize&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;! &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; go back to compiler
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For Truffle languages, it‚Äôs engineered to only deoptimize the first time a specific operation is run, so that the cost of the deopt isn‚Äôt spent every time should an operation consistently overflow.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;wet-code-is-fast-code-inlining-and-osr&quot;&gt;Wet code is fast code - Inlining and OSR&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;javascript&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-javascript &quot;&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;var &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000000&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;foo&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In V8, even something as trivial as that triggers a deopt! With options like&lt;code&gt;--trace-deopt&lt;&#x2F;code&gt; and &lt;code&gt;--trace-opt&lt;&#x2F;code&gt; one can gather a lot of data about the JIT as well as modify behaivour (there are also highly comprehensive tools for Graal, though I‚Äôll be using V8 since people likely have &lt;code&gt;node&lt;&#x2F;code&gt; it installed).&lt;&#x2F;p&gt;
&lt;p&gt;It is the final line (&lt;code&gt;foo(1, 2)&lt;&#x2F;code&gt;) that triggers the deopt, which is puzzling because that exact call is made in the loop! The message is ‚ÄúInsufficient type feedback for call‚Äù (you can find a full list of deopt reasons &lt;a href=&quot;https:&#x2F;&#x2F;chromium.googlesource.com&#x2F;v8&#x2F;v8&#x2F;+&#x2F;roll&#x2F;src&#x2F;deoptimize-reason.h&quot;&gt;here&lt;&#x2F;a&gt;, which funnily includes a ‚Äúno reason‚Äù reason). The output gives us an input frame which shows us the literals &lt;code&gt;1&lt;&#x2F;code&gt; and &lt;code&gt;2&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;So why the deoptimization? V8 should be smart enough to type inference that the type of &lt;code&gt;i&lt;&#x2F;code&gt; is an integer and that the literals passed in are also integers.&lt;&#x2F;p&gt;
&lt;p&gt;I can investigate this by replacing the final line with &lt;code&gt;foo(i, i +1)&lt;&#x2F;code&gt;, but I actually still get a deoptimization, though this time the message is ‚ÄúInsufficient type feedback for binary operation‚Äù, which is still strange!&lt;&#x2F;p&gt;
&lt;p&gt;The answer my friend, is &lt;del&gt;blowing in the wind&lt;&#x2F;del&gt; on-stack replacement (OSR). Inlining is a powerful compiler optimization (not just JITs) in which functions stop being functions and instead the contents are expanded at the call site. JITs can inline by changing the code at runtime to make it faster(compiled languages just inline statically).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; partial output from printing inlining details
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[compiling method 0x04a0439f3751 &amp;lt;JSFunction (sfi = 0x4a06ab56121)&amp;gt; using TurboFan OSR]
&lt;&#x2F;span&gt;&lt;span&gt;0x04a06ab561e9 &amp;lt;SharedFunctionInfo foo&amp;gt;: IsInlineable? true
&lt;&#x2F;span&gt;&lt;span&gt;Inlining small function(s) at call site #49:JSCall
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So V8 will compile &lt;code&gt;foo&lt;&#x2F;code&gt; and determine it is inline-able and inlines it with  with OSR. However, it only performs this inlining for the code within the loop because it&#x27;s the hot path and the last line doesn&#x27;t really exist to the interpreter when this inlining is performed. Thus, V8 still does not have enough type feedback on the function &lt;code&gt;foo&lt;&#x2F;code&gt; because it isn‚Äôt actually used in the loop -- the inlined version is. If I &lt;code&gt;--no-use-osr&lt;&#x2F;code&gt;, then the deoptimization doesn‚Äôt happen - whether I pass a literal or &lt;code&gt;i&lt;&#x2F;code&gt;. Yet without the inlining, even a measly million iterations are noticeably slower. JITs really embody &amp;quot;there are no solutions, only tradeoffs&amp;quot;. Deoptimizations are expensive but not nearly as much as the cost of method lookup and inlining is much preferred in this case.&lt;&#x2F;p&gt;
&lt;p&gt;Inlining is more effective than one might otherwise expect! I ran the code above with a couple extra zeroes, and it was 4 times slower with inlining disabled.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;inliningbench.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Though this is a blog post about JITs, inlining is also really effective for compiled languages. All LLVM languages will inline aggressively (because LLVM will inline), though Julia actually inlines without LLVM because of its jitty nature. JITs can inline with heuristics that come from runtime information, and can switch from not-inlining to inlining with OSR.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;a-note-about-jits-and-the-llvm&quot;&gt;A note about JITs and the LLVM&lt;&#x2F;h3&gt;
&lt;p&gt;A toolchain to consider is LLVM, which provides tools related to compiler infrastructure. Julia works with LLVM (note that it‚Äôs a large toolchain and each language will utilize it differently), as well as Rust, Swift and Crystal. Suffice it to say that it‚Äôs a significant and amazing project that of course also supports JITs, yet there hasn‚Äôt really been any significant dynamic JITs built with the LLVM. JavaScriptCore‚Äôs fourth compiler tier briefly used an LLVM backend but was replaced in less than two years. The LLVM hasn‚Äôt been well suited to dynamic JITs generally because it wasn‚Äôt made to work with the unique challenges of being dynamic. Pypy has tried about 5 or 6 times, but JSC actually went with it! With the LLVM, allocation sinking and code motion were limited. Powerful JIT features like range-inferencing (like type inference, but also knowing the range of a value) were not possible. Most importantly, LLVM comes with expensive compile times, which don&#x27;t matter as much for compiled languages.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;what-if-instead-of-instruction-based-ir-like-everyone-else-we-had-a-big-graph-and-also-it-modifies-itself&quot;&gt;What if instead of instruction based IR like everyone else we had a big graph, and also it modifies itself&lt;&#x2F;h3&gt;
&lt;p&gt;We&#x27;ve taken a look at LLVM bitcode and Python&#x2F;Ruby&#x2F;Java-esque bytecode as IR - and they share the same format of some kind of language that looks like instructions. Hotspot, Graal and V8 have an IR called &amp;quot;Sea of Nodes&amp;quot; (pioneered by Hotspot) which is essentially a lower level AST. One can imagine how Seas of Nodes are effective IR, as much of profiling work is based on a notion of a certain path not being taken often (or being traversed in a particular pattern). Note that these compiler ASTs are distinct from the parser AST.&lt;&#x2F;p&gt;
&lt;p&gt;They&#x27;re also my favourite just to understand my compilation. If you&#x27;ve ever worked with &lt;a href=&quot;https:&#x2F;&#x2F;jax.readthedocs.io&#x2F;en&#x2F;latest&#x2F;notebooks&#x2F;quickstart.html&quot;&gt;JAX&lt;&#x2F;a&gt;, you might&#x27;ve found that reading the compile graphs is useful for finding out why the compiled output is not performing the optimisation you expect. The graphs can be hard to approach, we&#x27;re going to work with some simpler ones.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;igvyikes.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Graal and V8 will both give you text outputs (formatted such that you can get a graph out of them). I&#x27;m not sure how V8 developers generate visual graphs but Oracle provides &amp;quot;Ideal Graph Visualizer&amp;quot;, which is used above. I did not have the energy to reinstall IGV so instead I have graphs from Chris Seaton generated with Seafoam which is not currently open sourced.&lt;&#x2F;p&gt;
&lt;p&gt;Anyway, let us look at a JavaScript AST!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;javascript&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-javascript &quot;&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulate&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;n&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;var &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;var &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;n&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;a&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  }
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulate&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Above is the code that I‚Äôve run through &lt;code&gt;d8 --print-ast test.js&lt;&#x2F;code&gt;, though we only care about the function &lt;code&gt;accumulate&lt;&#x2F;code&gt;. You‚Äôll notice that I only call it once, which means that I don‚Äôt have to wait for any compilation to occur in order to get an AST.&lt;&#x2F;p&gt;
&lt;p&gt;Below is the AST (with some non-essential lines removed)&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;FUNC&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;19
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;NAME &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;accumulate&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;PARAMS
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff5358156f0&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;n&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815798&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;DECLS
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff5358156f0&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;n&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815798&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815930&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;i&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;BLOCK NOCOMPLETIONS&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;EXPRESSION STATEMENT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;38
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;INIT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;38
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;LITERAL 0
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;FOR&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;43
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;INIT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;BLOCK NOCOMPLETIONS&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;EXPRESSION STATEMENT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;56
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;INIT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;56
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815930&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;i&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;LITERAL 0
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;COND&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;61
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;LT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;61
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815930&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;i&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; parameter[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff5358156f0&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;n&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;BODY&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;BLOCK&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;EXPRESSION STATEMENT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;77
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;ASSIGN_ADD&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;79
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; parameter[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815798&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;NEXT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;67
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;EXPRESSION STATEMENT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;67
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;POST INC&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;67
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815930&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;i&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;RETURN&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;91
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is pretty hard to parse, but it actually maps somewhat closely to a parser-level AST (though this won‚Äôt be the case for all programs) which will help. The AST below was generated with Acorn.js&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;acorn.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A distinct difference is the variable declarations. In the parser-AST, no actual declaration is explicit for the parameters, and the declaration for the loop is tucked away under the &lt;code&gt;ForStatement&lt;&#x2F;code&gt; node. In the compiler-level AST, all declarations are grouped, along with addresses and metadata.&lt;&#x2F;p&gt;
&lt;p&gt;The compiler-level AST also uses this wacky &lt;code&gt;VAR PROXY&lt;&#x2F;code&gt; thing. The parser-level AST cannot actually identify which names correspond to which variables (by addresses) due to hoisting and &lt;code&gt;eval&lt;&#x2F;code&gt; and whatnot. So the compiler AST uses PROXY variables that are later connected to the actual variable.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; This chunk is the declarations and the assignment of `x = 0`
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;DECLS
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff5358156f0&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;n&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815798&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;a&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VARIABLE &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815930&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;i&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;BLOCK NOCOMPLETIONS&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;EXPRESSION STATEMENT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;38
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;INIT&lt;&#x2F;span&gt;&lt;span&gt; at &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;38
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR PROXY&lt;&#x2F;span&gt;&lt;span&gt; local[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;] (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0x7ff535815840&lt;&#x2F;span&gt;&lt;span&gt;) (mode &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;VAR&lt;&#x2F;span&gt;&lt;span&gt;, assigned &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;x&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;. . . . &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;LITERAL 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, the same program‚Äôs AST with Graal!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;seafoam.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This of course, looks much simpler. Red is control flow, blue is &lt;del&gt;water&lt;&#x2F;del&gt; data flow, and arrows are directions. Note that the fact that this graph appears simpler than the AST from V8, does not indicate that Graal has better simplified the program. Rather, this graph is generated from Java which is much less dynamic. The same Graal graph generated from Ruby would closer resemble that first photo of the graph.&lt;&#x2F;p&gt;
&lt;p&gt;The fun part about Graal graphs is that these ASTs will actually change depending on execution. This graph was generated by calling the function many times, with random parameters so that the function doesn‚Äôt get optimized away and with OSR and inlining disabled. The dump actually gives you a whole folder of graphs! Graal uses a self-specializing AST to optimize their programs (V8 will make similar optimizations, but not at the AST level). When you dump the Graal graphs you get well over a dozen graphs at different levels of optimization. In node rewriting, nodes replace themselves (specialize) with a different node.&lt;&#x2F;p&gt;
&lt;p&gt;The above graph is a great example of a specialization on a dynamically typed language (image from ‚ÄúOne VM to Rule Them All‚Äù, 2013). The reason for this process to exist ties in closely with how partial evaluation works - it‚Äôs all about the specialization.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;yay-jit-compiled-code-let-s-compile-it-again-and-again&quot;&gt;Yay, JIT compiled code! Let&#x27;s compile it again! And again!&lt;&#x2F;h3&gt;
&lt;p&gt;I&#x27;ve been teasing &amp;quot;Tiering&amp;quot; since Part 1, so let&#x27;s finally get a look into it! It is the simple concept that if we&#x27;re not ready to create the most optimized code yet, but interpreting is still expensive, we can compile early once and then compile again when we&#x27;re ready to generate more optimized code.&lt;&#x2F;p&gt;
&lt;p&gt;Hotspot is a tiering JIT, with two compilers; C1 and C2. The C1 compiler will kick in first and do a quick compile and run then run full profiling to get C2 compiled code. This can help clear up a lot of our concerns with warmup. Unoptimized compiled code is still faster than interpreting and aquiring that unoptimized compiled code is faster. Another fancy thing is that not all code will be compiled by C1 and C2. If a function is deemed trivial enough, it&#x27;s very likely that optimized C2 output will not be helpful and no attempt will be made (and profiling time is saved!). If perhaps C1 is busy compiling, then the profiling can continue and skip C1 to be compiled by C2 directly.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;hotspottiers.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;JavaScript Core tiers even harder! In fact, it has &lt;em&gt;three JITs&lt;&#x2F;em&gt;. JSC&#x27;s interpreter also does light profiling, then moves onto the Baseline JIT, then to the DFG (Data Flow Graph) JIT, and finally to the FTL (Faster than Light) JIT. With these tiers, the meaning of deoptimization is no longer limited to a compiler-to-interpreter path, but deoptimization can happen from the DFG to the Baseline JIT (this doesn&#x27;t seem to be the case for Hotspot C2-&amp;gt;C1). These deoptimizations and passes into the next tier are done through on-stack-replacement.&lt;&#x2F;p&gt;
&lt;p&gt;The Baseline JIT kicks in by 100 executions and the DFG JIT kicks in at about 1000 executions (with exceptions) which means that the JIT gets compiled code much more quickly than say Pypy (which took about 3000 executions). The tiering strategy enables the JIT to try to match the amount of time spent executing the code with the amount of time spent optimizing the code. There are a whole bunch more handy tricks as to which kind of optimizations (inlining, type inferencing, etc) are done at which tier and why that&#x27;s optimal!&lt;&#x2F;p&gt;
&lt;h1 id=&quot;related-readings&quot;&gt;Related Readings&lt;&#x2F;h1&gt;
&lt;p&gt;In vague order of how they&#x27;re related to the blog post.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.freelists.org&#x2F;post&#x2F;luajit&#x2F;How-does-LuaJITs-trace-compiler-work,1&quot;&gt;How LuaJIT&#x27;s Trace Compiler Works from Mike Pall&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;tratt.net&#x2F;laurie&#x2F;research&#x2F;pubs&#x2F;html&#x2F;bolz_tratt__the_impact_of_metatracing_on_vm_design_and_implementation&#x2F;&quot;&gt;Impact of Meta-tracing on VMs by Laurie Tratt&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;morepypy.blogspot.com&#x2F;2010&#x2F;09&#x2F;escape-analysis-in-pypys-jit.html&quot;&gt;Pypy Escape Analysis&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;tratt.net&#x2F;laurie&#x2F;blog&#x2F;entries&#x2F;why_arent_more_users_more_happy_with_our_vms_part_1.html&quot;&gt;Why Users aren&#x27;t More Happy with VMs by Laurie Tratt&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Things About JS Engines&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;flaviocopes.com&#x2F;node-runtime-v8-options&#x2F;&quot;&gt;List of V8 Compiler Options&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;webkit.org&#x2F;blog&#x2F;3362&#x2F;introducing-the-webkit-ftl-jit&#x2F;&quot;&gt;JSCore Replacing their LLVM Backend for a &amp;quot;Faster Than Light&amp;quot; JIT&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Things about Deoptimizations&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;engineering.shopify.com&#x2F;blogs&#x2F;engineering&#x2F;optimizing-ruby-lazy-initialization-in-truffleruby-with-deoptimization&quot;&gt;Deoptimizing TruffleRuby Lazy Initialization by me&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;chrisseaton.com&#x2F;truffleruby&#x2F;deoptimizing&#x2F;&quot;&gt;Deoptimizing Ruby by Chris Seaton&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;v8.dev&#x2F;blog&#x2F;lazy-unlinking&quot;&gt;V8 Lazy Deopts&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Things About Graal&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;lafo.ssw.uni-linz.ac.at&#x2F;papers&#x2F;2013_Onward_OneVMToRuleThemAll.pdf&quot;&gt;One VM to Rule Them All (a paper)&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;chrisseaton.com&#x2F;truffleruby&#x2F;cext&#x2F;&quot;&gt;High Performance C Extensions by Chris Seaton&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;chrisseaton.com&#x2F;truffleruby&#x2F;basic-graal-graphs&#x2F;&quot;&gt;Understanding Graal Graphs by Chris Seaton&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;chrisseaton.com&#x2F;truffleruby&#x2F;tenthings&#x2F;&quot;&gt;Top 10 Things to do with GraalVM by Chris Seaton&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Things about Partial Evaluation&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;stefan-marr.de&#x2F;papers&#x2F;oopsla-marr-ducasse-meta-tracing-vs-partial-evaluation&#x2F;&quot;&gt;Partial Evaluation vs Meta-tracing&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;chrisseaton.com&#x2F;rubytruffle&#x2F;pldi17-truffle&#x2F;pldi17-truffle.pdf&quot;&gt;Paper that introduces partial evaluation for Graal&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Misc&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;jvns.ca&#x2F;blog&#x2F;2016&#x2F;07&#x2F;23&#x2F;rigorous-benchmarking-in-reasonable-time&#x2F;&quot;&gt;Benchmarking correctly is hard by Julia Evans&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>A Deep Introduction to JIT Compilers: JITs are not very Just-in-time</title>
		<published>2020-07-03T00:00:00+00:00</published>
		<updated>2020-07-03T00:00:00+00:00</updated>
		<link href="https://kipp.ly/jits-intro/"/>
		<link rel="alternate" href="https://kipp.ly/jits-intro/" type="text/html"/>
		<id>https://kipp.ly/jits-intro/</id>
		<content type="html">&lt;p&gt;&lt;em&gt;If you are familiar with how JITs generally work (if you get what the title is referring to), I recommend skimming this or going straight to reading &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;jits-impls&quot;&gt;How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More&lt;&#x2F;a&gt;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Someone once told me that compilers are just string in and bytes out and are not at all low-level and scary. This is actually fairly true, and it&#x27;s fun to learn about compiler internals and often useful for programmers everywhere!&lt;&#x2F;p&gt;
&lt;p&gt;This blog post gives background on how programming languages are implemented and how JITs work. It&#x27;ll introduce the implementation details of the Julia language, though it won&#x27;t talk about specific implementation details or optimizations made by more traditional JITs. Check out &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;jits-impls&quot;&gt;How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More&lt;&#x2F;a&gt; to read about how meta-tracing is implemented, how Graal supports C extensions, the relationship of JITs with LLVM and more!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-programming-languages-are-implemented&quot;&gt;How Programming Languages are Implemented&lt;&#x2F;h2&gt;
&lt;p&gt;When we run a program, it‚Äôs either interpreted or compiled in some way. The compiler&#x2F;interpreter is sometimes referred to as the &amp;quot;implementation&amp;quot; of a language, and one language can have many implementations. You may have heard things like &amp;quot;Python is interpreted&amp;quot;, but that really means the reference(standard&#x2F;default) implementation of Python is an interpreter. Python is a language specification and &lt;em&gt;CPython&lt;&#x2F;em&gt; is the interpreter and implementation of Python.&lt;&#x2F;p&gt;
&lt;p&gt;An interpreter is a program that directly executes your code. Well-known interpreters are usually written in C. Ruby, Python and PHP are written in C. Below is a function that loosely models how interpreters work:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;interpret&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;code &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;string&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;code &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;print(&amp;#39;Hello, World!&amp;#39;)&amp;quot; &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;Hello, World&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;  } &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;else if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;code &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;==&lt;&#x2F;span&gt;&lt;span&gt; ‚Äú&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x&lt;&#x2F;span&gt;&lt;span&gt;)‚Äù {
&lt;&#x2F;span&gt;&lt;span&gt;    variable_x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;variable_x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;4
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;x&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;  }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A compiler is a program that translates code from some language to another language, though it usually refers to a destination language that is a machine code. Examples of compiled languages are C, Go and Rust.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;compile&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;code &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;string&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  []&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;byte &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;compiled_code &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;get_machine_code&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;code&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;write_to_executable&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;compiled_code&lt;&#x2F;span&gt;&lt;span&gt;); &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; someone else will execute me later
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The difference between a compiled and interpreted language is actually much more nuanced. C, Go and Rust are clearly compiled, as they output a machine code file - which can be understood natively by the computer. The compile and run steps are fully distinct.&lt;&#x2F;p&gt;
&lt;p&gt;However, compilers can translate to any target language (this is sometimes called transpiling). Java for example, has a two-step implementation. The first is compiling Java source to bytecode, which is an Intermediate Representation (IR). The bytecode is then JIT compiled - which involves interpretation.&lt;&#x2F;p&gt;
&lt;p&gt;Python and Ruby also execute in two steps. Despite being known as interpreted languages, their reference implementations actually compile the source down to a bytecode. You may have seen .pyc files (not anymore in Python3, they&#x27;re better hidden) which contain Python bytecode!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;vm_flow.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The bytecode is then interpreted by a virtual machine. These interpreters use bytecode because programmers tend to care less about compile time, and creating a bytecode language allows the engineers to specify a bytecode language that is as efficient to interpret as possible.&lt;&#x2F;p&gt;
&lt;p&gt;Having bytecode is how languages check syntax before execution (though they could technically just do a pass before starting the interpreter). An example below shows why you would want to check syntax before runtime.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;sleep&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1000&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;bad syntax beep boop beep boop
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Interpreted languages are typically slower for various reasons, the most obvious being that they&#x27;re executed in a higher level language that has overhead execution time. The main reason is that the dynamic-ness of the languages they tend to implement means that they need many extra instructions to decide what to do next and how to route data. People still choose to build interpreters over compilers because they&#x27;re easier to build and are more suited to handle things like dynamic typing, scopes etc (though it is not logically impossible build a compiler that has the same features).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;so-what-is-a-jit&quot;&gt;So What is a JIT?&lt;&#x2F;h3&gt;
&lt;p&gt;A JIT compiler doesn&#x27;t compile code Ahead-Of-Time (AOT), but still compiles source code to machine code and therefore is not quite an interpreter. JITs compile code at runtime, while your program is executing. Again, a loose model;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;jit_compile&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;functions &lt;&#x2F;span&gt;&lt;span&gt;[]&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;string&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= range &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;functions &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    compiled_fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;get_machine_code&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;function&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;compiled_fn&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;execute&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span&gt;  }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This gives the JITs flexibility for dynamic language features, while maintaining speed from optimized machine code output. JIT-compiling C would make it slower as we&#x27;d just be adding the compilation time to the execution time. JIT-compiling Python would be fast, as compilation + executing machine code can often be faster than interpreting. JITs improve implementations in speed by being able to optimise (compile) on information that is only available at runtime.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;julia-a-jit-compiler-that-s-just-in-time&quot;&gt;Julia: a JIT Compiler that&#x27;s Just-in-time&lt;&#x2F;h3&gt;
&lt;p&gt;A common theme between compiled languages is that they&#x27;re statically typed. That means when the programmer creates or uses a value, they‚Äôre telling the computer what type it is and that information is guaranteed at compile time.&lt;&#x2F;p&gt;
&lt;p&gt;Julia is dynamically typed, but internally Julia is much closer to being statically typed.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;julia&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-julia &quot;&gt;&lt;code class=&quot;language-julia&quot; data-lang=&quot;julia&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;multiply&lt;&#x2F;span&gt;&lt;span&gt;(x, y)
&lt;&#x2F;span&gt;&lt;span&gt;  x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt; y
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;end
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here is an example of a Julia function, which could be used to multiply integers, floats, vectors, strings etc (Julia allows operator overloading). Compiling out the machine code for &lt;em&gt;all&lt;&#x2F;em&gt; these cases is not very productive for a variety of reasons, which is what we&#x27;d have to do if we wanted Julia to be a compiled language. Idiomatic programming means that the function will probably only be used by a few combinations of types and we don&#x27;t want to compile something that we don&#x27;t use yet since that&#x27;s not very jitty (this is not a real term).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;If I were to code &lt;code&gt;multiply(1, 2)&lt;&#x2F;code&gt;, then Julia will compile a function that multiplies integers.&lt;&#x2F;li&gt;
&lt;li&gt;If I then wrote &lt;code&gt;multiply(2, 3)&lt;&#x2F;code&gt;, the already-compiled code will be used.&lt;&#x2F;li&gt;
&lt;li&gt;If I added &lt;code&gt;multiply(1.4, 4)&lt;&#x2F;code&gt;, another version of the function will be compiled.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We can observe what the compilation does with &lt;code&gt;@code_llvm multiply(1, 1)&lt;&#x2F;code&gt;, which generates LLVM Bitcode (not quite machine code, but a lower-level Intermediate Representation).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;haskell&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-haskell &quot;&gt;&lt;code class=&quot;language-haskell&quot; data-lang=&quot;haskell&quot;&gt;&lt;span&gt;define i64 @julia_multiply_17232(i64, i64) {
&lt;&#x2F;span&gt;&lt;span&gt;top&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îå @ int&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;54&lt;&#x2F;span&gt;&lt;span&gt; within `*&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; mul i64 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îî
&lt;&#x2F;span&gt;&lt;span&gt;  ret i64 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And with &lt;code&gt;multiply(1.4, 4)&lt;&#x2F;code&gt;, you can see how complicated it can get to compile even one more function. In AOT compiled Julia, all of these combinations would have to live in the compiled code even if only one was used, along with the control flow to delegate.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;haskell&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-haskell &quot;&gt;&lt;code class=&quot;language-haskell&quot; data-lang=&quot;haskell&quot;&gt;&lt;span&gt;define double @julia_multiply_17042(double, i64) {
&lt;&#x2F;span&gt;&lt;span&gt;top&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îå @ promotion&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;312&lt;&#x2F;span&gt;&lt;span&gt; within `*&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ‚îå @ promotion&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;282&lt;&#x2F;span&gt;&lt;span&gt; within `promote&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ‚îÇ‚îå @ promotion&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;259&lt;&#x2F;span&gt;&lt;span&gt; within `_promote&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ‚îÇ‚îÇ‚îå @ number&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;7&lt;&#x2F;span&gt;&lt;span&gt; within `convert&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ‚îÇ‚îÇ‚îÇ‚îå @ float&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;60&lt;&#x2F;span&gt;&lt;span&gt; within `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;Float64&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; sitofp i64 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt; to double
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ‚îî‚îî‚îî‚îî
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îÇ @ promotion&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;312&lt;&#x2F;span&gt;&lt;span&gt; within `*&amp;#39; @ float&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;jl&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;405
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; fmul double &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0
&lt;&#x2F;span&gt;&lt;span&gt;; ‚îî
&lt;&#x2F;span&gt;&lt;span&gt;  ret double &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;%&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The general strategy of ‚Äúassume a type and compile&#x2F;behave based on that‚Äù is called type inferencing, which Julia mildly uses in the examples above. There are a lot of other compiler optimizations that are made, though none of them are very specific to JITs as Julia may be better described as a lazy AOT compiler.&lt;&#x2F;p&gt;
&lt;p&gt;The simplicity of this kind of jitting makes it easy for Julia to also supply AOT compilation. It also helps Julia to benchmark very well, definitely a tier above languages like Python and comparable to C.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;so-what-is-a-jit-take-two&quot;&gt;So What is a JIT? Take Two.&lt;&#x2F;h3&gt;
&lt;p&gt;Julia is actually the jittiest JIT in the original sense of the term, which was for production lines. As a JIT, it is the least interesting type and not canonically JIT compiled in the compilers sense! It compiles code right before the code needs to be used -- &amp;quot;just in time&amp;quot;. Most JITs however (Pypy, Java, JS Engines), are not at all about compiling code just-in-time, but compiling &lt;em&gt;optimal&lt;&#x2F;em&gt; code at an &lt;em&gt;optimal&lt;&#x2F;em&gt; time. In some cases that time is never. In other cases, compilation occurs more than once. In many cases where code is compiled, it doesn&#x27;t occur until after the source code has been executed numerous times, and the JIT will stay in an interpreter as the overhead to compilation is too high to be valuable.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;jits&#x2F;jitbrr.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The other aspect at play is generating &lt;em&gt;optimal code&lt;&#x2F;em&gt;. Assembly instructions are not created equal, and compilers will put a lot of effort into generating well-optimized machine code. Usually, it is possible for a human to write better assembly than a compiler (though it would take a fairly smart and knowledgeable human), because the compiler cannot dynamically analyze your code. By that, I mean things like knowing the possible range of your integers or what keys are in your map, as these are things that a computer could only know after (partially) executing your program. A JIT compiler can do those things because it interprets your code first and gathers data from the execution. Thus, JITs are expensive in that they interpret, and add compilation time to execution time, but they make it up in highly optimised compiled code. With that, the timing of compilation is also dependent on whether the JIT has gathered enough valuable information.&lt;&#x2F;p&gt;
&lt;p&gt;The cool part about JITs is that I was sort of lying when I said a JIT implementation of C could not be faster than existing compiled implementations. It would not be feasible to try, but jit-compiling C in the way I just described is not a strict superset of compiling a language and thus it is not logically impossible to compile code fast enough to make up for the compile+profile+interpreting time. If I &amp;quot;JIT compiled&amp;quot; C similarly to how Julia does it (statically compile each function as it&#x27;s called), it would be impossible to make it faster than compiled-C as the compile-time is non-negative and the generated machine code is essentially the same.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;pogo&quot;&gt;Pogo&lt;&#x2F;h2&gt;
&lt;p&gt;Though jitting C is not feasible, one can find a middle ground through Profile Guided Optimization (PGO, cutely [and uncommonly] pronounced ‚Äúpogo‚Äù). Instead of profiling while executing, you compile a program with PGO profiling, run that program and then recompile the original program with profiled data passed in. This is effective at reducing compiled-code size and improving branch prediction.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h3 id=&quot;warm-it-up&quot;&gt;Warm it up&lt;&#x2F;h3&gt;
&lt;p&gt;JITs have a concept of warming up. Because intepretation and profiling time is expensive, JITs will start by executing a program slowly and then work towards &amp;quot;peak performance&amp;quot;. For JITs with interpreted counterparts like Pypy, the JIT without warmup performs much worse at the beginning of execution due to the overhead of profiling. It&#x27;s also the reason that JITs will consume signifcantly more memory.&lt;&#x2F;p&gt;
&lt;p&gt;Warmup adds complexity to measuring efficiency of a JIT! It&#x27;s fine if you&#x27;re measuring the performance of generating the mandelbrot set, but becomes painful if you&#x27;re serving a web application and the first N requests are painfully slow. It means that Javascript is relatively less performant as a command line tool than it is for a webserver. It‚Äôs complicated by the fact that the performance doesn‚Äôt strictly increase. If Pypy decides it needs to compile many things all at once after JITs compiling some functions, then you might have a slow-down in the middle. It also makes benchmark results more ambiguous, as you have to check if the jitted languages were given time to warmup, but you‚Äôd also want to know if it took an unseemly amount of time to warmup. Optimizing your compiled code &lt;em&gt;and&lt;&#x2F;em&gt; warmup speed is unfortunately zero-sum(or at least small-sum) by nature. If you try to get your code to compile sooner, less data will be available, the compiled code will not be as efficient and peak performance will be lower. Aiming for higher peak performance of course, often means higher profiling costs.&lt;&#x2F;p&gt;
&lt;p&gt;Java and Javascript engines are examples of JITs that have put really good care into warmup time, but you may find that languages built for academic uses have monstrous warmup times in favour of snazzy peak performances.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;more-jits-how-jit-compilers-are-implemented-and-fast-julia-pypy-luajit-graal-and-more&quot;&gt;&amp;gt; More JITs: &lt;a href=&quot;https:&#x2F;&#x2F;kipp.ly&#x2F;blog&#x2F;jits-impls&quot;&gt;How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Talks about implementation of tracing JITs and meta-tracing JITs, specifically LuaJIT and Pypy&lt;&#x2F;li&gt;
&lt;li&gt;Introduces GraalVM, Hotspot and goes deeper into Javascript Engines. Goes through Tiering, Seas of Nodes, deoptimization and inlining.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Some Thoughts on Giving</title>
		<published>2020-05-12T00:00:00+00:00</published>
		<updated>2020-05-12T00:00:00+00:00</updated>
		<link href="https://kipp.ly/some-thoughts-on-giving/"/>
		<link rel="alternate" href="https://kipp.ly/some-thoughts-on-giving/" type="text/html"/>
		<id>https://kipp.ly/some-thoughts-on-giving/</id>
		<content type="html">&lt;p&gt;So my recent thoughts about giving have been about how much I give (time, objects, money) out of guilt, and how much good actually comes out of what I give.&lt;&#x2F;p&gt;
&lt;p&gt;Ideally, what I give should be very helpful by some measure, and I should not do have to it out of guilt or responsibility. I got the second one down early, as my giving throughout high school was mostly in organizing educational events or writing open source software. Late in high school, I became familiar with a movement called &lt;a href=&quot;https:&#x2F;&#x2F;www.effectivealtruism.org&#x2F;&quot;&gt;Effective Altruism&lt;&#x2F;a&gt; which really got me thinking about how relatively useless spending tens of thousands of dollars and more man hours than I can count organizing a three-day programming contest for college kids is.&lt;&#x2F;p&gt;
&lt;p&gt;And so began a guilt trip! All those charity ads about starving African children, abused women, abandoned puppies etc made me feel shitty about myself and the world, not that there&#x27;s any wrong with that kind of advertising. It did make me want to give, not out of generosity or care but because I felt like I didn&#x27;t deserve things I had, and that I shouldn&#x27;t be happy. I hide away from things that make me feel guilt or disgust like that, because those are negative emotions that feel bad. I like feeling &lt;em&gt;happy&lt;&#x2F;em&gt;, but what if I could expand the amount of things that make me feel happy? So I pulled a pretty selfish move and didn&#x27;t donate until I could be happy and confident doing so.&lt;&#x2F;p&gt;
&lt;p&gt;So here are the things I did &#x2F; went through to get myself feeling good, and &amp;quot;guilt-free&amp;quot; about donating. This ended with me donating 10,000 to the Future of Humanity Institute, about 20% of my untaxed income over the past two years.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Ask your friends to convince you. I &lt;em&gt;want&lt;&#x2F;em&gt; to be convinced that giving away some money would be good feel good. I care about my friends&#x27; opinions, and so talking to my friends in effective altruism was helpful. At the same time, I&#x27;m very against peer pressure so watch out for that!&lt;&#x2F;li&gt;
&lt;li&gt;Research what it costs to do X for another person. Think about how much you&#x27;d spend to get that for yourself, a friend or a stranger on the street.&lt;&#x2F;li&gt;
&lt;li&gt;Think about what your &amp;quot;worst case&amp;quot; is. This sounds depressing, but was helpful for me since I was taking money away from potential family illness, unemployment or need to pay tuition. These cases are highly unlikely, and more importantly, my worst case situations did not seem significantly more frightening with some missing money.&lt;&#x2F;li&gt;
&lt;li&gt;De-guilting by thinking about hedonic adaptation. When I hear about people struggling my empathetic brain signals go off and I start feeling very very bad, because if that happened to me tomorrow I &lt;em&gt;think&lt;&#x2F;em&gt; I&#x27;d be in incredible pain. It&#x27;s usually true that things are better than one expects them to be (there are studies on this too) and also that people can reestablish a base line.&lt;&#x2F;li&gt;
&lt;li&gt;Calibrate against your mind-tricks playing with your emotions. I realized I would instantly pay 5000+ to save a stranger dying right in front of me, but maybe not even want to spend money to save people in the future.&lt;&#x2F;li&gt;
&lt;li&gt;Think less about saving current lives, and more about saving future lives. This is also in line with being effective, as a general concept is that there are more people in the future than there are in the present. It&#x27;s much harder to feel guilt-tripped when the message is more &amp;quot;people in the future might be sad!&amp;quot;&lt;&#x2F;li&gt;
&lt;li&gt;Think about how much money you actually need &#x2F; use. What amount of coveniences or luxuries compares to the live of another human being? What amount is unused? I personally found that I was being too cautious with saving money.&lt;&#x2F;li&gt;
&lt;li&gt;Pick an issue that you&#x27;re passionate about, and feel positively about. I donated to the Future of Humanity Institute to work on human-aiding research and development. One of their focusus in AI Alignment, and as someone who works at an AI company, I care about the issue and can enjoy reading their research. They also study existential risk, biotechnology and fund altruistically motivated researchers -- all of which are pretty great and interesting to me.&lt;&#x2F;li&gt;
&lt;li&gt;Look into giving tax-efficiently! Canada will let you claim 15-29% in tax credits!&lt;&#x2F;li&gt;
&lt;li&gt;It&#x27;s satisfying! Being able to donate and be happy doing so is just &lt;em&gt;so great&lt;&#x2F;em&gt;. It means that you can feel more like you have an abundance of resources, which is a wonderful freeing feeling. You can spend your money to buy yourself happiness, affect your character and be a positive impact for the world. Honestly, I self-hypnotized a bit and repeated these concepts to myself to get here.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;But where do I stop? How do I live with myself eating out almost every day in a nice apartment and buying clothes I only wear once or twice? Well haha I&#x27;m selfish I suppose. I don&#x27;t have very clear thoughts about this yet, but I&#x27;m happy giving an amount I feel comfortable with you everyone else should too!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Working At Shopify Is Great</title>
		<published>2020-04-20T00:00:00+00:00</published>
		<updated>2020-04-20T00:00:00+00:00</updated>
		<link href="https://kipp.ly/real-good-things-about-internships/"/>
		<link rel="alternate" href="https://kipp.ly/real-good-things-about-internships/" type="text/html"/>
		<id>https://kipp.ly/real-good-things-about-internships/</id>
		<content type="html">&lt;p&gt;I mainly wrote this blog post to help advertise Shopify as a great place to intern at, but I&#x27;m sure all of these aspects can be found at other great companies, though maybe not all at one company&#x2F;team. I recommend this blog post not only for those looking to apply to Shopify, but to know how great internships can be and what qualities you would want from an internship.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m currently writing this in my last week at Shopify as I have decided to go elsewhere full-time, though I still love Shopify enough that I chose to intern there over joining a YCombinator cohort! It is a very special place to be, which is also why I returned three times (started interning at Shopify in Summer 2018).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;flexibility&quot;&gt;flexibility&lt;&#x2F;h2&gt;
&lt;p&gt;This is an underlying factor in a lot of other things I&#x27;ll talk about, but I like that Shopify doesn&#x27;t often have &amp;quot;rules&amp;quot; for anything. Shopify let me do two (two month) internships to accommodate for my two-month summers. They also let me work part-time after I graduated! Most importantly, they don&#x27;t require interns to be enrolled in a bachelor&#x27;s degree program bringing epic diversity to intern classes from people with degrees in other fields or former chefs. I got the same epic flexibility at Hatch Canada, working part-time and being allowed to work on projects of my choosing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;room-to-do-all-the-learning&quot;&gt;room to do all the learning&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;d say I&#x27;m three times better of a programmer than I was when I started at Shopify. It happen partially through the classic &amp;quot;learning on the job&amp;quot;. By building applications and getting code reviews from coworkers I became a better programmer. However, I think the key that made learning on the job effective was being able to ask a shitload of questions. Shopify was good at building an environment where I felt I could do that without feeling like I was asking bad questions or bothering anyone. This let me spend less time confused, make better decisions, learn about things I could apply in the future (or just sate curiosity).&lt;&#x2F;p&gt;
&lt;p&gt;Another great thing is that I had the room to dedicate time to learning. That included working through a book, reading papers or attending conferences. Shopify funded me buying textbooks and I felt alright taking a day to read up on a subject. I often spent time going down rabbit holes of reading even after completing a task. I was approved to go to Japan for a conference (cancelled due to COVID-19) and spent a day attending a workshop on VMs (didn&#x27;t even bother getting approval for that).&lt;&#x2F;p&gt;
&lt;p&gt;Learning is good. Especially in internships, your focus should be investing in yourself and great companies should want to invest in you (within reason of course).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;impact&quot;&gt;impact&lt;&#x2F;h2&gt;
&lt;p&gt;A lot of companies end up giving interns a special project of sorts. While the project may be substantial, interesting and potentially impactful, they often get iced as soon as the intern leaves. This may not be valuable to &lt;em&gt;everyone&lt;&#x2F;em&gt;, but at Shopify I was apart of the weekly sprints and worked on producing features and fixes that other engineers were actually relying on. Not having intern projects would also help you better understand how much you&#x27;d enjoy working at a company full-time. The downside of course, is that you might not actually have anything to call &amp;quot;your own&amp;quot; and you will lose engineering time to things like planning meetings (which are important and fun too!). But then... the next section.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;being-a-champion&quot;&gt;being a champion&lt;&#x2F;h2&gt;
&lt;p&gt;For my third internship at Shopify, I switched from the Facebook team to a neighbouring team with people I had worked with in the past (so it was still fairly familiar). It was a bit weird, as for those four months I&#x27;d be working part-time at 20 hours a week. This would make it hard for me to be involved in day-to-day work, especially with it being Black Friday Cyber Monday (huge week for Shopify). So, I went on to champion my own project where I extended an open source app into being able to generate code (Rails and NodeJS) to build Marketing Activity extensions. This meant that I was the lead on the project, and was responsible for informing stakeholders on the status. I interacted with numerous teams and became the &amp;quot;person to go to&amp;quot; for information on the project. Yes, there was a risk of it ending up more like an intern project, but that&#x27;s why it was also apart of the job to communicate with other teams and do health checks to make sure the project was ontrack and useful. Though it was not a huge project, it was exciting, impactful and &amp;quot;my own&amp;quot;!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;company-exposure-beyond-where-you-re-working&quot;&gt;company exposure beyond where you&#x27;re working&lt;&#x2F;h2&gt;
&lt;p&gt;My first four months at Shopify were on the Facebook Ads &#x2F; Instagram Checkout team, where we worked on an application for Shopify merchants to be able to directly advertise on Facebook through Shopify and to sell products via Instagram. Throughout my time there, I not only worked with the Facebook API but was in contact with Facebook engineers about goals and for technical support. The Facebook team also flew in to work with us and have social events, which was pretty fun! These experiences were unique, and helped me exercise some remote-working communication skills (which are really being tested during this quarantine).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;writing-for-an-engineering-blog&quot;&gt;writing for an engineering blog&lt;&#x2F;h2&gt;
&lt;p&gt;At the beginning of my current internship, I wrote a blog post about the first PR I shipped. The Engineering Blog doesn&#x27;t have any special barrier for interns submitting work - if you did something cool, you can write about it! Through writing the post, I was able to talk to some cool folks on the Eng Comms team and sharpen my shoddy writing skills. My post now lives on &lt;a href=&quot;https:&#x2F;&#x2F;engineering.shopify.com&#x2F;blogs&#x2F;engineering&#x2F;optimizing-ruby-lazy-initialization-in-truffleruby-with-deoptimization&quot;&gt;Shopify Engineering Blog&lt;&#x2F;a&gt;! It was great exposure for a personal brand to, as the post made it to the top post of Hacker News and stayed on the front page for over twelve hours.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;people-who-really-care&quot;&gt;people who really care&lt;&#x2F;h2&gt;
&lt;p&gt;This is the aspect I think Shopify is likely most special for, and the reason I was most afraid to leave Shopify. I always felt like my team members and lead had my best interests, and wanted to make sure that I felt productive and happy at Shopify. Weekly 1:1s, frequent kind words and so many other things really brought this together. Our CTO reached out to me to compliment me for my blog post. When the company went remote due to COVID-19, I got a personal message from my Director making sure that I was doing alright (which was ridiculous because he was dealing with being quarantined with kids) along with a little casual chat. Shopify didn&#x27;t even let go of culinary workers when we went remote. The list could go on! Choosing to leaving Shopify was a really emotional experience (I cried when verbally turning down the offer) because of all the kindness, patience and care people there have offered me.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;So keep an eye out for Shopify internships postings, and go do internships in general! Internships at Shopify run three times a year (January, May, September) for 4 to 8 months. Applications open 4 months before start dates~&lt;&#x2F;p&gt;
&lt;p&gt;Feel free to email email me with &lt;em&gt;your&lt;&#x2F;em&gt; name at kipp dot ly with any questions about choosing internships, or questions about working at Shopify or anything! Courage to talk to strangers on the internet will earn you my respect &amp;lt;3. However, please try to avoid questions along the lines of &amp;quot;how do I get an internship?&amp;quot; as quite frankly I don&#x27;t have insight beyond knowing exactly what I did (some of which I have forgotten). Requests for resume reviews, for example, is something I could actually help out with.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Optimizing Laziness in TruffleRuby with Deoptimization</title>
		<published>2020-03-25T00:00:00+00:00</published>
		<updated>2020-03-25T00:00:00+00:00</updated>
		<link href="https://kipp.ly/optimizing-laziness-in-truffleruby-with-deoptimization/"/>
		<link rel="alternate" href="https://kipp.ly/optimizing-laziness-in-truffleruby-with-deoptimization/" type="text/html"/>
		<id>https://kipp.ly/optimizing-laziness-in-truffleruby-with-deoptimization/</id>
		<content type="html">&lt;p&gt;This was published by the Shopify Engineering blog, so I won&#x27;t duplicate the content but here is a &lt;a href=&quot;https:&#x2F;&#x2F;engineering.shopify.com&#x2F;blogs&#x2F;engineering&#x2F;optimizing-ruby-lazy-initialization-in-truffleruby-with-deoptimization&quot;&gt;link!&lt;&#x2F;a&gt; Corresponding &lt;a href=&quot;https:&#x2F;&#x2F;engineering.shopify.com&#x2F;blogs&#x2F;engineering&#x2F;optimizing-ruby-lazy-initialization-in-truffleruby-with-deoptimization&quot;&gt;HN thread&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;On the bright side, on my personal site I can give it the bad-joke-title that I originally proposed.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>patience, humour, empathy. kindness, selflessness and honesty.</title>
		<published>2020-03-13T00:00:00+00:00</published>
		<updated>2020-03-13T00:00:00+00:00</updated>
		<link href="https://kipp.ly/patience-humour-empathy/"/>
		<link rel="alternate" href="https://kipp.ly/patience-humour-empathy/" type="text/html"/>
		<id>https://kipp.ly/patience-humour-empathy/</id>
		<content type="html">&lt;p&gt;there are some personality traits that make you a good person. kindness, selflessness and honesty are the kind of traits that are part of value systems. in some systems, if you&#x27;re mean you&#x27;re bad. if you&#x27;re selfish you&#x27;re bad. if you&#x27;re a liar, bad.&lt;&#x2F;p&gt;
&lt;p&gt;there are other good attributes like patience and humour. most people appreciate these things, but few would call you bad for being impatient, and less would call you bad for never being funny. might not be everyone&#x27;s stroke, but it&#x27;s not usually a part of an ethics system. im talking about ethical bad, and not aesthetics bad.&lt;&#x2F;p&gt;
&lt;p&gt;my claim is that empathy is not good. certainly not actively bad either, and probably aesthetically good. being unkind is bad because it hurts other people. in most ethics systems, this is bad. there is an easy case that empathy is an extension of this. if you don&#x27;t understand other people, then you won&#x27;t know what hurts them, and then you&#x27;ll hurt them. if you don&#x27;t empathize, then where&#x27;s the incentive to be good to them?&lt;&#x2F;p&gt;
&lt;p&gt;the entire reasoning for this claim, is that the above pipeline has too many steps! my other complaint, is that the notion of empathy being good, means that people without it must be bad.&lt;&#x2F;p&gt;
&lt;p&gt;rich capitalists who donate money are often criticized. not enough money, just doing it for the publicity, not actually caring about the cause. the first two, referring to selfishness and dishonesty are bad, but lack of empathy on its own is not a bad. side note that i&#x27;m on the fence on selfishness being bad.&lt;&#x2F;p&gt;
&lt;p&gt;this is convenient for a bunch of reasons, for example to serve my utilitarian ideals where many people who donate to poverty or health causes without any kind of empathy. or for people on the autism spectrum who often lack empathy, but it would be a shame and very likely inaccurate to consider them less morally good.&lt;&#x2F;p&gt;
&lt;p&gt;a conclusion for this blurb, is probably not anything you can use to live your life? i find it a helpful model, as i value ethical good and aesthetic good very differently and sometimes with people i like to attribute their traits incorrectly to better serve an misled desire.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Python History Since the Fifteenth Century</title>
		<published>2020-02-24T00:00:00+00:00</published>
		<updated>2020-02-24T00:00:00+00:00</updated>
		<link href="https://kipp.ly/python-history-since-the-fifteenth-century/"/>
		<link rel="alternate" href="https://kipp.ly/python-history-since-the-fifteenth-century/" type="text/html"/>
		<id>https://kipp.ly/python-history-since-the-fifteenth-century/</id>
		<content type="html">&lt;p&gt;When we study history in high school, we read about the history of machine guns, cars, printing press, etc. I imagine that some time in the future, students may sit down and read about the early programming languages and their development.&lt;&#x2F;p&gt;
&lt;p&gt;This post is a brain-dump of some fun things I know about Python, most of which are fairly non-technical. These are not the most fun things as I tried to avoid writing about things that were already nicely summarized, but they will at least be tastefully boring!&lt;&#x2F;p&gt;
&lt;h1 id=&quot;inspiration&quot;&gt;Inspiration&lt;&#x2F;h1&gt;
&lt;p&gt;In the mid 1980s, Guido van Rossum was working on ABC, a generally unpopular high-level language intended for teaching and prototyping. Based on his frustrations with ABC, Guido wanted Python to have a large and powerful standard library. Python (first released in 1991) would soon be joined by Java (released in 1995) in having such a standard library.&lt;&#x2F;p&gt;
&lt;p&gt;Contrary to C, Lisp (and lisp dialects) and Ruby, Python does not allow statements inside an expression. For example, &lt;code&gt;if (x = y)&lt;&#x2F;code&gt; (or more practically, &lt;code&gt;if (line = readline(file))&lt;&#x2F;code&gt;) could be used in C though Python does not allow them. The goal here was probably to make Python easy to use and to protect its users from common errors such as accidentally typing &lt;code&gt;x = y&lt;&#x2F;code&gt; instead of &lt;code&gt;x == y&lt;&#x2F;code&gt;. But also uhh... there&#x27;s a &lt;a href=&quot;https:&#x2F;&#x2F;www.python.org&#x2F;dev&#x2F;peps&#x2F;pep-0572&#x2F;&quot;&gt;walrus operator&lt;&#x2F;a&gt; (&lt;code&gt;:=&lt;&#x2F;code&gt;) for assignment expressions in Python 3.8 so maybe I just lied.&lt;&#x2F;p&gt;
&lt;p&gt;From Haskell and Lisp, Python inherited support for functional programming, with &lt;code&gt;filter&lt;&#x2F;code&gt;, &lt;code&gt;map&lt;&#x2F;code&gt; and &lt;code&gt;reduce&lt;&#x2F;code&gt;. Python documentation lists the &lt;code&gt;itertools&lt;&#x2F;code&gt; module under Functional Programiming Modules and credits Standard ML, APL and Haskell for its constructs.&lt;&#x2F;p&gt;
&lt;p&gt;Syntactically, Python was unique in not taking on many braces or brackets as C, Lisp and Java would. It introduced keywords such as &lt;code&gt;and&lt;&#x2F;code&gt; and &lt;code&gt;or&lt;&#x2F;code&gt; rather than &lt;code&gt;&amp;amp;&amp;amp;&lt;&#x2F;code&gt; and &lt;code&gt;||&lt;&#x2F;code&gt;. This is inline with Python&#x27;s philosophy, which we&#x27;ll dive into later.&lt;&#x2F;p&gt;
&lt;p&gt;Python is fairly different from many of its predecessors, though the language Guido wanted to be most different from is Perl. TMTOWTDI (pronounced &amp;quot;Tim Toady&amp;quot;) is a Perl motto which stands for &amp;quot;There&#x27;s more than one way to do it&amp;quot;. One of Python&#x27;s design principles, published in the &amp;quot;Zen of Python&amp;quot; in 1999 is &amp;quot;There should be one ‚Äî and preferably only one ‚Äî obvious way to do it&amp;quot;, directly conflicting with Perl.&lt;&#x2F;p&gt;
&lt;p&gt;Also, it was influenced by some actual art. Specifically, Python was named after Monty Python.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;oh-yeah-there-are-some-people-you-should-know&quot;&gt;Oh yeah there are some people you should know&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Guido van Rossum.&lt;&#x2F;strong&gt; Benevolent Dictator for Life, until of course he stepped down on 12 July 2018 and now sits on a steering council of five.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Tim Peters.&lt;&#x2F;strong&gt; Made Timsort (what Python and V8 uses). Wrote the Zen of Python, was on Python&#x27;s board of directors from 2001-2014 and got involved in the early 1990s.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Barry Warsaw.&lt;&#x2F;strong&gt; Core Python developer since mid 90&#x27;s. Used to be the lead maintainer of Jython, a Java implementation of Python. Currently employed by LinkedIn to work on Python.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;case-study-the-increment-decrement-operators&quot;&gt;Case Study: The Increment&#x2F;Decrement Operators&lt;&#x2F;h1&gt;
&lt;p&gt;Many question why in Python one cannot do &lt;code&gt;x++&lt;&#x2F;code&gt; or &lt;code&gt;x--&lt;&#x2F;code&gt; especially since it&#x27;s a common thing for people to know, is less characters than &lt;code&gt;x += 1&lt;&#x2F;code&gt;, etc etc. Its existence not hugely relevant to Python programmers, but the reasons why it doesn&#x27;t exist reveals a lot about Python.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Zen of Python &amp;quot;There should be one ‚Äî and preferably only one ‚Äî obvious way to do it&amp;quot;.&lt;&#x2F;li&gt;
&lt;li&gt;ABC never had that operator, so it may have been a fairly intuitive decision.&lt;&#x2F;li&gt;
&lt;li&gt;It might&#x27;ve been implemented by C just for an optimization as the instructions for &lt;code&gt;x++&lt;&#x2F;code&gt; could be more easily optimized (&lt;a href=&quot;http:&#x2F;&#x2F;www.bell-labs.com&#x2F;usr&#x2F;dmr&#x2F;www&#x2F;chist.html&quot;&gt;source&lt;&#x2F;a&gt;).&lt;&#x2F;li&gt;
&lt;li&gt;Python is serious about keeping its LL parser, which would make &lt;code&gt;++&lt;&#x2F;code&gt;a bit a pain to differentiate from &lt;code&gt;+ +&lt;&#x2F;code&gt;. (&lt;code&gt;--3&lt;&#x2F;code&gt;will evaluate to &lt;code&gt;3&lt;&#x2F;code&gt; in Python)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The most obvious reason of course, is that Guido didn&#x27;t want anyone making Python++.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;some-weird-shit-for-else&quot;&gt;Some Weird Shit: For...Else&lt;&#x2F;h1&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;42&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;== -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;This will not happen&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;break
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;else&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;Will this?&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The answer is yes, yes it does happen!&lt;&#x2F;p&gt;
&lt;p&gt;If a loop does not break, Python will try to go to an else block.&lt;&#x2F;p&gt;
&lt;p&gt;Is this a stupid feature? Probably. There seems to be just... a bunch of better and more readable ways to do this. I&#x27;m not even going to give an example since there are so many reasons why you might want this kind of logic flow.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s not forget that brilliant Zen of Python line. &amp;quot;There should be one-- and preferably only one --obvious way to do it.&amp;quot; Not only are there many ways to do this, a &lt;code&gt;for...else&lt;&#x2F;code&gt; statement is certainly the least obvious way.&lt;&#x2F;p&gt;
&lt;p&gt;The Zen of Python has many thoughts. The follow up to that line is &amp;quot;Although that way may not be obvious at first unless you&#x27;re Dutch.&amp;quot; The Dutch is referring to none other than Guido himself. So yeah, maybe this is just a mistake that Python made and can never walk back from, since there are definitely people out there using this thing. You can read the mailing list issue about it here (https:&#x2F;&#x2F;mail.python.org&#x2F;pipermail&#x2F;python-ideas&#x2F;2009-October&#x2F;006155.html)&lt;&#x2F;p&gt;
&lt;p&gt;But how did it end up here in the first place you ask?&lt;&#x2F;p&gt;
&lt;p&gt;Basically this kind of thing became a feature because Donald Knuth used it, and everyone knew about what Donald Knuth does so it made sense. It also made more sense when people used gotos to model their logic flow more frequently as all the loops had a if statement and goto.
The entire &lt;code&gt;for...else&lt;&#x2F;code&gt; block can logically be thought of one piece of code, and the break just jumps to the end and ignores the else. If it doesn&#x27;t break, then it continues to the else block. You can also &lt;code&gt;try...else&lt;&#x2F;code&gt;!&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-zen-of-python&quot;&gt;The Zen of Python&lt;&#x2F;h1&gt;
&lt;p&gt;Now that we&#x27;ve talked about two points of the text, let&#x27;s look at the whole thing.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#282a36;color:#f8f8f2;&quot;&gt;&lt;code&gt;&lt;span&gt;Beautiful is better than ugly.
&lt;&#x2F;span&gt;&lt;span&gt;Explicit is better than implicit.
&lt;&#x2F;span&gt;&lt;span&gt;Simple is better than complex.
&lt;&#x2F;span&gt;&lt;span&gt;Complex is better than complicated.
&lt;&#x2F;span&gt;&lt;span&gt;Flat is better than nested.
&lt;&#x2F;span&gt;&lt;span&gt;Sparse is better than dense.
&lt;&#x2F;span&gt;&lt;span&gt;Readability counts.
&lt;&#x2F;span&gt;&lt;span&gt;Special cases aren&amp;#39;t special enough to break the rules.
&lt;&#x2F;span&gt;&lt;span&gt;Although practicality beats purity.
&lt;&#x2F;span&gt;&lt;span&gt;Errors should never pass silently.
&lt;&#x2F;span&gt;&lt;span&gt;Unless explicitly silenced.
&lt;&#x2F;span&gt;&lt;span&gt;In the face of ambiguity, refuse the temptation to guess.
&lt;&#x2F;span&gt;&lt;span&gt;There should be one-- and preferably only one --obvious way to do it.
&lt;&#x2F;span&gt;&lt;span&gt;Although that way may not be obvious at first unless you&amp;#39;re Dutch.
&lt;&#x2F;span&gt;&lt;span&gt;Now is better than never.
&lt;&#x2F;span&gt;&lt;span&gt;Although never is often better than *right* now.
&lt;&#x2F;span&gt;&lt;span&gt;If the implementation is hard to explain, it&amp;#39;s a bad idea.
&lt;&#x2F;span&gt;&lt;span&gt;If the implementation is easy to explain, it may be a good idea.
&lt;&#x2F;span&gt;&lt;span&gt;Namespaces are one honking great idea -- let&amp;#39;s do more of those!
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can get the Zen of Python in a handy Easter Egg, by writing &lt;code&gt;import this&lt;&#x2F;code&gt;. I&#x27;ll let you think about the irony of that easter egg (line 2 &lt;em&gt;cough cough&lt;&#x2F;em&gt;). Oh and that line I&#x27;ve brought up over and over again? It does something two ways, neither of which are obvious!&lt;&#x2F;p&gt;
&lt;p&gt;I know you probably don&#x27;t care how the Easter Egg was implemented, since well, it&#x27;s a string. But you should, because it looks like this;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;s &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Gur Mra bs Clguba, ol Gvz Crgref
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Ornhgvshy vf orggre guna htyl.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Rkcyvpvg vf orggre guna vzcyvpvg.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Fvzcyr vf orggre guna pbzcyrk.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Pbzcyrk vf orggre guna pbzcyvpngrq.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Syng vf orggre guna arfgrq.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Fcnefr vf orggre guna qrafr.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Ernqnovyvgl pbhagf.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Fcrpvny pnfrf nera&amp;#39;g fcrpvny rabhtu gb oernx gur ehyrf.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Nygubhtu cenpgvpnyvgl orngf chevgl.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Reebef fubhyq arire cnff fvyragyl.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Hayrff rkcyvpvgyl fvyraprq.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Va gur snpr bs nzovthvgl, ershfr gur grzcgngvba gb thrff.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Gurer fubhyq or bar-- naq cersrenoyl bayl bar --boivbhf jnl gb qb vg.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Nygubhtu gung jnl znl abg or boivbhf ng svefg hayrff lbh&amp;#39;er Qhgpu.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Abj vf orggre guna arire.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Nygubhtu arire vf bsgra orggre guna *evtug* abj.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Vs gur vzcyrzragngvba vf uneq gb rkcynva, vg&amp;#39;f n onq vqrn.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Vs gur vzcyrzragngvba vf rnfl gb rkcynva, vg znl or n tbbq vqrn.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;Anzrfcnprf ner bar ubaxvat terng vqrn -- yrg&amp;#39;f qb zber bs gubfr!&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;d &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;{}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;c &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;65&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;97&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;26&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;        d[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;chr&lt;&#x2F;span&gt;&lt;span&gt;(i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span&gt;c)] &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;chr&lt;&#x2F;span&gt;&lt;span&gt;((i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;13&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;% &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;26 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;c)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;join&lt;&#x2F;span&gt;&lt;span&gt;([d&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;get&lt;&#x2F;span&gt;&lt;span&gt;(c, c) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;c &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;s]))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Nice one Tim.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;some-actual-history-1991-to-2000&quot;&gt;Some Actual History: 1991 to 2000&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;February 1991:&lt;&#x2F;strong&gt; 0.9.0 published to alt.sources&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;January 1994:&lt;&#x2F;strong&gt; Python 1.0&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;1995: Numpy&lt;&#x2F;strong&gt; (Numeric at the time)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;30 April 1999:&lt;&#x2F;strong&gt; Non font-size changing CSS added to docs. THE NEW AGE OF THE INTERWEBS!&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;16 October 2000:&lt;&#x2F;strong&gt; Python 2.0&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;could-i-get-the-time-what-s-that-it-s-false&quot;&gt;Could I get the time? What&#x27;s that, it&#x27;s False?&lt;&#x2F;h1&gt;
&lt;p&gt;From the Python 3.5 changelog;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Before Python 3.5, a datetime.time object was considered to be false if it represented midnight in UTC. This behavior was considered obscure and error-prone and has been removed in Python 3.5.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Umm, ok I guess. This wasn&#x27;t really a mistake, this behaviour was correctly documented. And, it&#x27;s consistent behaviour ish. 0 in general is a falsy thing. &lt;code&gt;0&lt;&#x2F;code&gt;, &lt;code&gt;[]&lt;&#x2F;code&gt;, etc etc.&lt;&#x2F;p&gt;
&lt;p&gt;It was actually raised as an issue in 2012, by someone who thought it was a bug. It was passed on because of the reasons stated above, but people came back about this in 2014! Particularly, this weird behaviour made doing &lt;code&gt;if timeobj&lt;&#x2F;code&gt; (where &lt;code&gt;timeobj&lt;&#x2F;code&gt; might be set to some falsy value) useless. Someone made a good argument that this type of &lt;code&gt;0&lt;&#x2F;code&gt; shouldn&#x27;t count the way that others do, as time cannot really be multiplied and such and thus doesn&#x27;t really represent a numeric value in the traditional sense. It wasn&#x27;t fixed (released) until September 2015!&lt;&#x2F;p&gt;
&lt;h1 id=&quot;some-actual-history-2000-to-2010&quot;&gt;Some Actual History: 2000 to 2010&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;January 17, 2001:&lt;&#x2F;strong&gt; Jython was created&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2003:&lt;&#x2F;strong&gt; BOOLEANS CAME TO PYTHON! Oddly late, C got their booleans in 1999. Also it&#x27;s implemented as a subclass of Integer, since 0 and 1 is what people used before and that&#x27;s why you can do arithmetic with Booleans!&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2005:&lt;&#x2F;strong&gt; Django, a popular web framework was born.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;December 2005:&lt;&#x2F;strong&gt; Reddit written in Python &amp;lt;3&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2006&lt;&#x2F;strong&gt;: Python 3 development commences&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2007:&lt;&#x2F;strong&gt; Pypy, a JIT compiled super fast Python that can&#x27;t actually run most production applications for various reasons was released.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;June 2007:&lt;&#x2F;strong&gt; Dropbox starts building in Python&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2008&lt;&#x2F;strong&gt;: EOL for Python 2 declared for 2015.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;3 December 2008:&lt;&#x2F;strong&gt; Python 3.0&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;also-randall-munroe&quot;&gt;Also, Randall Munroe&lt;&#x2F;h1&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;antigravity
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Doing that will open a page with this image;
&lt;img src=&quot;https:&#x2F;&#x2F;imgs.xkcd.com&#x2F;comics&#x2F;python.png&quot;&#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s how it&#x27;s implemented;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;webbrowser
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;hashlib
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;webbrowser&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;open&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;quot;https:&#x2F;&#x2F;xkcd.com&#x2F;353&#x2F;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ff79c6;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;geohash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;latitude&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;longitude&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;datedow&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&amp;#39;&amp;#39;&amp;#39;Compute geohash() using the Munroe algorithm.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;    &amp;gt;&amp;gt;&amp;gt; geohash(37.421542, -122.085589, b&amp;#39;2005-05-26-10458.68&amp;#39;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;    37.857713 -122.544543
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;    &amp;#39;&amp;#39;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;# https:&#x2F;&#x2F;xkcd.com&#x2F;426&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    h &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;hashlib&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;md5&lt;&#x2F;span&gt;&lt;span&gt;(datedow)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;hexdigest&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    p, q &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;[(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;%f&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;#39; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;% &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;float&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;fromhex&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;#39;0.&amp;#39; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;x)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;x &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span&gt;(h[:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;16&lt;&#x2F;span&gt;&lt;span&gt;], h[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;16&lt;&#x2F;span&gt;&lt;span&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;32&lt;&#x2F;span&gt;&lt;span&gt;])]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;%d%s %d%s&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f1fa8c;&quot;&gt;&amp;#39; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;% &lt;&#x2F;span&gt;&lt;span&gt;(latitude, p[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;:], longitude, q[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;:]))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We have Skip Montanaro (recently retired, congrats!) to thank for this!&lt;&#x2F;p&gt;
&lt;h1 id=&quot;some-actual-history-2010-to-present&quot;&gt;Some Actual History: 2010 to Present&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2012:&lt;&#x2F;strong&gt; Skulpt, an entirely in-browser implementation of Python was created. Pretty wild project if you ask me.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2013:&lt;&#x2F;strong&gt; Guido goes to Dropbox!&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2014&lt;&#x2F;strong&gt;: January 1, 2020 declared as EOL for Python2, only five years late!&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;November 9, 2015:&lt;&#x2F;strong&gt; Tensorflow (ML library built by Google) was released.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;October 2016:&lt;&#x2F;strong&gt; PyTorch was released (built by Facebook)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;July 2018:&lt;&#x2F;strong&gt; Guido steps down as BFDL&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;2018:&lt;&#x2F;strong&gt; RustPython, a python interpreter written in Rust comes into existence.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;January 2019:&lt;&#x2F;strong&gt; Steering Council Elected&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;October 2019:&lt;&#x2F;strong&gt; Guido leaves Dropbox&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;January 1st 2020&lt;&#x2F;strong&gt;: GOODBYE PYTHON 2. New decade, new Python.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;this-used-to-be-silly-episode-2-the-gil&quot;&gt;This Used to be Silly Episode 2: the GIL&lt;&#x2F;h1&gt;
&lt;p&gt;The GIL is silly! Well, no not really it&#x27;s pretty important and hard to remove. The Global Interpreter Lock makes it so that Python code cannot actually be executed in parallel, so threads are executed concurrently in a way where they&#x27;re &amp;quot;running at the same time&amp;quot;, but never both running at a given time.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s not just a &amp;quot;Python was implemented this way so we&#x27;re stuck with it&amp;quot; thing going on here. Pypy came along and it kept the GIL. Ruby has a GIL. OCaml has a GIL. JS just...doesn&#x27;t have threads. Yeah yeah, IronPython and Jython got rid of the GIL, but I&#x27;d like to hammer it in that there is a great argument for the GIL to be great.&lt;&#x2F;p&gt;
&lt;p&gt;So the silly part is what it was like before Python 3.2.&lt;&#x2F;p&gt;
&lt;p&gt;If you were to divide work between two threads, you&#x27;d imagine that it would be slightly slower than having one thread run it, since the time it takes for the GIL to be passed around cannot be &amp;lt;= 0. The keyword there is slightly. What you&#x27;d get before Python 3.2 is that it could be twice as slow. Oh no.&lt;&#x2F;p&gt;
&lt;p&gt;A quick description of the problem lies in how the GIL was implemented. The logic for it resulted in a system, where every so often (very often), a thread that might be waiting for the GIL will jump up and scream for the GIL, another thread will probably say &amp;quot;no you can&#x27;t have it, that&#x27;s mine&amp;quot; and the other thread will just keep jumping up and down and wasting time. The new implementation used an approach that was a bit more &amp;quot;Ok I&#x27;m done with the GIL now, who wants it?&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;This is a very high level abstraction and somewhat misleading. But tl;dr the GIL was being silly for a long time and no one fixed it. You can watch &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ph374fJqFPE&quot;&gt;Dave Beazely&#x27;s talk&lt;&#x2F;a&gt; on it.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;hall-of-fame-of-things-that-were-broken-for-a-long-time-and-no-one-noticed-non-python-related&quot;&gt;Hall of Fame of things that were broken for a long time and no one noticed non-Python related&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Tim Peters is brilliant not only for Python but also for Timsort! It&#x27;s used by Python, JS and the millions of Java things. That algorithm was designed in 2002. In 2015, some guys tried to formally verify it, and found it was broken! &lt;a href=&quot;http:&#x2F;&#x2F;envisage-project.eu&#x2F;wp-content&#x2F;uploads&#x2F;2015&#x2F;02&#x2F;sorting.pdf&quot;&gt;Link to paper&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;The &lt;code&gt;left-pad&lt;&#x2F;code&gt; &lt;a href=&quot;https:&#x2F;&#x2F;www.theverge.com&#x2F;2016&#x2F;3&#x2F;24&#x2F;11300840&#x2F;how-an-irate-developer-briefly-broke-javascript&quot;&gt;shenanigans&lt;&#x2F;a&gt;. Basically, npm didn&#x27;t have any fallback or handling if the dependency of a dependency of a... got removed. So when the tiniest package left npm, everything exploded! Most apps just stopped running. Rust with their package manager cargo just didn&#x27;t let people remove packages (not in a breaking way at least), somehow npm missed that.&lt;&#x2F;li&gt;
&lt;li&gt;Knight Capital had a bug that disrupted the NYSE and also lost them $460 million! This isn&#x27;t the strict definition of broken, but there was so much broken in their systems that I have 0 surprise this happened. They received 97 emails about an incorrect configuration after a deploy at 8AM, an hour before trading opened which should&#x27;ve been good warning to rollback, delay or at least throttle. By 10AM, the 460 million was lost. They let that shit run for 45 minutes! The error occurred because devops team failed to update one of the 8 servers. The old code that caused the failure had been obsolete for 9 years. Dead code should be considered a bug, thank you.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;legacy&quot;&gt;Legacy&lt;&#x2F;h1&gt;
&lt;h3 id=&quot;julia&quot;&gt;Julia&lt;&#x2F;h3&gt;
&lt;p&gt;Julia quotes &amp;quot;We want something as usable for general programming as Python&amp;quot; on their &lt;a href=&quot;https:&#x2F;&#x2F;julialang.org&#x2F;blog&#x2F;2012&#x2F;02&#x2F;why-we-created-julia&#x2F;&quot;&gt;Why We Created Julia&lt;&#x2F;a&gt; post. Though Julia is fundamentally different by being JITed-ish and more static, their common use in data science showcases some fundamental similarities.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ruby&quot;&gt;Ruby&lt;&#x2F;h3&gt;
&lt;p&gt;The creator of Ruby, Matz said &amp;quot;I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python&amp;quot;. It took on a similar engineering path by having a VM (YARV) and creating bytecode for it! Ruby also has a lot of similar syntax such as not having brackets and built itself a very large standard library. A huge difference however, is that Ruby has a lot more complicated grammer (probably inherited through Perl, along with some other crap) through the use of an LALR parser instead of Python&#x27;s home-grown LL parser.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;go&quot;&gt;Go&lt;&#x2F;h3&gt;
&lt;p&gt;Several companies have actually migrated from Python to Go, a symbol of success for Go. On their &lt;a href=&quot;https:&#x2F;&#x2F;golang.org&#x2F;doc&#x2F;faq&quot;&gt;FAQ&lt;&#x2F;a&gt; they list a few reasons as to how Python affected them. The big thing was that go wanted static typing, while keeping a &amp;quot;fluid&amp;quot; language the way Python does. This is a huge win for Go, as I feel a large part of their goal is to encourage good code (and there&#x27;s a general consensus that typing is good for that). Unlike many other languages that are more recently made, Go keeps the braces. Go basically ran away from all the fluidity that Python, Ruby and Julia have.&lt;&#x2F;p&gt;
&lt;p&gt;Dropbox has migrated some important components to Go, along with maintaining Go packages. Twitch rewrote their IRC chat system in Go. Uber rewrote some vital datastores workers in Go.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;end-of-post-ramble&quot;&gt;End of Post Ramble&lt;&#x2F;h1&gt;
&lt;p&gt;In general, syntax is a big one for Python&#x27;s influence, with CoffeeScript and Swift joining the list.&lt;&#x2F;p&gt;
&lt;p&gt;Python&#x27;s usage in machine learning is the one thing that will keep Python in the history books. When the future aliens or whatnot study the development of AI, they&#x27;ll remember the language that footed it.&lt;&#x2F;p&gt;
&lt;p&gt;Python has also footed pieces of internet history, including Wikipedia, Facebook, Amazon and Google. Though it may not be in the history books, Doki Doki Literature Club is a popular video game built in Python and maybe it&#x27;ll be games like that to make a retro comeback the same way we have emulators for old consoles today!&lt;&#x2F;p&gt;
&lt;p&gt;I tried to come up with a tl;dr to this post, but I don&#x27;t really have one. I started writing with the intention of showing people how important Python will be to history, but I got carried away with random Python stuffs in my head but I guess that&#x27;s fine.&lt;&#x2F;p&gt;
&lt;p&gt;I cited sources &#x2F; provided additional content where I deemed it would be helpful (ie hard to find with a quick Google). If anyone has questions about anything, please email me with &lt;em&gt;your&lt;&#x2F;em&gt; name at kipp dot ly. I did quite a bit of research on everything I wrote here.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Carnivorous Plant Collection (Image Heavy)</title>
		<published>2019-09-09T00:00:00+00:00</published>
		<updated>2019-09-09T00:00:00+00:00</updated>
		<link href="https://kipp.ly/carnivorous-plants/"/>
		<link rel="alternate" href="https://kipp.ly/carnivorous-plants/" type="text/html"/>
		<id>https://kipp.ly/carnivorous-plants/</id>
		<content type="html">&lt;p&gt;From late grade nine to early grade twelve, I collected hundreds of individual plants and over a dozen different species. Below a crapton of photos I could find, though right here I&#x27;ll include a list of plants I have owned.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Dionaea Muscipula&lt;&#x2F;li&gt;
&lt;li&gt;Sarracenia purpurea&lt;&#x2F;li&gt;
&lt;li&gt;Utricularia vulgarius&lt;&#x2F;li&gt;
&lt;li&gt;Nepenthes ampullaria&lt;&#x2F;li&gt;
&lt;li&gt;Nepenthes ventrata&lt;&#x2F;li&gt;
&lt;li&gt;Pinguicula Zerchi x Agnata&lt;&#x2F;li&gt;
&lt;li&gt;Pinguicula Moraensis&lt;&#x2F;li&gt;
&lt;li&gt;Pinguicula Vulgaris&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Capensis alba&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Capensis red&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Spatulata&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Hamiltonii&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Aliciae&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Binata&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Intermedia&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Indica&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Tokaensis&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Natalensis&lt;&#x2F;li&gt;
&lt;li&gt;Drosera Burmannii red&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Everyone asks WHY I have this hobby, and the answer is that when I started high school there was a cute boy who was interested in it and using my highly rational mind, I decided this was the obvious way to impress him. It did not work, but I did end up genuinely loving these babies &amp;lt;3 My first drosera that was gifted to me is named Gordon (rest in peace buddy).&lt;&#x2F;p&gt;
&lt;p&gt;Some interesting facts about these plants!&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Most of them grow in pure peat moss. Alternative soils &#x2F; other fertizilers will often kill them. Because of this, I also have to wash the soil before using it.&lt;&#x2F;li&gt;
&lt;li&gt;They can also grow in live peat moss. I got live peat moss for my plants at one point and it looked beautiful.&lt;&#x2F;li&gt;
&lt;li&gt;Some of these plants (namely pinguicula) require cold stratification, where the seeds are left in the freezer in a humid plastic bag to simulate going through winter.&lt;&#x2F;li&gt;
&lt;li&gt;Some of these plants are native to Canada! Others are not and had to be protected in a baggie because my house is too cold :(&lt;&#x2F;li&gt;
&lt;li&gt;Some of these plants took months to germinate, making them all the more special &amp;lt;3 &amp;lt;3 &amp;lt;3&lt;&#x2F;li&gt;
&lt;li&gt;I often cut the flower stalk before it bloomed, as many plants die after flowering.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Next goal:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;As soon as I have a more permanent place on residence, I plan on collecting succulents and cacti!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;1.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;2.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;3.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;4.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;5.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;6.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;7.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;8.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;9.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;10.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;11.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;12.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;13.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;14.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;15.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;16.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;17.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;18.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;19.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;20.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;21.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;22.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;23.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;24.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;25.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;26.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;27.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;28.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;29.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;30.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;31.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;32.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;33.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;34.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;35.jpg&quot; alt=&quot;&quot; &#x2F;&gt;
&lt;img src=&quot;..&#x2F;img&#x2F;carnivorousplants&#x2F;36.jpg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Group Hugging Theory</title>
		<published>2019-08-09T00:00:00+00:00</published>
		<updated>2019-08-09T00:00:00+00:00</updated>
		<link href="https://kipp.ly/group-hugging-theory/"/>
		<link rel="alternate" href="https://kipp.ly/group-hugging-theory/" type="text/html"/>
		<id>https://kipp.ly/group-hugging-theory/</id>
		<content type="html">&lt;p&gt;While one-on-one hugging is complicated enough as it is, the complications increase exponentially as number of people involved in the hug increase.&lt;&#x2F;p&gt;
&lt;p&gt;There are many intricacies with the one-on-one hug, such as whether you should have arms above or below the shoulders, how long and tightly you should hug, etc. But the general logistics of how the hug comes together is fairly simple.&lt;&#x2F;p&gt;
&lt;p&gt;With three people, it&#x27;s also fairly doable to have a decent hug, as such;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;grouphugs&#x2F;3personhug.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The three person hug is also fairly intuitive, I&#x27;ve rarely seen it done incorrectly.&lt;&#x2F;p&gt;
&lt;p&gt;With a four person hug, a problem arises. You&#x27;ll notice that the people on the outside are getting less hug.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;grouphugs&#x2F;4personhug.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;At around five people, things start going to hell.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;grouphugs&#x2F;5personhug.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;What is this garbage??? Why does it look like a huddle? Are we playing football? At least it&#x27;s better than going into &amp;quot;flower petal&amp;quot; mode, where people form a circle hugging people on the inside. Flower petal mode causes dramatic imbalance with the amount of hug each person gets.&lt;&#x2F;p&gt;
&lt;p&gt;There has to be a better way! Luckily, I&#x27;ve been able to engineer a new formation that works perfectly for 5+ person group hugs.&lt;&#x2F;p&gt;
&lt;p&gt;This is a Donut Hug!&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Stand in a circle with your group, with each person facing another person&#x27;s back&lt;&#x2F;li&gt;
&lt;li&gt;Each person should place their hand on the waist of the person in front of them.&lt;&#x2F;li&gt;
&lt;li&gt;On a loose (not totally necessary) count down, have all participants move into hug formation, hugging the person in front of them from behind.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Why is the Donut Hug optimal for group hugs?&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Equal hugs for everyone by virtue of the cyclic formation. No one feeling awkward or left out.&lt;&#x2F;li&gt;
&lt;li&gt;Hugs are even better quality than one-on-one hugs. With average human sizes, each person can hug two people in front of them.&lt;&#x2F;li&gt;
&lt;li&gt;Extra contact point with less than 12 people, as the circle closes in a way where your sides touch people on the inside of the circle&lt;&#x2F;li&gt;
&lt;li&gt;Not line-like, making it a good position for communication.&lt;&#x2F;li&gt;
&lt;li&gt;Hugging from the back is extra intimate.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>10 Tips for a Winning Hackathon Project</title>
		<published>2018-09-14T00:00:00+00:00</published>
		<updated>2018-09-14T00:00:00+00:00</updated>
		<link href="https://kipp.ly/hackathon-tips/"/>
		<link rel="alternate" href="https://kipp.ly/hackathon-tips/" type="text/html"/>
		<id>https://kipp.ly/hackathon-tips/</id>
		<content type="html">&lt;p&gt;It&#x27;s been almost been about three years since my first hackathon and I&#x27;ve now won prizes at nine hackathons (more if you count meme&#x2F;small hackathons), organized judging at a hackathon and was a judge myself twice. Crafting the perfect project is certainly isn&#x27;t a science, but I&#x27;ve found some things that usually work‚Ñ¢.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-don-t-skimp-on-the-brainstorming&quot;&gt;1. Don&#x27;t skimp on the brainstorming.&lt;&#x2F;h2&gt;
&lt;p&gt;Most hackathons work out to judge with 25% from technical difficulty. Some hackathons might value usability as another 25% which could also be related to your coding. Yeah it&#x27;s a coding competition, but you must have the right idea. I &lt;em&gt;have&lt;&#x2F;em&gt; been able to get around this annoyance if I notice a number of technical judges who will appreciate a project just because it&#x27;s cool &amp;lt;3. Here are a few questions I think about regarding an idea;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Is this novel? If not, does it do it much better than the original?&lt;&#x2F;li&gt;
&lt;li&gt;Is this impactful? How soon will it be impactful, and will that impact demo well?&lt;&#x2F;li&gt;
&lt;li&gt;Is this technically interesting? If not, how can it be spiced up?&lt;&#x2F;li&gt;
&lt;li&gt;How will this project demo?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;2-don-t-skimp-on-the-planning&quot;&gt;2. Don&#x27;t skimp on the planning.&lt;&#x2F;h2&gt;
&lt;p&gt;Working in a team is hard. Trying to design a full featured project and build it in 36 hours is hard. Sleep deprivation makes it worse. Trying to figure out what needs to get done and how will be insanely hard. Planning includes making sure that all team members know what they&#x27;re doing, and how all the parts will fit together. If a certain feature depends on another one, it would be a good time for someone to sleep. When considering &amp;quot;optional&amp;quot; features, set a time so that you know at which point you should give up and move onto something more essential. When planning, consider that some features may be a pain to implement but will never show up in the demo, or will only partially show up in the demo. For those, just have a UI or a single type of case that can be demoed and let the judges know.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-pair&quot;&gt;3. Pair.&lt;&#x2F;h2&gt;
&lt;p&gt;Code written at hackathons is bad, and gets exponentially (may be factorial, more data is needed) worse as time progresses. It&#x27;s almost always more efficient to have someone around for a sanity check, especially if they wrote some of the surrounding code.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;4-start-by-programming-the-new-things&quot;&gt;4. Start by programming the &amp;quot;new&amp;quot; things.&lt;&#x2F;h2&gt;
&lt;p&gt;Coding when tired is hard. Reading documentation when you&#x27;re so tired that everything is blurry is hard. If you&#x27;re working with a new kind of database, write yourself a query&#x2F;push&#x2F;update&#x2F;delete first, and let your team know where it is. Same goes for SDKs, sending requests from React for the first time, etc. People often don&#x27;t do that, since it yields working &amp;quot;parts&amp;quot; more slowly, but trust me this is #worth. This also means being A G I L E and spreading out your work rather than fully finishing one &amp;quot;part&amp;quot; then moving onto the next. Additionally, this will let you know early on if something isn&#x27;t technically feasible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;5-have-a-good-sleeping-pattern&quot;&gt;5. Have a good sleeping pattern.&lt;&#x2F;h2&gt;
&lt;p&gt;Power naps are much more efficient than just crashing for twelve hours near the end. I like to wake up for the last six hours of the hackathon. This gives me enough rest to be able to efficiently rescue last-minute bugs and demo without being a zombie. Another good time to sleep is right after planning, though I like to have one person awake to scaffold the project. It&#x27;s near impossible for four people to actively work on a fresh project at the same time.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;6-talk-to-sponsors-and-judges-during-the-hack&quot;&gt;6. Talk to sponsors and judges during the hack.&lt;&#x2F;h2&gt;
&lt;p&gt;This is especially great when going for category&#x2F;API prizes. Most people will be willing to give some pointers or new ideas that would make your hack more interesting. Sometimes it&#x27;ll be more like &amp;quot;Dude, this idea will never work ever&amp;quot;. With API prizes, they may share some magical feature that you didn&#x27;t know about and will save you hours. On top of that, the sponsors will (hopefully) have a better impression of your team. Often I have projects with an &amp;quot;Oh shit&amp;quot; moment, or a &amp;quot;LITTY!!!!&amp;quot; moment that are I wouldn&#x27;t have without talking to others.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;7-demo-and-talk&quot;&gt;7. Demo and talk.&lt;&#x2F;h2&gt;
&lt;p&gt;Judges can get seriously bored listening about the next big thing. Never separate the &amp;quot;talk&amp;quot; and the &amp;quot;demo&amp;quot;. Just do it at the same time. Demos are flashy, and you want to make sure to capture every possible feature. Rehearse your demo more than your speech (especially if the project is somewhat buggy). Another point to mention, is that your idea should be awesome to demo. This often means hardware, things happening in realtime or some other magical &amp;quot;waaaaaw&amp;quot; moment.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;8-don-t-bullshit&quot;&gt;8. Don&#x27;t bullshit.&lt;&#x2F;h2&gt;
&lt;p&gt;Maybe the one judge you get doesn&#x27;t catch it, but they&#x27;ll tell the other judges who likely will. I&#x27;ve disqualified people who comically oversold, totally missed the idea of blockchain, reused ideas or made up some facts about MRI scans (seriously?).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;9-it-s-a-good-sign-if-your-judge-asks-questions&quot;&gt;9. It&#x27;s a good sign if your judge asks questions.&lt;&#x2F;h2&gt;
&lt;p&gt;Usually, they&#x27;re not just trying to hurt your feelings and&#x2F;or ruin your life. They&#x27;re actually interested in how your project works. How you answer these questions are easily more important than the initial demo. Remember that when they ask a question, it&#x27;s not an invitation to start discussing an entire different aspect of your project. I&#x27;ve yet to encounter any question that would take more than a few sentences to answer.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;10-stop-talking&quot;&gt;10. STOP TALKING.&lt;&#x2F;h2&gt;
&lt;p&gt;If a teammate answers a question, you don&#x27;t need to add-on (unless it was &lt;em&gt;seriously&lt;&#x2F;em&gt; inadequate). If a feature is described, the implications of that feature are often intuitive. If your project is interesting enough, then it&#x27;s always safer to say less as then the judges will ask questions. Even if it isn&#x27;t interesting, a lot of judges will pick up on fact that you may have undersold and will prod you about it.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Other silly things that aren&#x27;t quite worth another point or related to winning;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Stressed programming is also bad. Go play games; go cup stacking or do yoga. PET THE THERAPY DOGS. Plus if you win cup stacking, you&#x27;re still a H A C K A T H O N W I N N E R ü§î&lt;&#x2F;li&gt;
&lt;li&gt;Sometimes when you&#x27;re REALLY tired, you start forgetting what you&#x27;re trying to do. Try making a list of comments in your code as a to-do list.&lt;&#x2F;li&gt;
&lt;li&gt;Be awake for closings. Having your team showing up to the stage and being like &amp;quot;Where is John? Oh I see he&#x27;s passed out on the table back there.&amp;quot; is awks.&lt;&#x2F;li&gt;
&lt;li&gt;Don&#x27;t try to build a project that covers every single category and API prize.&lt;&#x2F;li&gt;
&lt;li&gt;Feed yourself. But not just chips. Have a salad.&lt;&#x2F;li&gt;
&lt;li&gt;Write decent commit messages; especially for the last couple hours. Finding a bug during demos and having no idea when it happened is very yikes.&lt;&#x2F;li&gt;
&lt;li&gt;Other people will hate you if you use blockchain wrong. Or if you just plug a random model into AR. Or if you use an API and advertise your &amp;quot;machine learning&amp;quot; hack.  ¬Ø\_(„ÉÑ)_&#x2F;¬Ø. It will sometimes push you towards a win but do you really want to win that way? DO YOU?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Chemical Composition of Apple Screens</title>
		<published>2017-09-09T00:00:00+00:00</published>
		<updated>2017-09-09T00:00:00+00:00</updated>
		<link href="https://kipp.ly/chemical-composition-of-apple-screens/"/>
		<link rel="alternate" href="https://kipp.ly/chemical-composition-of-apple-screens/" type="text/html"/>
		<id>https://kipp.ly/chemical-composition-of-apple-screens/</id>
		<content type="html">&lt;p&gt;In July of 2017, nine SHAD Fellows participated in a fast-paced version of the Students on the Beamline program at the University of Saskatchewan. Other than flat ground(and more flat ground), Saskatchewan is home to a synchrotron light source, the only one in Canada and one of eight in North America.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;span class=&quot;pink-highlight&quot;&gt;A synchrotron particle accelerator uses about 900 billion electrons at any point in time, sped up to around 1.38√ó10‚Åπ km&#x2F;hr‚Ää-‚Ääfast enough to reach the moon in a second.&lt;&#x2F;span&gt; As these electrons spin, certain laws of physics allow them to produce extremely powerful light. The light produced at the synchrotron is millions of times brighter than the sun.&lt;&#x2F;p&gt;
&lt;p&gt;At the CLS, our team decided to investigate the strength of glass based on it&#x27;s chemical composition. Because of the busy program, we had twenty hours over two weeks to come up with an idea, research, gather samples and analyze the data. We wouldn&#x27;t have gotten anything done without large amount of donations, including:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;iPod Touch 4&lt;&#x2F;li&gt;
&lt;li&gt;iPhone 4&lt;&#x2F;li&gt;
&lt;li&gt;iPhone 5&lt;&#x2F;li&gt;
&lt;li&gt;iPhone 5c&lt;&#x2F;li&gt;
&lt;li&gt;iPhone 6&lt;&#x2F;li&gt;
&lt;li&gt;iPhone 6s
And many other non-Apple devices. Many of the Android devices used Gorilla Glass, and given how notorious Apple is for planned obsolescence.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;span class=&quot;pink-highlight&quot;&gt;Spoiler alert: Since the iPod Touch 4, the quality of glass from these devices has been increasing. Apple does not use cheaply produced glass hoping that people visit their expensive repair shops more often.&lt;span&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Anywho, really bright lights are cool. X-Rays are essential for doctors, and your desk light helps you to read through the night. Synchrotrons aim lights at samples to gather information about chemical composition, map where elements are found and model the molecular structure of samples.&lt;&#x2F;p&gt;
&lt;p&gt;During our experiment we worked with the XRF technique‚Ää-‚ÄäX-Ray Fluorescence. The high energy rays of light strike the atoms in the sample, exciting the electrons. Electrons from lower energy orbitals (for example, an electron from n = 2) will be dislodged from the atom, causing an electron from a higher energy orbital to fall into it&#x27;s place. This will release a very specific amount of energy, which when measured can be used to identify the element. Add a few asterisks to the information you just read, cause it&#x27;s physics and it&#x27;s not really that straightforward.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;synchrotronproject&#x2F;xrf.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Gorilla Glass tells us that they use an ion-exchange process to add potassium ions to their glass, with the theory that larger ions will cause the glass to be stronger. &lt;span class=&quot;pink-highlight&quot;&gt;Sodium ions are replaced by larger potassium ions, creating compressive stress in the glass, and thus more resistant to damage.&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s what we found in our samples;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;synchrotronproject&#x2F;full-graph.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This graph may be a pain to read :p&lt;&#x2F;p&gt;
&lt;p&gt;With the XRF technique, we were able to determine relative compositions. Each peak represents the presence of a different element (as labeled). As a quick note, we still have no clue what was up with the halfnium in the iPhone 5. iPhones seem to have increasingly more potassium(K) over time, though the iPhone 6s appears to be an anomaly, though can be ignored since the phone we used was severely cracked and a powdered glass sample was used.&lt;&#x2F;p&gt;
&lt;p&gt;In case you&#x27;re curious, unlabeled peaks are secondary peaks of an element. Depending on the electron that is dislodged, different energies will be released. Arsenic(As) is commonly used in glass production, and is expected to be present in glass. The argon peak at the beginning is just from the air.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;synchrotronproject&#x2F;five.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The iPhone 5C was a cheap and very popular phone. Without a contract, they started at $99 USD while the iPhone 5 started at $649 USD. &lt;span class=&quot;pink-highlight&quot;&gt;It wasn&#x27;t just the specs that caused this huge price difference‚Ää-‚Ääthe differences in quality can be observed in the glass.&lt;&#x2F;span&gt; The iPhone 5C had significantly less potassium(K) and more calcium(Ca). Apple was likely able to use calcium as a cheaper substitute for potassium as they&#x27;re both Alkali Metals and share similar properties. The Iron(Fe) is most likely an impurity.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;..&#x2F;img&#x2F;synchrotronproject&#x2F;generations.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In this graph, you can see the amount of potassium(K) increase when the model of the iPhone is more recent. Additionally, there seems to be a big leap between their approach to getting stronger glass from the iPhone 4 to the 5 and 6 (Good job Apple!). The obvious question, is why not just stuff it with all the potassium possible? With the atomic structure of glass (and other properties), having too many large ions could actually cause bends or bumps in the glass. There&#x27;s a good chance they have a research team dedicated to improving the glass on their phones.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s always good to know that Apple is really trying to make our phones last longer, and they&#x27;re not really hoping that you&#x27;re visiting their expensive-ass Genius Bar with shattered screens.&lt;&#x2F;p&gt;
&lt;p&gt;Thanks for reading,&lt;&#x2F;p&gt;
&lt;p&gt;&lt;span class=&quot;green-highlight&quot;&gt;Carol Chen, the rest of the team and scientists at the CLS&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
</feed>
